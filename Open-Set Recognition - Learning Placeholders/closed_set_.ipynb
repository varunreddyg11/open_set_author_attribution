{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hiCdiTWzgKeG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#pd.set_option('display.max_rows', 50000)/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oq68oD37gl7e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IWe3lgvZgZTb",
        "outputId": "c9bc9791-9fb8-4f25-b527-1a6864e66839"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           author  real_label  label  \\\n",
              "0  A11OTLEDSW8ZXD          44     44   \n",
              "1  A11OTLEDSW8ZXD          44     44   \n",
              "2  A11OTLEDSW8ZXD          44     44   \n",
              "3  A11OTLEDSW8ZXD          44     44   \n",
              "4  A11OTLEDSW8ZXD          44     44   \n",
              "5  A11OTLEDSW8ZXD          44     44   \n",
              "6  A11OTLEDSW8ZXD          44     44   \n",
              "7  A11OTLEDSW8ZXD          44     44   \n",
              "8  A11OTLEDSW8ZXD          44     44   \n",
              "9  A11OTLEDSW8ZXD          44     44   \n",
              "\n",
              "                                              review  \\\n",
              "0  I have always been a fan of the Lewis and Clar...   \n",
              "1  I started reading this book during a three-wee...   \n",
              "2  This cable is well-made and feels sturdier tha...   \n",
              "3  This kibble is expensive, but the cats like it...   \n",
              "4  This device is exactly what we needed for our ...   \n",
              "5  These beef hides are quite the treat.  I like ...   \n",
              "6  Reading this memoir was quite a surprise.  It ...   \n",
              "7  Being a born Hoosier and having graduated from...   \n",
              "8  This is a surprisingly good first novel.  Whil...   \n",
              "9  My first impression of this lens was its weigh...   \n",
              "\n",
              "                        product_domain  overall  #words  \n",
              "0                        books.json.gz      5.0     529  \n",
              "1                        books.json.gz      4.0     193  \n",
              "2  cell_phones_and_accessories.json.gz      4.0     109  \n",
              "3                 pet_supplies.json.gz      5.0     100  \n",
              "4                  electronics.json.gz      4.0     197  \n",
              "5                 pet_supplies.json.gz      5.0     130  \n",
              "6                        books.json.gz      4.0     393  \n",
              "7                        books.json.gz      4.0     382  \n",
              "8                        books.json.gz      5.0     140  \n",
              "9                  electronics.json.gz      3.0     348  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-623aa9b7-5468-4bae-9e6c-ee80c2103917\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>real_label</th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "      <th>product_domain</th>\n",
              "      <th>overall</th>\n",
              "      <th>#words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>I have always been a fan of the Lewis and Clar...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>5.0</td>\n",
              "      <td>529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>I started reading this book during a three-wee...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>This cable is well-made and feels sturdier tha...</td>\n",
              "      <td>cell_phones_and_accessories.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>This kibble is expensive, but the cats like it...</td>\n",
              "      <td>pet_supplies.json.gz</td>\n",
              "      <td>5.0</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>This device is exactly what we needed for our ...</td>\n",
              "      <td>electronics.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>These beef hides are quite the treat.  I like ...</td>\n",
              "      <td>pet_supplies.json.gz</td>\n",
              "      <td>5.0</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>Reading this memoir was quite a surprise.  It ...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>Being a born Hoosier and having graduated from...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>This is a surprisingly good first novel.  Whil...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>5.0</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>My first impression of this lens was its weigh...</td>\n",
              "      <td>electronics.json.gz</td>\n",
              "      <td>3.0</td>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-623aa9b7-5468-4bae-9e6c-ee80c2103917')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-623aa9b7-5468-4bae-9e6c-ee80c2103917 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-623aa9b7-5468-4bae-9e6c-ee80c2103917');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset=pd.read_csv(\"/content/drive/MyDrive/ASU/train.csv\")\n",
        "dataset.head(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9pq-A70gfgG",
        "outputId": "74235a90-16e4-40da-c1d6-d7908e319ed2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(dataset.real_label.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "F4xsb7Ingh-k",
        "outputId": "1bebfd74-f8d9-4b5d-a246-53b378adbf60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            author  label  review  product_domain  overall  #words\n",
              "real_label                                                        \n",
              "0              500    500     500             500      500     500\n",
              "1              500    500     500             500      500     500\n",
              "2              500    500     500             500      500     500\n",
              "3              500    500     500             500      500     500\n",
              "4              500    500     500             500      500     500\n",
              "...            ...    ...     ...             ...      ...     ...\n",
              "95             500    500     500             500      500     500\n",
              "96             500    500     500             500      500     500\n",
              "97             500    500     500             500      500     500\n",
              "98             500    500     500             500      500     500\n",
              "99             500    500     500             500      500     500\n",
              "\n",
              "[100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43afb344-11b0-4359-8585-71daae97cf44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "      <th>product_domain</th>\n",
              "      <th>overall</th>\n",
              "      <th>#words</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43afb344-11b0-4359-8585-71daae97cf44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43afb344-11b0-4359-8585-71daae97cf44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43afb344-11b0-4359-8585-71daae97cf44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset.groupby(by='real_label').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "59Iv1OIhgkPS",
        "outputId": "286e3627-8dd8-49ae-a459-dcb53ff7528d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       real_label                                             review\n",
              "0              44  I have always been a fan of the Lewis and Clar...\n",
              "1              44  I started reading this book during a three-wee...\n",
              "2              44  This cable is well-made and feels sturdier tha...\n",
              "3              44  This kibble is expensive, but the cats like it...\n",
              "4              44  This device is exactly what we needed for our ...\n",
              "...           ...                                                ...\n",
              "49995          46  Dumbo is one of disney's most beloved and clas...\n",
              "49996          46  I haven't played anygood sport games yet and i...\n",
              "49997          46  This game is loads of fun, i really liked this...\n",
              "49998          46  Gabriel is one of the funniest comedians i've ...\n",
              "49999          46  red tails is about the tuskegee airforce men w...\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f3c03fa-4220-4af4-9dc8-c73c4f57876a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>I have always been a fan of the Lewis and Clar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>I started reading this book during a three-wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>This cable is well-made and feels sturdier tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>This kibble is expensive, but the cats like it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>This device is exactly what we needed for our ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>46</td>\n",
              "      <td>Dumbo is one of disney's most beloved and clas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>46</td>\n",
              "      <td>I haven't played anygood sport games yet and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>46</td>\n",
              "      <td>This game is loads of fun, i really liked this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>46</td>\n",
              "      <td>Gabriel is one of the funniest comedians i've ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>46</td>\n",
              "      <td>red tails is about the tuskegee airforce men w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f3c03fa-4220-4af4-9dc8-c73c4f57876a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f3c03fa-4220-4af4-9dc8-c73c4f57876a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f3c03fa-4220-4af4-9dc8-c73c4f57876a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset.loc[:,['real_label','review']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WSv4YScMgmb_"
      },
      "outputs": [],
      "source": [
        "import regex as re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i9PWLkmpgoLo"
      },
      "outputs": [],
      "source": [
        "dataset['flag']=dataset.loc[:,['real_label','review']].apply(lambda x: re.match(\"UPDATE*\",x['review']),axis=1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-AEvb1-ogpxk"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ocljhqeCgrKx"
      },
      "outputs": [],
      "source": [
        "#removing updated records\n",
        "\n",
        "dataset_filtered=dataset.loc[:,['real_label','review','flag']].loc[dataset['flag'].isin([None])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yGEU0z_wgs_h"
      },
      "outputs": [],
      "source": [
        "dataset_filtered.drop('flag',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0hcdDVPvgujd",
        "outputId": "50adfaf3-71f6-4706-cde9-7311090aa667"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       real_label                                             review  \\\n",
              "450            44  <div id=\"video-block-R2SQB0OUB1NBH5\" class=\"a-...   \n",
              "2809            0  <div id=\"video-block-R1VMY3B2ETH5QP\" class=\"a-...   \n",
              "2821            0  <div id=\"video-block-R3NJKKD6S2WID6\" class=\"a-...   \n",
              "2952            0  <div id=\"video-block-R33S0CYT44UQX1\" class=\"a-...   \n",
              "2970            0  <div id=\"video-block-R5L2E0WNGPMI7\" class=\"a-s...   \n",
              "...           ...                                                ...   \n",
              "44995          40  <div id=\"video-block-R1R0HO8E534KBL\" class=\"a-...   \n",
              "44996          40  <div id=\"video-block-R1ZAATOSO22JSK\" class=\"a-...   \n",
              "44999          40  <div id=\"video-block-R306912UZ65A6Y\" class=\"a-...   \n",
              "45555          69  <div id=\"video-block-R2NVHO9ID4JNHG\" class=\"a-...   \n",
              "45636          69  <div id=\"video-block-R13GXJJWLY7JN2\" class=\"a-...   \n",
              "\n",
              "                                                  flag  \n",
              "450    <regex.Match object; span=(0, 4), match='<div'>  \n",
              "2809   <regex.Match object; span=(0, 4), match='<div'>  \n",
              "2821   <regex.Match object; span=(0, 4), match='<div'>  \n",
              "2952   <regex.Match object; span=(0, 4), match='<div'>  \n",
              "2970   <regex.Match object; span=(0, 4), match='<div'>  \n",
              "...                                                ...  \n",
              "44995  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "44996  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "44999  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "45555  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "45636  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "\n",
              "[719 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee9a865a-6922-4d9b-86eb-072468c15fbb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>44</td>\n",
              "      <td>&lt;div id=\"video-block-R2SQB0OUB1NBH5\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2809</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;div id=\"video-block-R1VMY3B2ETH5QP\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2821</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;div id=\"video-block-R3NJKKD6S2WID6\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2952</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;div id=\"video-block-R33S0CYT44UQX1\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2970</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;div id=\"video-block-R5L2E0WNGPMI7\" class=\"a-s...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44995</th>\n",
              "      <td>40</td>\n",
              "      <td>&lt;div id=\"video-block-R1R0HO8E534KBL\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44996</th>\n",
              "      <td>40</td>\n",
              "      <td>&lt;div id=\"video-block-R1ZAATOSO22JSK\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44999</th>\n",
              "      <td>40</td>\n",
              "      <td>&lt;div id=\"video-block-R306912UZ65A6Y\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45555</th>\n",
              "      <td>69</td>\n",
              "      <td>&lt;div id=\"video-block-R2NVHO9ID4JNHG\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45636</th>\n",
              "      <td>69</td>\n",
              "      <td>&lt;div id=\"video-block-R13GXJJWLY7JN2\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>719 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee9a865a-6922-4d9b-86eb-072468c15fbb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee9a865a-6922-4d9b-86eb-072468c15fbb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee9a865a-6922-4d9b-86eb-072468c15fbb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset_filtered['flag']=dataset_filtered.loc[:,['real_label','review']].apply(lambda x: re.match(\"<div*\",x['review']),axis=1 )\n",
        "dataset_filtered.loc[:,['real_label','review','flag']].loc[~dataset_filtered['flag'].isin([None])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "dzYeq9Pcgv-Y",
        "outputId": "72ab5cdd-57f5-4f58-ed50-47b97a5b856e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            review  flag\n",
              "real_label              \n",
              "0                4     4\n",
              "1                1     1\n",
              "5                1     1\n",
              "7              178   178\n",
              "8                1     1\n",
              "9               35    35\n",
              "10              22    22\n",
              "14               3     3\n",
              "16             170   170\n",
              "17               1     1\n",
              "32               1     1\n",
              "34              58    58\n",
              "39              10    10\n",
              "40             139   139\n",
              "44               1     1\n",
              "45               1     1\n",
              "51              72    72\n",
              "53               9     9\n",
              "61               9     9\n",
              "69               2     2\n",
              "96               1     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d166a3b-d1b6-44e6-86e4-2c77bc21be42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>178</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>139</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d166a3b-d1b6-44e6-86e4-2c77bc21be42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d166a3b-d1b6-44e6-86e4-2c77bc21be42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d166a3b-d1b6-44e6-86e4-2c77bc21be42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dataset_filtered.loc[:,['real_label','review','flag']].loc[~dataset_filtered['flag'].isin([None])].groupby('real_label').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4WcMNZCDgx7c"
      },
      "outputs": [],
      "source": [
        "dataset_filtered.drop('flag',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_GWJsLH5hE4a",
        "outputId": "f37b6a9f-6144-4c1c-c2f6-ad4ab2cbf93b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   real_label                                             review\n",
              "0          44  I have always been a fan of the Lewis and Clar...\n",
              "1          44  I started reading this book during a three-wee...\n",
              "2          44  This cable is well-made and feels sturdier tha...\n",
              "3          44  This kibble is expensive, but the cats like it...\n",
              "4          44  This device is exactly what we needed for our ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad2188a7-d4c5-424f-b1fb-4120cbcf78db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>I have always been a fan of the Lewis and Clar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>I started reading this book during a three-wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>This cable is well-made and feels sturdier tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>This kibble is expensive, but the cats like it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>This device is exactly what we needed for our ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad2188a7-d4c5-424f-b1fb-4120cbcf78db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad2188a7-d4c5-424f-b1fb-4120cbcf78db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad2188a7-d4c5-424f-b1fb-4120cbcf78db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset_filtered.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "tWeBPDesiKXr",
        "outputId": "51b900b7-1b68-4bef-e305-76e2f2dedd29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            review\n",
              "real_label        \n",
              "0              497\n",
              "1              500\n",
              "2              500\n",
              "3              500\n",
              "4              500\n",
              "...            ...\n",
              "95             500\n",
              "96             500\n",
              "97             500\n",
              "98             500\n",
              "99             500\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a29b6ab-50e4-49aa-be4b-7b97283f1a4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a29b6ab-50e4-49aa-be4b-7b97283f1a4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a29b6ab-50e4-49aa-be4b-7b97283f1a4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a29b6ab-50e4-49aa-be4b-7b97283f1a4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dataset_filtered.groupby('real_label').count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Input dataset\n",
        "dataset_filtered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jYLP4SFw4JoF",
        "outputId": "8c2a082e-e69e-41aa-d823-e5c756d904a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       real_label                                             review\n",
              "0              44  I have always been a fan of the Lewis and Clar...\n",
              "1              44  I started reading this book during a three-wee...\n",
              "2              44  This cable is well-made and feels sturdier tha...\n",
              "3              44  This kibble is expensive, but the cats like it...\n",
              "4              44  This device is exactly what we needed for our ...\n",
              "...           ...                                                ...\n",
              "49995          46  Dumbo is one of disney's most beloved and clas...\n",
              "49996          46  I haven't played anygood sport games yet and i...\n",
              "49997          46  This game is loads of fun, i really liked this...\n",
              "49998          46  Gabriel is one of the funniest comedians i've ...\n",
              "49999          46  red tails is about the tuskegee airforce men w...\n",
              "\n",
              "[49967 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a269fd8-d513-42e1-8abd-6eee5c4ae68b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>I have always been a fan of the Lewis and Clar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>I started reading this book during a three-wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>This cable is well-made and feels sturdier tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>This kibble is expensive, but the cats like it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>This device is exactly what we needed for our ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>46</td>\n",
              "      <td>Dumbo is one of disney's most beloved and clas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>46</td>\n",
              "      <td>I haven't played anygood sport games yet and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>46</td>\n",
              "      <td>This game is loads of fun, i really liked this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>46</td>\n",
              "      <td>Gabriel is one of the funniest comedians i've ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>46</td>\n",
              "      <td>red tails is about the tuskegee airforce men w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49967 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a269fd8-d513-42e1-8abd-6eee5c4ae68b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a269fd8-d513-42e1-8abd-6eee5c4ae68b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a269fd8-d513-42e1-8abd-6eee5c4ae68b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "918jkbVoh_Y1",
        "outputId": "8586f748-bc25-4df0-bd76-08c84cf114b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    n_gpu=torch.cuda.device_count()\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy-HBiXjiE1g",
        "outputId": "8e89eb32-f6e4-49aa-971c-460558ed41ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer,BertTokenizer\n",
        "# Load the tokenizer.\n",
        "print('Loading Roberta tokenizer...')\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "5e49f574fc784dee829f63e7b57c1e5e",
            "ff5537f8d4de4ad79b242a039e7f21fd",
            "cb3620b504f347599aa9e97d681cf0cb",
            "9fe22194db0e4d4c91ca395f274804fd",
            "b714a50f338b4d388549231b53d8ce04",
            "36f86491a6654bc79426b56082f15407",
            "64b9af0dd2b8486195bd87913e02d681",
            "d7f7bb02e6444e4b9934c2125fabb1c9",
            "e063a91f3dc842bfaf9ca14207b1be82",
            "6e23826b83504bab95154b60c93310d9",
            "653f34951fe24f87bf5ac7addb9615ec",
            "ab09c9910bc84cf1af02838c418ef83e",
            "e7c4166a7a8747978717ba7aae195ae7",
            "7b3be117f6dd4b9faa3a21af007bf4ff",
            "f73492744a404c67aa23413e77969171",
            "e3c311d2fb224d079b13399064908893",
            "ec390a539a0c4b408e46b1b1abd56329",
            "b2a7f88ab772488fb26bb0320a5bff7e",
            "bf2b5e3a280c437ebd17cac71f441a21",
            "47900b36aea54bc29e1fe5d6e54333af",
            "18dbf81a0007438d837e9a89fcc275fa",
            "dcb28abbc57c48069d6909747376dcfe",
            "7bcaa69d6e3d43e19f0c56f05844d760",
            "9550883bc39949d1972d1683452b4266",
            "45960c910c934728a4d143553e896ab8",
            "bbe83bd48ac344ae9a58dc8b92e93061",
            "ef63a720b5934de8b3c405b78f41ee70",
            "300ee276fbb34414a4e0522ce8b74b06",
            "bcea42c3ba474faead0a1ebb7eb0e426",
            "71562a7413054110a40d6e619d3ef894",
            "5c479a7273974e7b9977c205ecbf4700",
            "30d6a792f21842a2b3607a7107465f51",
            "587906a4b6ec4895ab873ecbae50aed8"
          ]
        },
        "id": "6BZYtNIG-YG9",
        "outputId": "0d9376ce-811e-4414-bd81-54f09f48dc7a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Roberta tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e49f574fc784dee829f63e7b57c1e5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab09c9910bc84cf1af02838c418ef83e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bcaa69d6e3d43e19f0c56f05844d760"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1qImgeyib35",
        "outputId": "ffa1b891-7129-4e07-c4cf-973bf6d6896e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length in training data:  6643\n"
          ]
        }
      ],
      "source": [
        "#Max length\n",
        "\n",
        "max_len = 0\n",
        "len_list=[]\n",
        "# For every sentence...\n",
        "for r in dataset_filtered.values:\n",
        "    #print(r)\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(r[1], add_special_tokens=True)\n",
        "    len_list.append([r[0],len(input_ids)])\n",
        "    \n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length in training data: ', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YjNFmPYLisgM"
      },
      "outputs": [],
      "source": [
        "len_df=pd.DataFrame(len_list)\n",
        "len_df.columns=['Lable','str_len']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_df.loc[len_df['str_len'].values>2000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VxoSNUV48EeU",
        "outputId": "579cda0a-cd51-4a4d-b2a2-2f0d2207be96"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Lable  str_len\n",
              "1021      55     2271\n",
              "1092      55     2281\n",
              "1143      55     2533\n",
              "1155      55     2431\n",
              "1168      55     2037\n",
              "...      ...      ...\n",
              "47926     75     2999\n",
              "47932     75     2323\n",
              "47960     75     2098\n",
              "47961     75     2535\n",
              "47964     75     2015\n",
              "\n",
              "[230 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24e76e63-24b4-4c91-90d3-5425ac81b858\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lable</th>\n",
              "      <th>str_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>55</td>\n",
              "      <td>2271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>55</td>\n",
              "      <td>2281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1143</th>\n",
              "      <td>55</td>\n",
              "      <td>2533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1155</th>\n",
              "      <td>55</td>\n",
              "      <td>2431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1168</th>\n",
              "      <td>55</td>\n",
              "      <td>2037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47926</th>\n",
              "      <td>75</td>\n",
              "      <td>2999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47932</th>\n",
              "      <td>75</td>\n",
              "      <td>2323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47960</th>\n",
              "      <td>75</td>\n",
              "      <td>2098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47961</th>\n",
              "      <td>75</td>\n",
              "      <td>2535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47964</th>\n",
              "      <td>75</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>230 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24e76e63-24b4-4c91-90d3-5425ac81b858')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24e76e63-24b4-4c91-90d3-5425ac81b858 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24e76e63-24b4-4c91-90d3-5425ac81b858');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "XvMsVBbAlo85",
        "outputId": "5b293f58-7f71-4179-df48-c7dfd070e786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49967\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       str_len\n",
              "Lable         \n",
              "0          497\n",
              "1          500\n",
              "2          500\n",
              "3          500\n",
              "4          500\n",
              "...        ...\n",
              "95         500\n",
              "96         500\n",
              "97         500\n",
              "98         500\n",
              "99         500\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ebc38b9-e1ba-4b7d-81fb-056519449254\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>str_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lable</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ebc38b9-e1ba-4b7d-81fb-056519449254')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ebc38b9-e1ba-4b7d-81fb-056519449254 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ebc38b9-e1ba-4b7d-81fb-056519449254');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "print(len(len_df))\n",
        "len_df.groupby('Lable').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "obu05H4dmKtC",
        "outputId": "6ad32e6b-50c3-4918-b827-429d979a52fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39301\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       str_len\n",
              "Lable         \n",
              "0          476\n",
              "1          495\n",
              "2          484\n",
              "3          235\n",
              "4          473\n",
              "...        ...\n",
              "95         494\n",
              "96         500\n",
              "97         330\n",
              "98         154\n",
              "99         363\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-894838f1-5ace-4248-8a91-ef26b95efb7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>str_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lable</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-894838f1-5ace-4248-8a91-ef26b95efb7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-894838f1-5ace-4248-8a91-ef26b95efb7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-894838f1-5ace-4248-8a91-ef26b95efb7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len_df_filtered=len_df.loc[len_df['str_len'].values<=512]\n",
        "print(len(len_df_filtered))\n",
        "len_df_filtered.groupby('Lable').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "B19CR8NUnkOA"
      },
      "outputs": [],
      "source": [
        "dataset_filtered['num_sentences']=dataset_filtered.apply(lambda x:len(x.values[1].split('\\n')),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKUsJTzQ1MHm",
        "outputId": "9b934334-6e95-4063-cbbd-ca137e241d58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "np.percentile(dataset_filtered.num_sentences.values,95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "caLOP-mt10ru",
        "outputId": "a3475c50-e8a8-453c-e9cb-939512ea6c4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       real_label                                             review  \\\n",
              "3021           43  With HOLLYWOOD CLASSICS 100 MOVIE PACK, MILL C...   \n",
              "3023           43  Based on current polling numbers at a film res...   \n",
              "3062           43  The majority of films in the ACTION CLASSICS 5...   \n",
              "3183           43  WESTERN CLASSICS 100 MOVIE PACK is a set of 24...   \n",
              "3361           43  The CRIME CLASSICS 50 MOVIE PACK has one film ...   \n",
              "4789           68  Book #5 in the action-adventure series first p...   \n",
              "10224           7  <div id=\"video-block-R2SS5UEOOTKZG1\" class=\"a-...   \n",
              "11119          91  With many books, translations are negligible, ...   \n",
              "14002          74  Obama's Wars by Bob Woodward\\nSimon and Schust...   \n",
              "14025          74  The Baby Boomer Generation will be the new\\n\"T...   \n",
              "14063          74  Turbo Charged- Accelerate Your Fat Burning Met...   \n",
              "14124          74  Visions of the Multiverse\\nIs Our Universe One...   \n",
              "14146          74  The author's main point is that vaccines can\\n...   \n",
              "14388          74  The author's main thesis is that the seas have...   \n",
              "14441          74  Biofuels Engineering Process Technology by Dra...   \n",
              "14497          74  Super Body Super Brain- The Workout That Does ...   \n",
              "19033          16  I purchased Samsun Galaxy 7.7 with Prepaid mon...   \n",
              "19094          16  I am an experienced knitter who has made dozen...   \n",
              "19128          16  \"Life's little emergencies\" is a reference wri...   \n",
              "19299          16  All recipes in this book have a few things in ...   \n",
              "19383          16  <div id=\"video-block-RJZQTRRL40LXO\" class=\"a-s...   \n",
              "19583          15  Jean Vigo...the man who influenced the French ...   \n",
              "19599          15  Whit Stillman, the director who brought us \"Me...   \n",
              "19603          15  When it comes to the \"Star Trek\" films, some r...   \n",
              "19635          15  With Walt Disney's \"Zorro\" popular television ...   \n",
              "19712          15  For six years, \"Daria\" was a popular animated ...   \n",
              "19756          15  Back in 1961, one of the popular comedy shows ...   \n",
              "19800          15  With the announcement that \"90210', based on t...   \n",
              "19802          15  Back in 1982, the sci-fi Disney film \"Tron\" ca...   \n",
              "19808          15  Filmmaker Jacques Tati has inspired many peopl...   \n",
              "19832          15  One of the most fascinating and also important...   \n",
              "19894          15  Based on the popular manga and anime series th...   \n",
              "19958          15  Throughout the life of young pervert Tomoki Sa...   \n",
              "19980          15  Whenever there is an art heist, there is one w...   \n",
              "20151          26  This review will have a two-part format. In th...   \n",
              "20165          26  This review will have a two-part format. In th...   \n",
              "20170          26  Please note: This review is going to be quite ...   \n",
              "20407          26  This review will have a two-part format. In th...   \n",
              "25687          12  When I was young, I watched \"The Wizard of Oz\"...   \n",
              "42079          51  Anyone can file for Social Security Disability...   \n",
              "42154          51  Things have come a long way since we simply ad...   \n",
              "42186          51  <div id=\"video-block-R2HOIF5I4Y5VQN\" class=\"a-...   \n",
              "42286          51  Most iPad users I know are self-taught.  I kno...   \n",
              "42296          51  I have questions, lots of questions about Soci...   \n",
              "42367          51  One of the more interesting facets of supply c...   \n",
              "42393          51  The Kocaso has a gesture-based lock screen. If...   \n",
              "46638          90  I loved DS9. I didn't realize how much I'd lov...   \n",
              "49760          46  Angel is a awesome show and here are the best ...   \n",
              "49778          46  This is a awesome show probably one of the bes...   \n",
              "49853          46  Great seasons here is the best episodes for ea...   \n",
              "\n",
              "       num_sentences  \n",
              "3021             207  \n",
              "3023             105  \n",
              "3062             105  \n",
              "3183             106  \n",
              "3361             109  \n",
              "4789             102  \n",
              "10224            114  \n",
              "11119            169  \n",
              "14002            147  \n",
              "14025            113  \n",
              "14063            110  \n",
              "14124            104  \n",
              "14146            186  \n",
              "14388            109  \n",
              "14441            146  \n",
              "14497            164  \n",
              "19033            105  \n",
              "19094            122  \n",
              "19128            228  \n",
              "19299            119  \n",
              "19383            126  \n",
              "19583            117  \n",
              "19599            103  \n",
              "19603            155  \n",
              "19635            104  \n",
              "19712            133  \n",
              "19756            103  \n",
              "19800            156  \n",
              "19802            113  \n",
              "19808            104  \n",
              "19832            110  \n",
              "19894            119  \n",
              "19958            101  \n",
              "19980            107  \n",
              "20151            135  \n",
              "20165            131  \n",
              "20170            145  \n",
              "20407            115  \n",
              "25687            108  \n",
              "42079            220  \n",
              "42154            184  \n",
              "42186            157  \n",
              "42286            335  \n",
              "42296            144  \n",
              "42367            267  \n",
              "42393            105  \n",
              "46638            215  \n",
              "49760            124  \n",
              "49778            106  \n",
              "49853            104  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99ef47d4-76b7-47fd-a016-1abee73a40b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "      <th>num_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3021</th>\n",
              "      <td>43</td>\n",
              "      <td>With HOLLYWOOD CLASSICS 100 MOVIE PACK, MILL C...</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3023</th>\n",
              "      <td>43</td>\n",
              "      <td>Based on current polling numbers at a film res...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3062</th>\n",
              "      <td>43</td>\n",
              "      <td>The majority of films in the ACTION CLASSICS 5...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3183</th>\n",
              "      <td>43</td>\n",
              "      <td>WESTERN CLASSICS 100 MOVIE PACK is a set of 24...</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3361</th>\n",
              "      <td>43</td>\n",
              "      <td>The CRIME CLASSICS 50 MOVIE PACK has one film ...</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4789</th>\n",
              "      <td>68</td>\n",
              "      <td>Book #5 in the action-adventure series first p...</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10224</th>\n",
              "      <td>7</td>\n",
              "      <td>&lt;div id=\"video-block-R2SS5UEOOTKZG1\" class=\"a-...</td>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11119</th>\n",
              "      <td>91</td>\n",
              "      <td>With many books, translations are negligible, ...</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14002</th>\n",
              "      <td>74</td>\n",
              "      <td>Obama's Wars by Bob Woodward\\nSimon and Schust...</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14025</th>\n",
              "      <td>74</td>\n",
              "      <td>The Baby Boomer Generation will be the new\\n\"T...</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14063</th>\n",
              "      <td>74</td>\n",
              "      <td>Turbo Charged- Accelerate Your Fat Burning Met...</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14124</th>\n",
              "      <td>74</td>\n",
              "      <td>Visions of the Multiverse\\nIs Our Universe One...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14146</th>\n",
              "      <td>74</td>\n",
              "      <td>The author's main point is that vaccines can\\n...</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14388</th>\n",
              "      <td>74</td>\n",
              "      <td>The author's main thesis is that the seas have...</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14441</th>\n",
              "      <td>74</td>\n",
              "      <td>Biofuels Engineering Process Technology by Dra...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14497</th>\n",
              "      <td>74</td>\n",
              "      <td>Super Body Super Brain- The Workout That Does ...</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19033</th>\n",
              "      <td>16</td>\n",
              "      <td>I purchased Samsun Galaxy 7.7 with Prepaid mon...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19094</th>\n",
              "      <td>16</td>\n",
              "      <td>I am an experienced knitter who has made dozen...</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19128</th>\n",
              "      <td>16</td>\n",
              "      <td>\"Life's little emergencies\" is a reference wri...</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19299</th>\n",
              "      <td>16</td>\n",
              "      <td>All recipes in this book have a few things in ...</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19383</th>\n",
              "      <td>16</td>\n",
              "      <td>&lt;div id=\"video-block-RJZQTRRL40LXO\" class=\"a-s...</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19583</th>\n",
              "      <td>15</td>\n",
              "      <td>Jean Vigo...the man who influenced the French ...</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19599</th>\n",
              "      <td>15</td>\n",
              "      <td>Whit Stillman, the director who brought us \"Me...</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19603</th>\n",
              "      <td>15</td>\n",
              "      <td>When it comes to the \"Star Trek\" films, some r...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19635</th>\n",
              "      <td>15</td>\n",
              "      <td>With Walt Disney's \"Zorro\" popular television ...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19712</th>\n",
              "      <td>15</td>\n",
              "      <td>For six years, \"Daria\" was a popular animated ...</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19756</th>\n",
              "      <td>15</td>\n",
              "      <td>Back in 1961, one of the popular comedy shows ...</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19800</th>\n",
              "      <td>15</td>\n",
              "      <td>With the announcement that \"90210', based on t...</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19802</th>\n",
              "      <td>15</td>\n",
              "      <td>Back in 1982, the sci-fi Disney film \"Tron\" ca...</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19808</th>\n",
              "      <td>15</td>\n",
              "      <td>Filmmaker Jacques Tati has inspired many peopl...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19832</th>\n",
              "      <td>15</td>\n",
              "      <td>One of the most fascinating and also important...</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19894</th>\n",
              "      <td>15</td>\n",
              "      <td>Based on the popular manga and anime series th...</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19958</th>\n",
              "      <td>15</td>\n",
              "      <td>Throughout the life of young pervert Tomoki Sa...</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19980</th>\n",
              "      <td>15</td>\n",
              "      <td>Whenever there is an art heist, there is one w...</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20151</th>\n",
              "      <td>26</td>\n",
              "      <td>This review will have a two-part format. In th...</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20165</th>\n",
              "      <td>26</td>\n",
              "      <td>This review will have a two-part format. In th...</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20170</th>\n",
              "      <td>26</td>\n",
              "      <td>Please note: This review is going to be quite ...</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20407</th>\n",
              "      <td>26</td>\n",
              "      <td>This review will have a two-part format. In th...</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25687</th>\n",
              "      <td>12</td>\n",
              "      <td>When I was young, I watched \"The Wizard of Oz\"...</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42079</th>\n",
              "      <td>51</td>\n",
              "      <td>Anyone can file for Social Security Disability...</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42154</th>\n",
              "      <td>51</td>\n",
              "      <td>Things have come a long way since we simply ad...</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42186</th>\n",
              "      <td>51</td>\n",
              "      <td>&lt;div id=\"video-block-R2HOIF5I4Y5VQN\" class=\"a-...</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42286</th>\n",
              "      <td>51</td>\n",
              "      <td>Most iPad users I know are self-taught.  I kno...</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42296</th>\n",
              "      <td>51</td>\n",
              "      <td>I have questions, lots of questions about Soci...</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42367</th>\n",
              "      <td>51</td>\n",
              "      <td>One of the more interesting facets of supply c...</td>\n",
              "      <td>267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42393</th>\n",
              "      <td>51</td>\n",
              "      <td>The Kocaso has a gesture-based lock screen. If...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46638</th>\n",
              "      <td>90</td>\n",
              "      <td>I loved DS9. I didn't realize how much I'd lov...</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49760</th>\n",
              "      <td>46</td>\n",
              "      <td>Angel is a awesome show and here are the best ...</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49778</th>\n",
              "      <td>46</td>\n",
              "      <td>This is a awesome show probably one of the bes...</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49853</th>\n",
              "      <td>46</td>\n",
              "      <td>Great seasons here is the best episodes for ea...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99ef47d4-76b7-47fd-a016-1abee73a40b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99ef47d4-76b7-47fd-a016-1abee73a40b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99ef47d4-76b7-47fd-a016-1abee73a40b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "dataset_filtered.loc[dataset_filtered['num_sentences']>100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzg99yNARt7Q",
        "outputId": "92a25756-5028-418d-e552-5aafe555a251"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['real_label', 'review', 'num_sentences'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "dataset_filtered.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TJH5YBtl2TOY"
      },
      "outputs": [],
      "source": [
        "labels = dataset_filtered.real_label.values\n",
        "sentences=dataset_filtered.review.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(dataset_filtered.real_label.values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI8AQwQo9hYz",
        "outputId": "9e910418-5b61-4372-f1bc-64e91b27d617"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "pvL9x0Nz9IA7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labels = torch.nn.functional.one_hot(labels, num_classes = 100).to(torch.float)\n",
        "#print(labels)"
      ],
      "metadata": {
        "id": "oNK487VO9Ms9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8csXCK7-eXp",
        "outputId": "770284ad-4d5c-4515-d4c6-a0f99be79f5f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  I have always been a fan of the Lewis and Clark (L&C) expedition and have read numerous books on that era.  I even road tripped along the Missouri River to the river's source in Montana (bypassing North Dakota and eastern Montana due to repeated tornadoes that summer), stopping along all the historical signs.  I'm a fan because I understand the courage it took to explore unknown lands with potential violent inhabitants, but I also understand the significance of American expansion to the Pacific via the Northwest passage.  Opening up these lands is one of Jefferson's biggest legacies as president.\n",
            "\n",
            "What Julie Fenster does here is not just summarize the L&C expedition, though.  She describes the young America at the turn of the 19th century.  Pioneers were moving westward, but Spain controlled the western lands. She gives short biographies of the players, the governors, kings and explorers of the era.  It was a time of great hostilities.  Fenster portrays Jefferson as a man fighting off the John Adams supporters; all was not going so well for Jefferson when he first became president.\n",
            "\n",
            "What readers get out of this very readable account is that the L&C expedition was not the only expedition going on at the time.  It's interesting to note that there were other courageous explorers willing to report back to Jefferson what the Spanish-held lands were like, and Fenster describes these in relation to the L&C expedition  The Hunter & Dunbar expedition was as valuable to Jefferson as the L&C one was, or the oft-plagued expedition of Zebulon Pike, or the courage of Thomas Freeman or Peter Custis.  All these men deserve their fifteen minutes of fame, and Fenster delivers a fast-paced narrative to tell the more complete story of a young America restless to explore and dominate its western boundaries.  If it hadn't been for the expense of the Napoleonic wars in western Europe, France and Spain may have had different visions of their mission in the New World.\n",
            "\n",
            "For those who are well-versed in the L&C expedition, it's well-known among those scholars that Lewis and Clark were not the first white men to traverse\n",
            "the Missouri River.  There were many French trappers and a few lone Spaniards who had made contact with the native tribes, and who unknowingly spread communicable diseases to these vulnerable people and decimated entire villages.  Fenster tries to bring this into perspective here, as L&C did not meet any hostile natives until they came among the Mandan.  Entire villages south of them were abandoned due to diseases the white settlers had brought to the region.\n",
            "\n",
            "This is a very readable narrative of Jefferson's goal to get the western lands explored.  There are a lot of names dropped early on to give the curious reader a perspective.  Spain and the young United States almost went to war over the status of New Orleans and the Louisiana territory, but the Napoleonic wars sidetracked the kings in Europe.  Many of the explorers in this book fall along the wayside in American history, but Fenster gives credit to all these men and help the history buff see that L&C were not the only expedition exploring unchartered waters.\n",
            "Tokenized:  ['I', 'Ġhave', 'Ġalways', 'Ġbeen', 'Ġa', 'Ġfan', 'Ġof', 'Ġthe', 'ĠLewis', 'Ġand', 'ĠClark', 'Ġ(', 'L', '&', 'C', ')', 'Ġexpedition', 'Ġand', 'Ġhave', 'Ġread', 'Ġnumerous', 'Ġbooks', 'Ġon', 'Ġthat', 'Ġera', '.', 'Ġ', 'ĠI', 'Ġeven', 'Ġroad', 'Ġtri', 'pped', 'Ġalong', 'Ġthe', 'ĠMissouri', 'ĠRiver', 'Ġto', 'Ġthe', 'Ġriver', \"'s\", 'Ġsource', 'Ġin', 'ĠMontana', 'Ġ(', 'by', 'pass', 'ing', 'ĠNorth', 'ĠDakota', 'Ġand', 'Ġeastern', 'ĠMontana', 'Ġdue', 'Ġto', 'Ġrepeated', 'Ġtorn', 'adoes', 'Ġthat', 'Ġsummer', '),', 'Ġstopping', 'Ġalong', 'Ġall', 'Ġthe', 'Ġhistorical', 'Ġsigns', '.', 'Ġ', 'ĠI', \"'m\", 'Ġa', 'Ġfan', 'Ġbecause', 'ĠI', 'Ġunderstand', 'Ġthe', 'Ġcourage', 'Ġit', 'Ġtook', 'Ġto', 'Ġexplore', 'Ġunknown', 'Ġlands', 'Ġwith', 'Ġpotential', 'Ġviolent', 'Ġinhabitants', ',', 'Ġbut', 'ĠI', 'Ġalso', 'Ġunderstand', 'Ġthe', 'Ġsignificance', 'Ġof', 'ĠAmerican', 'Ġexpansion', 'Ġto', 'Ġthe', 'ĠPacific', 'Ġvia', 'Ġthe', 'ĠNorthwest', 'Ġpassage', '.', 'Ġ', 'ĠOpening', 'Ġup', 'Ġthese', 'Ġlands', 'Ġis', 'Ġone', 'Ġof', 'ĠJefferson', \"'s\", 'Ġbiggest', 'Ġleg', 'acies', 'Ġas', 'Ġpresident', '.', 'Ċ', 'Ċ', 'What', 'ĠJulie', 'ĠFen', 'ster', 'Ġdoes', 'Ġhere', 'Ġis', 'Ġnot', 'Ġjust', 'Ġsummarize', 'Ġthe', 'ĠL', '&', 'C', 'Ġexpedition', ',', 'Ġthough', '.', 'Ġ', 'ĠShe', 'Ġdescribes', 'Ġthe', 'Ġyoung', 'ĠAmerica', 'Ġat', 'Ġthe', 'Ġturn', 'Ġof', 'Ġthe', 'Ġ19', 'th', 'Ġcentury', '.', 'Ġ', 'ĠPione', 'ers', 'Ġwere', 'Ġmoving', 'Ġwest', 'ward', ',', 'Ġbut', 'ĠSpain', 'Ġcontrolled', 'Ġthe', 'Ġwestern', 'Ġlands', '.', 'ĠShe', 'Ġgives', 'Ġshort', 'Ġbi', 'ographies', 'Ġof', 'Ġthe', 'Ġplayers', ',', 'Ġthe', 'Ġgovernors', ',', 'Ġkings', 'Ġand', 'Ġexplorers', 'Ġof', 'Ġthe', 'Ġera', '.', 'Ġ', 'ĠIt', 'Ġwas', 'Ġa', 'Ġtime', 'Ġof', 'Ġgreat', 'Ġhostilities', '.', 'Ġ', 'ĠFen', 'ster', 'Ġportrays', 'ĠJefferson', 'Ġas', 'Ġa', 'Ġman', 'Ġfighting', 'Ġoff', 'Ġthe', 'ĠJohn', 'ĠAdams', 'Ġsupporters', ';', 'Ġall', 'Ġwas', 'Ġnot', 'Ġgoing', 'Ġso', 'Ġwell', 'Ġfor', 'ĠJefferson', 'Ġwhen', 'Ġhe', 'Ġfirst', 'Ġbecame', 'Ġpresident', '.', 'Ċ', 'Ċ', 'What', 'Ġreaders', 'Ġget', 'Ġout', 'Ġof', 'Ġthis', 'Ġvery', 'Ġreadable', 'Ġaccount', 'Ġis', 'Ġthat', 'Ġthe', 'ĠL', '&', 'C', 'Ġexpedition', 'Ġwas', 'Ġnot', 'Ġthe', 'Ġonly', 'Ġexpedition', 'Ġgoing', 'Ġon', 'Ġat', 'Ġthe', 'Ġtime', '.', 'Ġ', 'ĠIt', \"'s\", 'Ġinteresting', 'Ġto', 'Ġnote', 'Ġthat', 'Ġthere', 'Ġwere', 'Ġother', 'Ġcourageous', 'Ġexplorers', 'Ġwilling', 'Ġto', 'Ġreport', 'Ġback', 'Ġto', 'ĠJefferson', 'Ġwhat', 'Ġthe', 'ĠSpanish', '-', 'held', 'Ġlands', 'Ġwere', 'Ġlike', ',', 'Ġand', 'ĠFen', 'ster', 'Ġdescribes', 'Ġthese', 'Ġin', 'Ġrelation', 'Ġto', 'Ġthe', 'ĠL', '&', 'C', 'Ġexpedition', 'Ġ', 'ĠThe', 'ĠHunter', 'Ġ&', 'ĠDun', 'bar', 'Ġexpedition', 'Ġwas', 'Ġas', 'Ġvaluable', 'Ġto', 'ĠJefferson', 'Ġas', 'Ġthe', 'ĠL', '&', 'C', 'Ġone', 'Ġwas', ',', 'Ġor', 'Ġthe', 'Ġoft', '-', 'pl', 'ag', 'ued', 'Ġexpedition', 'Ġof', 'ĠZ', 'eb', 'ul', 'on', 'ĠPike', ',', 'Ġor', 'Ġthe', 'Ġcourage', 'Ġof', 'ĠThomas', 'ĠFreeman', 'Ġor', 'ĠPeter', 'ĠCust', 'is', '.', 'Ġ', 'ĠAll', 'Ġthese', 'Ġmen', 'Ġdeserve', 'Ġtheir', 'Ġfifteen', 'Ġminutes', 'Ġof', 'Ġfame', ',', 'Ġand', 'ĠFen', 'ster', 'Ġdelivers', 'Ġa', 'Ġfast', '-', 'paced', 'Ġnarrative', 'Ġto', 'Ġtell', 'Ġthe', 'Ġmore', 'Ġcomplete', 'Ġstory', 'Ġof', 'Ġa', 'Ġyoung', 'ĠAmerica', 'Ġrestless', 'Ġto', 'Ġexplore', 'Ġand', 'Ġdominate', 'Ġits', 'Ġwestern', 'Ġboundaries', '.', 'Ġ', 'ĠIf', 'Ġit', 'Ġhadn', \"'t\", 'Ġbeen', 'Ġfor', 'Ġthe', 'Ġexpense', 'Ġof', 'Ġthe', 'ĠNap', 'ole', 'onic', 'Ġwars', 'Ġin', 'Ġwestern', 'ĠEurope', ',', 'ĠFrance', 'Ġand', 'ĠSpain', 'Ġmay', 'Ġhave', 'Ġhad', 'Ġdifferent', 'Ġvisions', 'Ġof', 'Ġtheir', 'Ġmission', 'Ġin', 'Ġthe', 'ĠNew', 'ĠWorld', '.', 'Ċ', 'Ċ', 'For', 'Ġthose', 'Ġwho', 'Ġare', 'Ġwell', '-', 'vers', 'ed', 'Ġin', 'Ġthe', 'ĠL', '&', 'C', 'Ġexpedition', ',', 'Ġit', \"'s\", 'Ġwell', '-', 'known', 'Ġamong', 'Ġthose', 'Ġscholars', 'Ġthat', 'ĠLewis', 'Ġand', 'ĠClark', 'Ġwere', 'Ġnot', 'Ġthe', 'Ġfirst', 'Ġwhite', 'Ġmen', 'Ġto', 'Ġtraverse', 'Ċ', 'the', 'ĠMissouri', 'ĠRiver', '.', 'Ġ', 'ĠThere', 'Ġwere', 'Ġmany', 'ĠFrench', 'Ġtra', 'ppers', 'Ġand', 'Ġa', 'Ġfew', 'Ġlone', 'ĠSpani', 'ards', 'Ġwho', 'Ġhad', 'Ġmade', 'Ġcontact', 'Ġwith', 'Ġthe', 'Ġnative', 'Ġtribes', ',', 'Ġand', 'Ġwho', 'Ġunknow', 'ingly', 'Ġspread', 'Ġcommun', 'icable', 'Ġdiseases', 'Ġto', 'Ġthese', 'Ġvulnerable', 'Ġpeople', 'Ġand', 'Ġdec', 'imated', 'Ġentire', 'Ġvillages', '.', 'Ġ', 'ĠFen', 'ster', 'Ġtries', 'Ġto', 'Ġbring', 'Ġthis', 'Ġinto', 'Ġperspective', 'Ġhere', ',', 'Ġas', 'ĠL', '&', 'C', 'Ġdid', 'Ġnot', 'Ġmeet', 'Ġany', 'Ġhostile', 'Ġnatives', 'Ġuntil', 'Ġthey', 'Ġcame', 'Ġamong', 'Ġthe', 'ĠMand', 'an', '.', 'Ġ', 'ĠEnt', 'ire', 'Ġvillages', 'Ġsouth', 'Ġof', 'Ġthem', 'Ġwere', 'Ġabandoned', 'Ġdue', 'Ġto', 'Ġdiseases', 'Ġthe', 'Ġwhite', 'Ġsettlers', 'Ġhad', 'Ġbrought', 'Ġto', 'Ġthe', 'Ġregion', '.', 'Ċ', 'Ċ', 'This', 'Ġis', 'Ġa', 'Ġvery', 'Ġreadable', 'Ġnarrative', 'Ġof', 'ĠJefferson', \"'s\", 'Ġgoal', 'Ġto', 'Ġget', 'Ġthe', 'Ġwestern', 'Ġlands', 'Ġexplored', '.', 'Ġ', 'ĠThere', 'Ġare', 'Ġa', 'Ġlot', 'Ġof', 'Ġnames', 'Ġdropped', 'Ġearly', 'Ġon', 'Ġto', 'Ġgive', 'Ġthe', 'Ġcurious', 'Ġreader', 'Ġa', 'Ġperspective', '.', 'Ġ', 'ĠSpain', 'Ġand', 'Ġthe', 'Ġyoung', 'ĠUnited', 'ĠStates', 'Ġalmost', 'Ġwent', 'Ġto', 'Ġwar', 'Ġover', 'Ġthe', 'Ġstatus', 'Ġof', 'ĠNew', 'ĠOrleans', 'Ġand', 'Ġthe', 'ĠLouisiana', 'Ġterritory', ',', 'Ġbut', 'Ġthe', 'ĠNap', 'ole', 'onic', 'Ġwars', 'Ġsid', 'etr', 'acked', 'Ġthe', 'Ġkings', 'Ġin', 'ĠEurope', '.', 'Ġ', 'ĠMany', 'Ġof', 'Ġthe', 'Ġexplorers', 'Ġin', 'Ġthis', 'Ġbook', 'Ġfall', 'Ġalong', 'Ġthe', 'Ġways', 'ide', 'Ġin', 'ĠAmerican', 'Ġhistory', ',', 'Ġbut', 'ĠFen', 'ster', 'Ġgives', 'Ġcredit', 'Ġto', 'Ġall', 'Ġthese', 'Ġmen', 'Ġand', 'Ġhelp', 'Ġthe', 'Ġhistory', 'Ġbuff', 'Ġsee', 'Ġthat', 'ĠL', '&', 'C', 'Ġwere', 'Ġnot', 'Ġthe', 'Ġonly', 'Ġexpedition', 'Ġexploring', 'Ġunch', 'art', 'ered', 'Ġwaters', '.']\n",
            "Token IDs:  [100, 33, 460, 57, 10, 2378, 9, 5, 3577, 8, 4433, 36, 574, 947, 347, 43, 25512, 8, 33, 1166, 3617, 2799, 15, 14, 3567, 4, 1437, 38, 190, 921, 7182, 5686, 552, 5, 4630, 1995, 7, 5, 4908, 18, 1300, 11, 8920, 36, 1409, 10212, 154, 369, 6223, 8, 4580, 8920, 528, 7, 6636, 9007, 24263, 14, 1035, 238, 8197, 552, 70, 5, 4566, 2434, 4, 1437, 38, 437, 10, 2378, 142, 38, 1346, 5, 9699, 24, 362, 7, 5393, 4727, 8952, 19, 801, 4153, 24696, 6, 53, 38, 67, 1346, 5, 11382, 9, 470, 2919, 7, 5, 3073, 1241, 5, 8535, 9078, 4, 1437, 14491, 62, 209, 8952, 16, 65, 9, 9033, 18, 934, 2985, 15668, 25, 394, 4, 50118, 50118, 2264, 9786, 15615, 3121, 473, 259, 16, 45, 95, 40402, 5, 226, 947, 347, 25512, 6, 600, 4, 1437, 264, 7448, 5, 664, 730, 23, 5, 1004, 9, 5, 753, 212, 3220, 4, 1437, 34562, 268, 58, 1375, 3072, 7767, 6, 53, 2809, 4875, 5, 4669, 8952, 4, 264, 2029, 765, 4003, 24015, 9, 5, 472, 6, 5, 12066, 6, 31820, 8, 38897, 9, 5, 3567, 4, 1437, 85, 21, 10, 86, 9, 372, 30519, 4, 1437, 15615, 3121, 29565, 9033, 25, 10, 313, 2190, 160, 5, 610, 5710, 2732, 131, 70, 21, 45, 164, 98, 157, 13, 9033, 77, 37, 78, 1059, 394, 4, 50118, 50118, 2264, 5360, 120, 66, 9, 42, 182, 44680, 1316, 16, 14, 5, 226, 947, 347, 25512, 21, 45, 5, 129, 25512, 164, 15, 23, 5, 86, 4, 1437, 85, 18, 2679, 7, 1591, 14, 89, 58, 97, 24219, 38897, 2882, 7, 266, 124, 7, 9033, 99, 5, 3453, 12, 11706, 8952, 58, 101, 6, 8, 15615, 3121, 7448, 209, 11, 9355, 7, 5, 226, 947, 347, 25512, 1437, 20, 7126, 359, 6367, 4901, 25512, 21, 25, 5130, 7, 9033, 25, 5, 226, 947, 347, 65, 21, 6, 50, 5, 24453, 12, 2911, 1073, 6796, 25512, 9, 525, 3209, 922, 261, 20859, 6, 50, 5, 9699, 9, 1813, 11460, 50, 2155, 37513, 354, 4, 1437, 404, 209, 604, 6565, 49, 23843, 728, 9, 9444, 6, 8, 15615, 3121, 8806, 10, 1769, 12, 20764, 7122, 7, 1137, 5, 55, 1498, 527, 9, 10, 664, 730, 36844, 7, 5393, 8, 11781, 63, 4669, 10156, 4, 1437, 318, 24, 5844, 75, 57, 13, 5, 5623, 9, 5, 7645, 4104, 10003, 9425, 11, 4669, 1005, 6, 1470, 8, 2809, 189, 33, 56, 430, 28420, 9, 49, 2511, 11, 5, 188, 623, 4, 50118, 50118, 2709, 167, 54, 32, 157, 12, 3697, 196, 11, 5, 226, 947, 347, 25512, 6, 24, 18, 157, 12, 6421, 566, 167, 18118, 14, 3577, 8, 4433, 58, 45, 5, 78, 1104, 604, 7, 40660, 50118, 627, 4630, 1995, 4, 1437, 345, 58, 171, 1515, 8419, 14403, 8, 10, 367, 10801, 14703, 5954, 54, 56, 156, 1511, 19, 5, 3763, 17116, 6, 8, 54, 36756, 7790, 2504, 16759, 26092, 6357, 7, 209, 4478, 82, 8, 5044, 24985, 1445, 9365, 4, 1437, 15615, 3121, 5741, 7, 836, 42, 88, 4263, 259, 6, 25, 226, 947, 347, 222, 45, 972, 143, 11928, 33616, 454, 51, 376, 566, 5, 10682, 260, 4, 1437, 9860, 1885, 9365, 2077, 9, 106, 58, 6978, 528, 7, 6357, 5, 1104, 27258, 56, 1146, 7, 5, 976, 4, 50118, 50118, 713, 16, 10, 182, 44680, 7122, 9, 9033, 18, 724, 7, 120, 5, 4669, 8952, 16217, 4, 1437, 345, 32, 10, 319, 9, 2523, 1882, 419, 15, 7, 492, 5, 10691, 10746, 10, 4263, 4, 1437, 2809, 8, 5, 664, 315, 532, 818, 439, 7, 997, 81, 5, 2194, 9, 188, 4942, 8, 5, 5993, 4284, 6, 53, 5, 7645, 4104, 10003, 9425, 16742, 17985, 10074, 5, 31820, 11, 1005, 4, 1437, 1876, 9, 5, 38897, 11, 42, 1040, 1136, 552, 5, 1319, 1949, 11, 470, 750, 6, 53, 15615, 3121, 2029, 1361, 7, 70, 209, 604, 8, 244, 5, 750, 27793, 192, 14, 226, 947, 347, 58, 45, 5, 129, 25512, 8668, 27433, 2013, 3215, 5794, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6LWSQnh-UGQn"
      },
      "outputs": [],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for s in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        s,                      # Sentence to encode.\n",
        "                        truncation=True,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94sqHr36CdtB",
        "outputId": "666d4676-c412-45b2-e876-b05d8b3a4e9e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    0,   100,    33,   460,    57,    10,  2378,     9,     5,  3577,\n",
              "            8,  4433,    36,   574,   947,   347,    43, 25512,     8,    33,\n",
              "         1166,  3617,  2799,    15,    14,  3567,     4,  1437,    38,   190,\n",
              "          921,  7182,  5686,   552,     5,  4630,  1995,     7,     5,  4908,\n",
              "           18,  1300,    11,  8920,    36,  1409, 10212,   154,   369,  6223,\n",
              "            8,  4580,  8920,   528,     7,  6636,  9007, 24263,    14,  1035,\n",
              "          238,  8197,   552,    70,     5,  4566,  2434,     4,  1437,    38,\n",
              "          437,    10,  2378,   142,    38,  1346,     5,  9699,    24,   362,\n",
              "            7,  5393,  4727,  8952,    19,   801,  4153, 24696,     6,    53,\n",
              "           38,    67,  1346,     5, 11382,     9,   470,  2919,     7,     5,\n",
              "         3073,  1241,     5,  8535,  9078,     4,  1437, 14491,    62,   209,\n",
              "         8952,    16,    65,     9,  9033,    18,   934,  2985, 15668,    25,\n",
              "          394,     4, 50118, 50118,  2264,  9786, 15615,  3121,   473,   259,\n",
              "           16,    45,    95, 40402,     5,   226,   947,   347, 25512,     6,\n",
              "          600,     4,  1437,   264,  7448,     5,   664,   730,    23,     5,\n",
              "         1004,     9,     5,   753,   212,  3220,     4,  1437, 34562,   268,\n",
              "           58,  1375,  3072,  7767,     6,    53,  2809,  4875,     5,  4669,\n",
              "         8952,     4,   264,  2029,   765,  4003, 24015,     9,     5,   472,\n",
              "            6,     5, 12066,     6, 31820,     8, 38897,     9,     5,  3567,\n",
              "            4,  1437,    85,    21,    10,    86,     9,   372, 30519,     4,\n",
              "         1437, 15615,  3121, 29565,  9033,    25,    10,   313,  2190,   160,\n",
              "            5,   610,  5710,  2732,   131,    70,    21,    45,   164,    98,\n",
              "          157,    13,  9033,    77,    37,    78,  1059,   394,     4, 50118,\n",
              "        50118,  2264,  5360,   120,    66,     9,    42,   182, 44680,  1316,\n",
              "           16,    14,     5,   226,   947,   347, 25512,    21,    45,     5,\n",
              "          129, 25512,   164,    15,    23,     5,    86,     4,  1437,    85,\n",
              "           18,  2679,     7,  1591,    14,    89,    58,    97, 24219, 38897,\n",
              "         2882,     7,   266,   124,     7,  9033,    99,     5,  3453,    12,\n",
              "        11706,  8952,    58,   101,     6,     8, 15615,  3121,  7448,   209,\n",
              "           11,  9355,     7,     5,   226,   947,   347, 25512,  1437,    20,\n",
              "         7126,   359,  6367,  4901, 25512,    21,    25,  5130,     7,  9033,\n",
              "           25,     5,   226,   947,   347,    65,    21,     6,    50,     5,\n",
              "        24453,    12,  2911,  1073,  6796, 25512,     9,   525,  3209,   922,\n",
              "          261, 20859,     6,    50,     5,  9699,     9,  1813, 11460,    50,\n",
              "         2155, 37513,   354,     4,  1437,   404,   209,   604,  6565,    49,\n",
              "        23843,   728,     9,  9444,     6,     8, 15615,  3121,  8806,    10,\n",
              "         1769,    12, 20764,  7122,     7,  1137,     5,    55,  1498,   527,\n",
              "            9,    10,   664,   730, 36844,     7,  5393,     8, 11781,    63,\n",
              "         4669, 10156,     4,  1437,   318,    24,  5844,    75,    57,    13,\n",
              "            5,  5623,     9,     5,  7645,  4104, 10003,  9425,    11,  4669,\n",
              "         1005,     6,  1470,     8,  2809,   189,    33,    56,   430, 28420,\n",
              "            9,    49,  2511,    11,     5,   188,   623,     4, 50118, 50118,\n",
              "         2709,   167,    54,    32,   157,    12,  3697,   196,    11,     5,\n",
              "          226,   947,   347, 25512,     6,    24,    18,   157,    12,  6421,\n",
              "          566,   167, 18118,    14,  3577,     8,  4433,    58,    45,     5,\n",
              "           78,  1104,   604,     7, 40660, 50118,   627,  4630,  1995,     4,\n",
              "         1437,   345,    58,   171,  1515,  8419, 14403,     8,    10,   367,\n",
              "        10801, 14703,  5954,    54,    56,   156,  1511,    19,     5,  3763,\n",
              "        17116,     6,     8,    54, 36756,  7790,  2504, 16759, 26092,  6357,\n",
              "            7,   209,  4478,    82,     8,  5044, 24985,  1445,  9365,     4,\n",
              "         1437, 15615,  3121,  5741,     7,   836,    42,    88,  4263,   259,\n",
              "            6,     2])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlyteN-zJGuU",
        "outputId": "6af65169-aacf-4b70-fe9f-f3ee8157f652"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vPrzId6-VHRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824b85dd-4605-49f5-d5a1-f23b9de7f0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44,970 training samples\n",
            "4,997 validation samples\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "S28rl4_sW-Tg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForSequenceClassification,BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 100, # The number of output labels--2 for binary classification.\n",
        "             # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f813b126a8d49708c6b57cdd7ea083e",
            "5d578b958e744234960b086ef7382c14",
            "d357520ec4aa40e590501bf3692baa34",
            "d4b30545da0e449cbbd8ecd54011436f",
            "9ddbd777132b42fc8c9018bc8b97e993",
            "66200ad9979e464b960cdce71c7dd1af",
            "e532244c360347e0bfb95d048542fa3c",
            "04d805bfdf75454c9632f80a4f89989c",
            "1cc9e0538484445d959e31d448ade76d",
            "a86083ab57c845648deba87a7b7c39a5",
            "19f810c703684ad9835a12253a0d48b8"
          ]
        },
        "id": "FFC8OPPtXj-o",
        "outputId": "dd064c3e-1ee7-42bc-d67a-ca08559052f1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f813b126a8d49708c6b57cdd7ea083e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=100, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyfOCEN1Xryv",
        "outputId": "ef674866-faee-4d77-a714-0645f0b3214f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "#total_steps = len(train_dataloader) * epochs\n",
        "gradient_accumulation_steps=1\n",
        "n_gpu=1\n",
        "#total_steps= ((len(train_dataloader) // (batch_size * max(1, n_gpu)))// gradient_accumulation_steps* float(epochs))\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "0w5GFlvKYPSt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "Kw9o2H90ZOV6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "ETl2dVFAZRQ9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "       \n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "        \n",
        " \n",
        "\n",
        " \n",
        "        loss = result.loss\n",
        "\n",
        "        logits = result.logits\n",
        "        print(\"logits : \",logits)\n",
        "        print(len(logits))\n",
        "        \n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX-FmXpBZfoX",
        "outputId": "fca31550-38c0-4d98-e321-59f9a4dec864"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16\n",
            "logits :  tensor([[-8.6470e-01, -9.6667e-01,  3.5705e-01,  ..., -5.8946e-01,\n",
            "         -1.0955e+00, -1.1073e+00],\n",
            "        [-4.2590e-01, -4.6796e-01,  2.9121e-01,  ..., -6.6057e-01,\n",
            "          1.0148e-01, -6.1516e-01],\n",
            "        [ 2.1697e+00, -3.0648e-01, -1.1989e+00,  ..., -3.7410e-01,\n",
            "         -1.6134e+00, -1.1925e+00],\n",
            "        ...,\n",
            "        [ 1.1060e-01, -5.7789e-01, -4.9495e-01,  ...,  9.3414e-01,\n",
            "          2.8554e-01, -2.4390e-01],\n",
            "        [-1.2996e+00,  2.3271e-01,  3.8709e-01,  ..., -2.8812e-01,\n",
            "          1.6986e-01,  1.4058e+00],\n",
            "        [ 1.1526e-03, -5.4275e-01,  6.3928e-02,  ..., -1.1929e+00,\n",
            "         -1.2240e+00, -6.9519e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3962, -0.9419, -0.5872,  ...,  0.2050,  1.5292, -0.9430],\n",
            "        [-0.3858, -0.0749,  0.0287,  ..., -1.4395, -0.2531, -0.1694],\n",
            "        [ 1.6980,  0.1641,  1.1625,  ...,  0.5478, -1.2901,  0.8336],\n",
            "        ...,\n",
            "        [-0.3634, -1.0160, -1.2479,  ...,  0.7343,  2.4797, -0.7088],\n",
            "        [-1.0516, -0.6657, -1.5059,  ...,  0.5864,  2.6698, -1.0563],\n",
            "        [-0.0851,  1.6305,  1.2931,  ..., -0.7351,  1.2989,  0.8992]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0584,  0.0358, -0.3632,  ..., -0.9165,  2.1498, -0.0510],\n",
            "        [-0.5896, -0.9023, -0.5196,  ...,  0.8024,  1.9985, -0.2532],\n",
            "        [ 0.6037,  0.5676, -1.3039,  ..., -0.7330,  0.3866, -0.8635],\n",
            "        ...,\n",
            "        [-0.9449, -1.0876, -1.3518,  ..., -0.5419, -0.3621, -1.0195],\n",
            "        [-0.9591, -0.1812,  0.0061,  ..., -0.1941,  0.0468, -0.1544],\n",
            "        [ 2.9366,  1.4664,  0.5869,  ...,  0.7965, -1.2664, -1.2580]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3106, -0.3000, -1.5209,  ...,  2.4179, -0.1240,  1.2277],\n",
            "        [-0.7821,  0.2157, -0.1370,  ...,  0.4573,  6.8189, -0.1774],\n",
            "        [ 0.8807, -1.3885,  0.5778,  ..., -0.9353, -0.6942, -0.1863],\n",
            "        ...,\n",
            "        [-1.0051, -0.5361,  0.1626,  ..., -0.8610, -0.5793,  0.6412],\n",
            "        [ 0.2983,  0.3383, -0.0762,  ..., -0.6688,  0.2428, -0.4228],\n",
            "        [ 0.9260,  1.0759, -0.4259,  ...,  0.5328,  1.1962,  0.3143]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-4.8724e-01, -1.0763e-01, -1.0306e-01,  ...,  5.6781e-02,\n",
            "          5.3924e+00,  5.7354e-01],\n",
            "        [ 3.3708e-01, -1.0329e+00,  7.1479e-01,  ..., -9.2645e-01,\n",
            "         -4.6075e-01,  3.1473e-01],\n",
            "        [ 4.2499e-01,  3.6188e-02,  5.8465e-01,  ...,  4.0472e-01,\n",
            "         -1.6379e+00,  8.2738e-01],\n",
            "        ...,\n",
            "        [-7.0425e-01,  2.2424e-01, -1.8032e-01,  ..., -8.2805e-01,\n",
            "         -5.3828e-01, -9.9579e-01],\n",
            "        [-1.9696e-01, -8.8329e-01, -1.5283e+00,  ...,  2.6999e-01,\n",
            "          6.0288e-01, -5.3213e-01],\n",
            "        [-8.5323e-01,  1.2427e-01, -3.9453e-03,  ..., -8.1316e-01,\n",
            "          1.0934e+00, -7.1342e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 5.0109,  0.4061, -0.5900,  ...,  0.8206, -1.5159, -1.1537],\n",
            "        [-1.3497, -0.4385, -0.2231,  ..., -0.5764,  1.2967, -0.5176],\n",
            "        [-0.3181, -0.6186,  1.5087,  ..., -1.0942, -0.7339, -0.7973],\n",
            "        ...,\n",
            "        [-0.4694, -0.3374,  0.1884,  ..., -0.2642,  0.7853, -0.0218],\n",
            "        [-0.6326, -0.2682,  0.8692,  ...,  0.4876,  0.5796,  1.5688],\n",
            "        [-0.2241, -1.0596, -0.3031,  ..., -0.1296, -1.1712,  0.6472]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3561,  0.7683,  0.8255,  ..., -1.3376, -0.4810,  0.2174],\n",
            "        [-0.3623,  0.1736, -0.4347,  ..., -0.7362,  2.8548,  0.2759],\n",
            "        [ 0.4012,  1.1118,  0.2149,  ...,  0.0092,  1.1780,  0.7886],\n",
            "        ...,\n",
            "        [-0.1271,  0.7232, -0.3447,  ..., -0.4066,  2.3906, -0.0243],\n",
            "        [-0.8351,  0.6842,  0.8658,  ..., -1.2177, -0.2701,  0.3675],\n",
            "        [-0.7020, -1.5442,  0.8366,  ..., -1.0465, -0.8200,  0.4967]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,320  of  2,811.    Elapsed: 1:01:00.\n",
            "logits :  tensor([[-0.5043,  0.2347, -0.1573,  ...,  0.7514, -0.3525,  0.0541],\n",
            "        [-0.1923, -0.5685, -0.1630,  ..., -0.5873, -0.6757, -0.3197],\n",
            "        [ 2.8986, -0.1770, -1.1329,  ...,  1.0359, -1.4304, -0.8665],\n",
            "        ...,\n",
            "        [-0.6669,  0.2678,  0.0340,  ...,  0.2208, -0.1351,  0.1894],\n",
            "        [-0.5816, -1.0115,  0.0709,  ..., -0.2390, -0.2448,  0.4596],\n",
            "        [-0.4687,  0.3215, -0.7098,  ...,  1.3055, -1.0539,  1.0848]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4953,  0.5564,  0.6660,  ..., -1.3119,  0.9544, -0.3581],\n",
            "        [ 0.2909,  0.0811, -1.1006,  ...,  1.1907, -0.7730, -0.2386],\n",
            "        [-0.1655,  0.3546,  0.1262,  ..., -0.9183, -0.1876,  0.1515],\n",
            "        ...,\n",
            "        [ 0.8835,  0.3929, -1.8682,  ...,  6.7375, -0.2071,  1.3939],\n",
            "        [ 0.9363,  0.7310, -0.8414,  ..., -0.1178,  0.0324, -0.5291],\n",
            "        [ 0.7356,  0.9221,  0.6392,  ...,  1.0596, -0.4356, -0.2518]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6551, -0.3830, -1.5009,  ...,  0.8298, -0.5582, -0.3722],\n",
            "        [-0.2696, -0.8429,  0.5789,  ..., -0.5512, -0.7804, -0.8003],\n",
            "        [-1.0209, -1.3172,  0.1512,  ..., -1.3084, -0.8572, -0.4750],\n",
            "        ...,\n",
            "        [ 1.3253,  0.1365, -0.7825,  ..., -0.2470, -0.5300, -0.6994],\n",
            "        [ 0.2111,  2.8060,  0.4569,  ..., -0.6149, -0.8912,  0.1625],\n",
            "        [-0.4140, -0.4523, -0.7452,  ..., -0.5876, -0.2018, -0.8402]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7300, -0.5992, -0.7853,  ...,  0.4514, -0.2553, -0.9103],\n",
            "        [-0.1595,  1.1361, -0.1377,  ..., -0.3004,  0.3257, -0.2370],\n",
            "        [-0.2923, -0.0330, -0.1833,  ..., -0.1627,  0.3260,  0.1774],\n",
            "        ...,\n",
            "        [ 1.6939,  0.3073, -1.1122,  ...,  0.5296, -0.0489, -0.6990],\n",
            "        [-0.3951,  1.1592,  0.3663,  ..., -0.1481,  1.4144,  0.3947],\n",
            "        [-0.5945, -0.0780,  1.8654,  ..., -0.8780, -0.4716,  1.0469]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1008, -0.5960, -0.3992,  ..., -0.8033, -0.1906, -0.8009],\n",
            "        [-0.1582, -0.7437,  0.8988,  ..., -0.6899,  1.1451,  0.4999],\n",
            "        [-1.0736, -1.3096, -0.1699,  ...,  0.5875,  1.3602, -0.5903],\n",
            "        ...,\n",
            "        [ 2.4148, -0.8517,  0.4816,  ...,  0.3375, -0.6784, -1.0731],\n",
            "        [-0.3086,  1.3057, -0.0401,  ..., -0.8631,  0.3054, -0.2685],\n",
            "        [ 2.7498,  1.3048,  2.0613,  ...,  0.3717, -1.6049,  0.0040]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9716, -0.4545,  1.5201,  ..., -1.1460, -0.8871,  0.4591],\n",
            "        [-0.3650,  1.0127, -0.5591,  ..., -0.4164,  0.2264, -0.5617],\n",
            "        [-1.1156, -1.1292,  0.3312,  ..., -0.2596,  0.8377, -0.5484],\n",
            "        ...,\n",
            "        [ 1.5179,  0.6432, -0.8448,  ...,  0.7451, -0.2383,  0.2528],\n",
            "        [-0.0880,  0.3614,  0.1475,  ...,  0.3542,  0.6789,  0.5469],\n",
            "        [-0.4299, -1.2339, -1.0428,  ...,  0.2291,  2.0678, -0.0335]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0618, -0.9852, -0.8813,  ...,  0.2513, -1.2331,  0.3705],\n",
            "        [ 0.7357,  0.1098, -1.3879,  ..., -0.0640,  0.4491, -0.5161],\n",
            "        [-0.7262,  0.7138,  0.0243,  ...,  0.0544,  0.3532,  1.3033],\n",
            "        ...,\n",
            "        [-0.4996, -0.4935,  0.1214,  ..., -0.3121,  0.0586, -0.7100],\n",
            "        [-0.5680, -0.3720,  0.4242,  ..., -1.5334, -0.2063, -0.0960],\n",
            "        [ 1.3919, -0.0751,  0.5748,  ..., -0.4736, -1.1192, -0.9868]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.2487e+00,  2.2398e-02,  3.2827e-01,  ..., -1.0811e+00,\n",
            "         -3.1498e-01, -4.3568e-01],\n",
            "        [-5.3192e-01,  6.3402e-02,  3.5200e-01,  ..., -3.3450e-01,\n",
            "          5.8731e-01, -5.6729e-01],\n",
            "        [-2.1377e-01, -6.6009e-02, -2.3916e-01,  ..., -1.1356e+00,\n",
            "         -5.7171e-01, -7.2712e-01],\n",
            "        ...,\n",
            "        [-7.2752e-01, -9.7252e-02, -7.5561e-01,  ...,  2.6937e+00,\n",
            "          1.2615e+00,  3.0599e+00],\n",
            "        [-8.8635e-01, -6.8754e-01,  4.7996e-01,  ..., -1.3266e+00,\n",
            "         -1.5976e+00, -7.2581e-01],\n",
            "        [-3.4082e-01, -1.9177e-01, -3.4673e-03,  ...,  7.8864e-01,\n",
            "         -6.8952e-01,  4.8416e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0752, -0.1644,  0.5921,  ..., -0.7224,  0.6637, -0.2764],\n",
            "        [ 2.3465,  0.7978,  1.2852,  ...,  0.5313, -0.8517,  0.3008],\n",
            "        [ 2.1331,  1.1805,  1.3765,  ...,  0.4695, -1.6653,  0.1450],\n",
            "        ...,\n",
            "        [-0.0329, -0.9628,  3.2414,  ..., -1.1842, -0.8796,  0.6950],\n",
            "        [ 0.6120,  0.6941,  1.6290,  ..., -0.6344, -0.0148, -0.3756],\n",
            "        [-0.8054, -0.1383, -1.0393,  ...,  0.9092, -0.7897,  1.2282]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.1293, -0.0068, -1.7675,  ...,  2.6667, -0.4903, -0.6051],\n",
            "        [-1.4498, -1.0946, -0.8514,  ..., -0.9370, -1.1108, -1.4479],\n",
            "        [ 0.3090, -0.0164, -0.7329,  ...,  0.6843, -0.6089,  0.1252],\n",
            "        ...,\n",
            "        [ 1.0254, -0.6866,  1.5391,  ..., -0.3450, -0.6518, -0.7892],\n",
            "        [ 1.9322, -1.0248,  0.3520,  ..., -0.8719, -0.9651, -0.6324],\n",
            "        [-0.0196, -0.9209, -0.1649,  ..., -0.1787,  0.9492, -1.0303]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5174,  0.9883,  0.5040,  ...,  0.0271,  1.8102, -0.0811],\n",
            "        [ 0.5048,  6.1492,  1.6259,  ..., -0.0262, -0.2742,  0.8365],\n",
            "        [-0.5066, -1.0223, -0.0835,  ..., -0.3332,  1.8114, -0.2238],\n",
            "        ...,\n",
            "        [-0.3600, -1.0396, -0.3048,  ..., -0.7957, -0.0569, -1.0383],\n",
            "        [-0.4025, -0.0180,  0.6356,  ...,  0.0249,  2.5509,  0.6129],\n",
            "        [ 0.1580,  1.0393,  0.3158,  ..., -0.0565,  1.2687,  0.6522]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0885, -1.1009, -0.8715,  ...,  0.4239,  1.9289, -0.5372],\n",
            "        [-0.5208, -0.5190, -0.2098,  ..., -0.2880,  0.5681,  0.0795],\n",
            "        [-0.3975, -0.4440, -0.3369,  ...,  0.1882,  0.2456, -1.3313],\n",
            "        ...,\n",
            "        [-1.0811, -0.3285,  0.0630,  ..., -0.2784,  0.1024,  1.3582],\n",
            "        [-0.2847,  0.5940,  0.7330,  ..., -0.1688, -1.2524,  0.4763],\n",
            "        [-0.3031, -0.1094,  0.7220,  ..., -0.2091, -1.2781,  0.6670]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6205,  1.0965,  0.2185,  ..., -0.5888,  0.6329, -0.1740],\n",
            "        [-0.5626, -0.9121, -1.2927,  ...,  0.2266, -0.6076, -1.4121],\n",
            "        [ 0.7366,  0.7005,  1.1385,  ...,  0.6395, -0.7538, -0.1840],\n",
            "        ...,\n",
            "        [-0.7519, -1.0530, -1.0469,  ...,  0.4666, -0.1912,  0.4179],\n",
            "        [-0.2447, -0.7693, -1.3974,  ...,  2.3004,  1.3644,  0.7098],\n",
            "        [ 0.1776,  0.0542, -0.0277,  ..., -0.8650, -0.3553, -0.6172]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 5.1447, -0.1331,  0.3211,  ..., -0.2446, -1.0104, -1.4874],\n",
            "        [-0.0362, -0.5145, -0.1785,  ...,  0.6917, -0.3039, -0.4289],\n",
            "        [-0.2298, -0.5167,  1.6799,  ..., -1.0012, -1.3460,  0.2655],\n",
            "        ...,\n",
            "        [-0.4830, -0.2305, -0.0499,  ..., -0.4037,  0.3586,  0.3379],\n",
            "        [-0.4194, -0.6518,  0.2250,  ...,  0.1179,  1.6859, -0.0638],\n",
            "        [-0.5208, -0.0389, -0.5275,  ...,  0.7314,  7.3232,  0.3173]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-6.1339e-01, -1.3722e+00,  2.8241e-01,  ...,  5.3754e-01,\n",
            "          5.2027e-01, -4.1891e-01],\n",
            "        [-7.3983e-01, -1.6029e-01, -7.1680e-01,  ..., -3.2353e-04,\n",
            "          2.2706e+00, -5.0404e-01],\n",
            "        [ 2.8047e+00,  7.8380e-03,  2.2868e-01,  ..., -5.2071e-01,\n",
            "         -8.0293e-01, -4.1701e-01],\n",
            "        ...,\n",
            "        [-2.1902e-01, -1.0198e+00, -1.0180e+00,  ...,  8.0937e-01,\n",
            "          2.4492e+00, -6.4421e-01],\n",
            "        [ 4.9992e-01, -1.3584e+00,  7.3414e-01,  ..., -1.3949e+00,\n",
            "         -3.6816e-01, -5.3943e-01],\n",
            "        [-7.9051e-01, -4.1532e-01, -1.5488e-01,  ...,  9.3728e-01,\n",
            "         -5.9735e-01,  1.9190e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.2959, -1.2376,  0.5262,  ..., -1.0775, -0.4629, -0.7805],\n",
            "        [ 1.2923,  0.5521, -1.5269,  ...,  1.7557,  0.5763, -0.1981],\n",
            "        [-0.3207, -1.0158, -0.7008,  ..., -0.2215, -0.6551, -1.2779],\n",
            "        ...,\n",
            "        [ 0.2251, -0.1548, -0.6272,  ...,  0.7959,  0.0864,  0.9869],\n",
            "        [-0.7009, -1.1724, -0.8063,  ..., -0.4454, -1.4147, -1.5432],\n",
            "        [-0.6428, -0.0919, -1.2149,  ...,  1.9950,  1.0153,  0.6976]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.7138,  0.0492, -0.1419,  ...,  0.6667, -1.1494, -1.0766],\n",
            "        [-0.7379, -0.3621, -0.2351,  ..., -0.1299,  1.8871, -1.3345],\n",
            "        [ 1.8485,  0.9764, -1.3219,  ...,  0.6506, -1.7597, -0.5878],\n",
            "        ...,\n",
            "        [ 0.3673,  1.0354,  0.8607,  ..., -0.6408,  0.6156,  0.2762],\n",
            "        [ 0.8004,  0.3318, -1.3530,  ...,  0.9640, -0.9234,  0.0668],\n",
            "        [-0.6899, -0.7924,  1.1512,  ..., -1.3880, -0.5184, -0.0233]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5707,  0.1320, -1.1747,  ..., -0.4186,  0.5170, -0.5376],\n",
            "        [-0.5746, -1.1835,  0.2081,  ...,  0.4230,  0.3892, -0.1084],\n",
            "        [-0.2839, -0.1636, -1.8180,  ...,  2.7311,  0.1973,  1.1866],\n",
            "        ...,\n",
            "        [-0.7476,  0.6909,  0.6164,  ...,  0.5957, -0.2822,  7.3013],\n",
            "        [ 0.5887,  0.6103,  0.5927,  ...,  0.3421, -1.0100, -0.2267],\n",
            "        [-0.6405,  0.1468,  2.3510,  ...,  0.2111, -0.4780,  0.1955]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.2427,  0.2374,  0.6027,  ...,  1.3879, -0.8765,  1.4058],\n",
            "        [ 1.8297,  0.4711,  1.1261,  ...,  0.5972, -1.6169,  0.7488],\n",
            "        [ 2.2872,  0.0617,  0.4556,  ..., -0.8286, -0.8388, -0.9177],\n",
            "        ...,\n",
            "        [-0.8872, -0.2303, -1.1726,  ...,  0.3898, -0.3430, -0.2666],\n",
            "        [-0.3482, -0.7380,  0.1396,  ...,  0.0478,  0.5436, -0.2490],\n",
            "        [-1.2056,  0.1501, -0.1234,  ...,  0.1254,  0.7939,  2.5982]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0388,  0.5127,  0.3622,  ...,  0.4332,  1.7259,  0.8789],\n",
            "        [ 1.2122, -1.3950,  1.6029,  ..., -1.8615, -0.9517, -0.9769],\n",
            "        [-0.5637, -0.3392,  1.1528,  ..., -0.4268,  1.2815, -0.4209],\n",
            "        ...,\n",
            "        [ 5.3881,  0.4461, -0.2361,  ...,  1.4932, -1.4565, -1.8201],\n",
            "        [-0.7033, -0.8604, -0.3969,  ...,  1.0595, -0.1622,  3.1634],\n",
            "        [ 3.7571,  0.7667, -0.4729,  ...,  1.5097, -1.2180, -0.5632]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0051,  0.1573, -0.0650,  ..., -0.8059,  0.5562, -0.2439],\n",
            "        [-0.8670, -0.2030,  0.4447,  ..., -0.7812,  1.1707, -0.1435],\n",
            "        [-0.1435,  0.7495,  0.2958,  ...,  0.0250,  0.7715,  1.2136],\n",
            "        ...,\n",
            "        [-0.0489, -0.7489,  0.1121,  ...,  0.7385,  0.5348, -0.8420],\n",
            "        [-1.1008, -0.5649,  0.3437,  ..., -0.2160,  0.1102, -0.4256],\n",
            "        [-0.0371,  0.1617,  1.1351,  ...,  0.1680, -1.2725,  2.8957]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-8.1777e-01, -5.2306e-01, -1.1202e-01,  ...,  1.3078e-01,\n",
            "         -2.5298e-01, -6.1359e-02],\n",
            "        [-7.0060e-01, -7.7341e-01, -2.0479e+00,  ...,  8.6420e-03,\n",
            "         -8.3013e-01, -4.4774e-01],\n",
            "        [ 1.0702e+00, -1.2185e+00,  9.2606e-01,  ..., -9.5922e-01,\n",
            "         -5.9358e-01,  2.7303e-01],\n",
            "        ...,\n",
            "        [ 3.4909e-01, -1.1244e+00, -2.2858e-01,  ..., -6.6068e-01,\n",
            "         -8.4492e-01,  7.5034e-01],\n",
            "        [-8.9796e-01, -4.6204e-01,  1.7215e-01,  ...,  1.0778e-03,\n",
            "          1.1206e-01,  1.2382e+00],\n",
            "        [ 7.4287e-01,  1.9082e-02,  1.3727e-01,  ..., -4.6138e-01,\n",
            "         -1.1517e+00,  8.4783e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4233, -0.6652, -0.6679,  ..., -0.0037,  0.7592, -1.2188],\n",
            "        [ 0.3958, -0.5107, -0.4496,  ..., -0.5699, -0.2586, -0.3893],\n",
            "        [-0.4868,  0.5010,  0.0219,  ...,  0.0872, -0.4280,  1.1288],\n",
            "        ...,\n",
            "        [-0.7066, -1.1003,  0.8431,  ..., -0.7749, -0.8752,  1.7296],\n",
            "        [ 0.5951,  0.4820, -1.2528,  ..., -0.0392,  0.4834, -0.2745],\n",
            "        [ 2.9412,  0.1817, -0.6693,  ...,  1.0828, -1.5370, -1.1106]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8340, -0.3726,  0.0498,  ..., -0.0482, -0.3401, -0.0993],\n",
            "        [-0.4483,  0.0796,  1.2022,  ..., -0.3574, -0.3208,  0.2264],\n",
            "        [-0.0515, -0.3956,  0.2509,  ...,  0.0937, -0.2465, -0.0393],\n",
            "        ...,\n",
            "        [ 0.2788, -0.5752,  0.5125,  ..., -0.2058, -0.0335,  0.1081],\n",
            "        [-0.8224, -1.1010, -0.5768,  ...,  0.1452, -0.6639,  0.3498],\n",
            "        [-0.8396,  0.0860,  0.1670,  ..., -0.3623, -0.3619,  1.9232]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8658,  0.7075, -0.1285,  ...,  0.4920, -0.9565, -0.0568],\n",
            "        [ 0.7107, -0.3933, -0.3962,  ..., -0.1775, -1.9835, -0.2726],\n",
            "        [-0.6861, -0.9186, -1.2145,  ...,  0.6606,  1.2931, -0.2052],\n",
            "        ...,\n",
            "        [-0.7385, -0.3532, -1.1042,  ..., -0.0046, -0.7875, -1.0347],\n",
            "        [-0.5161, -0.5270, -1.1225,  ...,  2.5851, -0.1267,  1.9913],\n",
            "        [ 2.9421,  0.1164, -0.0115,  ...,  0.5269, -1.6924, -0.7062]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8333,  0.2044,  0.3355,  ..., -0.8467, -0.6260, -0.8262],\n",
            "        [-0.5534, -1.0962, -2.0078,  ..., -0.3180, -0.5573, -1.0796],\n",
            "        [-0.7018, -1.2216,  1.3680,  ..., -1.1542, -1.2069,  0.9731],\n",
            "        ...,\n",
            "        [ 4.4990,  0.3089,  0.8272,  ...,  0.5222, -0.6618, -1.1664],\n",
            "        [ 1.0530, -1.2707, -0.1511,  ..., -1.2097, -1.5428,  0.0571],\n",
            "        [ 0.0892, -0.4607, -0.9913,  ...,  0.6709, -0.7312, -0.2320]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6025, -1.6665,  0.0583,  ..., -0.6974,  0.7088, -0.9992],\n",
            "        [ 0.3166, -0.0106, -1.2717,  ...,  1.2996, -0.1681,  0.4769],\n",
            "        [-1.0205, -1.5962, -1.2667,  ...,  0.2739,  0.5027, -0.0440],\n",
            "        ...,\n",
            "        [-0.0634,  1.1893,  0.3863,  ...,  0.1548,  2.4511,  0.2860],\n",
            "        [ 0.4082, -0.6889, -1.0352,  ...,  1.1763, -0.7465, -0.3171],\n",
            "        [-0.6138, -0.5694,  0.4785,  ..., -0.0535, -0.3329,  0.2223]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.3413e-01, -1.4110e-01, -5.4491e-01,  ..., -7.9793e-02,\n",
            "          4.6911e-02,  7.6624e-01],\n",
            "        [ 7.4431e-01, -8.1737e-02,  4.8737e+00,  ..., -2.0022e+00,\n",
            "         -1.0025e+00,  1.5316e-03],\n",
            "        [-1.2297e+00, -8.5060e-01, -9.7791e-01,  ..., -2.5202e-01,\n",
            "         -6.7439e-01, -1.2284e+00],\n",
            "        ...,\n",
            "        [-7.8322e-01, -4.9236e-01,  1.8669e-01,  ..., -5.7039e-01,\n",
            "          2.0096e-01, -8.8063e-01],\n",
            "        [-2.4912e-01, -4.4267e-01, -1.2350e-01,  ..., -5.0648e-01,\n",
            "          2.5839e-01,  2.9376e-01],\n",
            "        [-4.5491e-01, -1.2265e+00, -3.2296e-01,  ..., -2.9762e-01,\n",
            "         -3.3182e-01, -1.5517e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0586e+00, -1.4875e+00, -1.4500e+00,  ...,  5.0266e-01,\n",
            "         -2.0876e-01, -1.9490e-01],\n",
            "        [ 4.8202e-01, -1.9919e-01,  5.4009e+00,  ..., -2.4032e+00,\n",
            "         -1.1358e+00, -5.7785e-02],\n",
            "        [-1.1782e+00, -8.2338e-01,  1.5588e+00,  ..., -1.1019e+00,\n",
            "         -3.5063e-01,  1.4898e+00],\n",
            "        ...,\n",
            "        [-7.5543e-01,  7.2393e-02, -1.2055e+00,  ...,  2.0812e+00,\n",
            "         -1.1279e-01,  1.1052e+00],\n",
            "        [-2.7125e-01,  1.9605e+00,  3.3508e-01,  ..., -7.8479e-01,\n",
            "          1.3593e-01, -1.9166e-03],\n",
            "        [ 2.5890e-01, -1.4404e-01, -3.9132e-02,  ...,  8.0303e-01,\n",
            "          2.2530e-01, -2.7966e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-9.5060e-01, -1.3562e+00,  1.3997e-03,  ..., -4.4218e-01,\n",
            "         -7.3967e-01, -1.1496e+00],\n",
            "        [ 2.1212e+00,  5.0497e-01, -2.2011e+00,  ...,  3.5580e+00,\n",
            "         -9.9791e-03, -1.3298e-01],\n",
            "        [ 2.1786e+00,  5.8095e-02, -9.3714e-01,  ..., -8.6297e-01,\n",
            "         -1.6559e-01, -5.8065e-01],\n",
            "        ...,\n",
            "        [-9.8102e-01,  5.2880e-01,  6.7079e-01,  ...,  8.7552e-02,\n",
            "          6.4747e-01,  1.2337e+00],\n",
            "        [-1.2659e+00, -7.4090e-01, -5.6297e-01,  ..., -2.3311e-01,\n",
            "          1.2171e+00,  1.0781e+00],\n",
            "        [-7.4077e-01,  4.0753e-01, -1.3181e-01,  ...,  1.6955e-01,\n",
            "         -3.0904e-01, -1.9800e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.2056, -0.1103,  0.1996,  ...,  1.0303,  3.5884,  0.8524],\n",
            "        [-0.4584, -0.4689, -1.4000,  ...,  2.5402,  0.3207,  0.5192],\n",
            "        [-0.3848, -0.8556, -1.0542,  ...,  0.5001,  0.2495, -0.2364],\n",
            "        ...,\n",
            "        [ 1.0141,  0.1739, -2.0323,  ...,  6.4729, -0.0175,  1.8320],\n",
            "        [-0.2474,  0.5831,  0.2765,  ..., -0.6852,  1.2758,  0.2449],\n",
            "        [-0.9784,  0.0105,  0.4766,  ..., -0.0455, -0.2922,  0.0079]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9125,  0.3044, -0.1726,  ..., -0.0071, -0.5919,  4.2050],\n",
            "        [-0.7361,  0.0397, -0.2351,  ...,  0.0087,  0.6492,  0.0437],\n",
            "        [-0.4433, -1.3442, -1.2708,  ..., -1.1585, -1.1607, -0.6285],\n",
            "        ...,\n",
            "        [-1.1782, -1.3075, -1.5955,  ...,  0.2970, -0.3140, -0.0109],\n",
            "        [-0.9133, -1.2660, -0.8451,  ..., -0.5250, -1.4689, -0.2978],\n",
            "        [-0.2206,  0.3218, -1.3506,  ...,  1.6743, -1.2347,  1.0768]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5567, -0.2883, -0.1521,  ..., -0.6837,  0.6172,  0.2550],\n",
            "        [ 0.3869,  0.3701,  0.5749,  ..., -0.2068, -0.1755, -0.3534],\n",
            "        [-1.3225, -1.0642,  0.4196,  ..., -1.1762, -1.1302, -0.9965],\n",
            "        ...,\n",
            "        [ 0.0503,  0.7387,  1.0955,  ..., -0.3993, -0.1278,  0.1400],\n",
            "        [-1.0699,  0.6703,  0.2775,  ..., -0.8933,  1.1432, -0.1867],\n",
            "        [-0.8889, -1.8969, -1.1737,  ..., -0.4830, -0.3809, -0.3312]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7239,  0.1282,  0.0381,  ..., -0.0314,  0.1746,  1.1688],\n",
            "        [-0.4840, -1.0777, -1.4272,  ..., -0.2618, -0.1722, -0.2497],\n",
            "        [-0.9966, -0.2954, -0.5013,  ...,  0.6284, -0.4991,  2.4338],\n",
            "        ...,\n",
            "        [-0.1879, -0.3674, -1.1755,  ...,  1.4282, -0.3113, -0.5569],\n",
            "        [-1.2028, -0.6067, -0.1297,  ..., -0.4761,  0.2979, -0.9802],\n",
            "        [-0.3144, -1.5949, -0.0105,  ..., -1.3505, -0.4035, -0.7976]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5476, -0.5612, -0.4541,  ..., -0.1001, -1.6831, -0.8573],\n",
            "        [ 0.2205,  0.3704,  0.0395,  ..., -0.8594,  0.4095, -0.2664],\n",
            "        [ 0.9988,  0.6587, -0.6682,  ..., -0.1535, -1.1637, -0.1869],\n",
            "        ...,\n",
            "        [-0.9784, -0.3699,  0.8876,  ..., -0.8422,  1.4001, -0.2664],\n",
            "        [ 1.6363,  1.0742, -0.8171,  ...,  0.2879, -0.4386, -1.3110],\n",
            "        [-0.1345, -0.3376, -0.1219,  ...,  0.8632,  0.2619, -0.2605]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 7.7642e-01,  8.0371e-02, -2.4013e-01,  ..., -5.1238e-01,\n",
            "         -2.6998e-01, -7.7001e-01],\n",
            "        [ 3.8145e-01,  1.9925e-01, -8.3195e-01,  ...,  1.2666e-03,\n",
            "          6.7487e-02, -2.7839e-01],\n",
            "        [ 2.3603e-01,  8.4152e-02,  1.9232e+00,  ..., -3.1588e-01,\n",
            "         -7.1120e-01,  2.4645e-01],\n",
            "        ...,\n",
            "        [ 1.0590e+00,  3.1504e-01, -1.0594e+00,  ...,  7.6853e-01,\n",
            "          4.0791e-02,  4.3462e-01],\n",
            "        [-1.3065e-01, -3.3275e-02, -1.0292e+00,  ...,  2.4961e-01,\n",
            "         -7.9989e-01, -1.4932e+00],\n",
            "        [-8.1012e-01,  2.8194e-01,  7.0286e-01,  ..., -1.2085e+00,\n",
            "          6.8038e-01,  3.7193e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.8691e-01, -4.3824e-01, -2.7470e-01,  ..., -2.3620e-01,\n",
            "         -1.2876e+00, -3.1127e-01],\n",
            "        [-1.3145e-01,  4.2812e-01, -1.2436e-01,  ...,  1.2835e-01,\n",
            "          1.1590e+00,  8.0740e-01],\n",
            "        [-3.8360e-01, -6.9224e-01, -5.2390e-01,  ...,  1.0933e+00,\n",
            "          1.9696e+00,  1.1168e+00],\n",
            "        ...,\n",
            "        [ 3.5338e-01, -6.4374e-01, -5.3272e-01,  ...,  6.6564e-01,\n",
            "          2.0911e-03, -4.1325e-01],\n",
            "        [-1.0051e+00, -9.6767e-01, -1.0722e+00,  ..., -1.8389e-01,\n",
            "         -9.9749e-01, -7.0098e-01],\n",
            "        [-2.0800e-01, -2.4815e+00,  3.6540e-01,  ..., -1.5104e+00,\n",
            "         -9.5017e-01, -2.6290e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.6689, -0.0644, -1.3223,  ..., -0.3559,  0.8035, -0.4554],\n",
            "        [-0.0551,  1.5781,  0.6777,  ..., -0.0043,  1.3044,  0.8294],\n",
            "        [-0.3338, -0.6068,  0.0200,  ..., -0.3299, -0.5085,  0.6393],\n",
            "        ...,\n",
            "        [-0.4509, -0.1410,  1.4114,  ..., -0.4009, -0.5489,  0.8802],\n",
            "        [ 0.6454, -0.4911, -1.9908,  ...,  0.9138, -0.1096, -0.4619],\n",
            "        [-0.8241, -0.7517, -1.2249,  ...,  0.6837,  0.4573, -0.0914]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2360,  0.0446, -0.0125,  ...,  0.2362,  0.0189, -0.2766],\n",
            "        [ 0.0614, -0.2707,  1.8719,  ..., -0.6215,  0.1295, -0.7535],\n",
            "        [-1.1261, -0.8449, -0.1716,  ...,  0.0512,  2.0848,  3.1543],\n",
            "        ...,\n",
            "        [-0.5958, -0.0651,  0.4000,  ..., -0.1465, -0.3362, -1.3486],\n",
            "        [-0.8916, -0.7546,  0.0226,  ..., -0.1676,  0.3358,  0.6725],\n",
            "        [-1.0753, -0.8008,  0.6786,  ..., -0.6866, -0.2206,  1.7303]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1588e-01,  3.1355e-01, -5.5406e-01,  ...,  9.5848e-01,\n",
            "         -1.3262e+00,  6.8696e-01],\n",
            "        [-6.0294e-01, -1.7674e-01, -1.5916e+00,  ...,  1.3172e+00,\n",
            "          1.6437e-01,  1.4944e+00],\n",
            "        [ 2.2515e-01, -6.3113e-01, -8.3333e-02,  ...,  8.0903e-01,\n",
            "          2.9097e-02, -1.6485e-01],\n",
            "        ...,\n",
            "        [-7.8536e-01, -5.2666e-01, -1.8497e+00,  ...,  2.4695e+00,\n",
            "          5.8698e-02,  1.8737e+00],\n",
            "        [-8.2132e-01,  2.3503e-03,  5.7559e-01,  ...,  4.6860e-02,\n",
            "          1.1554e+00,  6.3492e-01],\n",
            "        [ 1.0344e+00,  7.9452e-01,  5.1079e-01,  ...,  1.6604e-01,\n",
            "         -1.1405e+00, -2.2620e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,360  of  2,811.    Elapsed: 1:02:04.\n",
            "logits :  tensor([[-9.5281e-02,  4.8139e-01, -1.3721e+00,  ...,  1.9949e+00,\n",
            "         -9.2966e-01,  2.6473e+00],\n",
            "        [ 4.7846e-01,  4.0846e-01, -6.6500e-01,  ...,  1.2962e+00,\n",
            "         -3.2449e-03,  1.8593e-01],\n",
            "        [-1.1333e+00, -1.5426e+00, -1.4727e+00,  ...,  1.0570e-01,\n",
            "          1.5193e+00,  1.6841e-01],\n",
            "        ...,\n",
            "        [ 4.7898e+00,  1.1052e+00,  2.1834e-02,  ...,  2.2424e+00,\n",
            "         -1.7466e+00, -5.0272e-01],\n",
            "        [ 5.0331e-01,  3.2082e-01, -9.8457e-01,  ...,  3.4155e-02,\n",
            "          4.3874e-01, -3.2916e-01],\n",
            "        [ 4.3557e+00,  5.1428e-01, -1.6223e-01,  ...,  1.0520e+00,\n",
            "         -1.6147e+00, -1.3122e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3661, -0.5648,  1.2696,  ..., -1.0321,  0.3470, -0.7114],\n",
            "        [ 0.2340, -0.1164, -1.8855,  ...,  3.8150,  0.5769,  1.1199],\n",
            "        [ 0.6026, -1.0730, -1.0880,  ..., -0.1719,  0.0338, -0.4405],\n",
            "        ...,\n",
            "        [-0.3923,  0.0565,  0.7039,  ...,  0.3114, -0.4366, -1.0809],\n",
            "        [-0.3217,  0.1244,  3.9608,  ..., -1.4805, -0.5182,  0.3026],\n",
            "        [ 1.8276,  0.3777,  1.4213,  ...,  0.3923, -1.1267,  0.6767]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.6166,  1.3110,  0.0241,  ...,  0.9151, -1.9010, -0.0401],\n",
            "        [-0.2574, -0.9534, -1.2007,  ..., -0.4813, -0.9455, -0.6533],\n",
            "        [-0.4076, -0.2781, -1.6115,  ...,  3.7583,  0.1751,  0.4459],\n",
            "        ...,\n",
            "        [ 0.8450,  0.0381, -1.2045,  ..., -0.2442,  0.7502, -0.4275],\n",
            "        [-0.3766, -0.6445, -0.3697,  ..., -0.1507, -1.5830, -0.5706],\n",
            "        [ 1.6975,  0.9365,  0.3070,  ...,  0.2725, -0.4515, -0.1782]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3472,  0.5422,  0.8664,  ..., -1.4295,  1.0461,  0.0050],\n",
            "        [ 0.0473,  2.4862,  1.6087,  ..., -0.2014, -0.5692,  0.4933],\n",
            "        [-0.3024, -0.6499,  0.2064,  ...,  0.1418, -0.6968,  1.0754],\n",
            "        ...,\n",
            "        [ 0.7176, -0.0506,  1.3262,  ...,  0.7187, -0.8845,  2.3484],\n",
            "        [-0.5939,  0.2316,  1.0571,  ..., -0.5081, -1.2105, -0.6534],\n",
            "        [-0.2787,  0.2272,  0.3927,  ..., -0.1295,  0.1095, -0.0091]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6034, -0.5382, -0.7397,  ...,  0.0448,  0.1607,  0.2399],\n",
            "        [-1.0636,  0.5859,  0.3409,  ..., -1.2363, -0.6895, -0.3110],\n",
            "        [ 0.8342, -0.4964, -1.2800,  ..., -0.5998, -1.0234, -0.2934],\n",
            "        ...,\n",
            "        [ 0.2666, -0.5017, -0.1970,  ...,  0.5207, -0.0967, -0.3275],\n",
            "        [-0.1658, -0.7061, -0.3309,  ...,  0.6789, -1.0640,  0.9789],\n",
            "        [ 3.0886,  0.6214,  0.8822,  ..., -0.2534, -1.9148, -0.5998]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.6098,  0.6988, -1.1081,  ..., -0.5021,  0.4965, -0.4868],\n",
            "        [ 3.9096,  0.0720,  0.4500,  ...,  0.4843, -0.8413, -1.3937],\n",
            "        [-0.6104, -0.6355, -0.7009,  ...,  1.5950,  0.1765,  1.1792],\n",
            "        ...,\n",
            "        [-0.7372,  1.0198,  0.5958,  ..., -1.0858,  1.1902,  0.0369],\n",
            "        [-0.4480,  0.6759, -0.0297,  ...,  0.3595,  0.2428,  0.1558],\n",
            "        [ 0.0779,  0.7991, -0.1128,  ..., -0.8536,  1.4496, -0.3069]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.4696,  1.7349,  1.0233,  ..., -0.4088, -1.0979,  0.3394],\n",
            "        [-0.7599, -1.0632,  2.3572,  ..., -1.4206, -0.3796,  1.1519],\n",
            "        [-1.0081, -1.7060, -1.5242,  ..., -0.1123,  0.1753, -0.1797],\n",
            "        ...,\n",
            "        [ 0.6700, -1.0028, -0.1607,  ..., -1.1546, -1.5525, -1.3663],\n",
            "        [ 0.9164,  0.1949, -0.0422,  ...,  1.3269, -0.9404,  1.2197],\n",
            "        [-0.6522, -0.4559, -1.7546,  ...,  2.4298,  0.0908,  0.9044]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1515,  0.5579,  0.2130,  ..., -1.0570, -0.4573, -0.1218],\n",
            "        [-0.1708,  0.7194,  0.6062,  ..., -1.0174,  0.2624, -0.1627],\n",
            "        [-0.2053, -0.0751, -0.4937,  ...,  0.7132,  0.4874,  0.5162],\n",
            "        ...,\n",
            "        [-0.3087, -0.5907,  1.4321,  ..., -1.0844, -0.3258, -0.5109],\n",
            "        [-0.3038, -0.2937,  0.4698,  ..., -0.8888, -0.7501, -0.8912],\n",
            "        [-0.5263, -0.6673, -0.3923,  ..., -0.0450, -0.0189, -0.2489]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.1286,  1.7424,  0.3199,  ...,  0.4514, -1.1915, -0.8948],\n",
            "        [-0.9105, -0.4683,  1.1752,  ..., -1.2676, -0.7854, -0.7607],\n",
            "        [-0.6904, -0.3216, -0.3207,  ...,  0.4732,  0.9518, -0.8172],\n",
            "        ...,\n",
            "        [-0.6588, -0.9097,  0.2420,  ..., -0.6734, -0.2712, -0.5438],\n",
            "        [-0.9940, -0.4520, -0.4209,  ..., -0.0987,  1.1081,  1.1189],\n",
            "        [-1.5459, -0.1600, -0.3349,  ...,  1.1133,  1.2094,  6.6204]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0615, -1.2728,  2.3018,  ..., -1.5307, -1.4336,  0.3475],\n",
            "        [-1.6991, -1.9842, -1.4515,  ...,  0.1355,  0.2612, -0.2161],\n",
            "        [ 0.2562,  1.7422,  0.4811,  ..., -0.2079,  1.1350,  0.4800],\n",
            "        ...,\n",
            "        [-0.5582, -0.0628, -0.5070,  ..., -0.3779,  0.3535,  0.6762],\n",
            "        [-0.6878,  0.3890,  0.3137,  ...,  0.2362,  0.1486,  1.0184],\n",
            "        [ 0.2444, -0.5479, -0.0654,  ..., -0.7872, -1.0825,  0.1050]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.2552,  0.4787, -0.3411,  ...,  0.9834,  0.8495,  7.0384],\n",
            "        [ 0.5275, -1.1258,  3.0134,  ..., -0.6445, -0.8196,  0.0425],\n",
            "        [ 0.3466, -0.9313, -0.5261,  ..., -0.7100, -1.4513, -0.0784],\n",
            "        ...,\n",
            "        [-0.9108, -0.4769, -0.2442,  ..., -0.6029,  1.2726, -0.8753],\n",
            "        [ 1.7124, -0.1465,  1.1071,  ..., -0.4300, -1.4549, -0.5968],\n",
            "        [ 0.7694,  0.5681,  0.3160,  ..., -0.2363,  0.3696, -0.7855]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 5.4713,  1.2483, -0.0253,  ...,  1.1648, -1.0280, -1.4229],\n",
            "        [-0.9122, -1.5562,  1.0728,  ..., -1.1666, -0.9151,  0.9299],\n",
            "        [ 2.7411, -0.2074,  0.6141,  ..., -0.0601, -0.6888, -0.9061],\n",
            "        ...,\n",
            "        [ 1.3628, -0.5329,  1.0719,  ...,  0.0448, -0.7625, -0.6779],\n",
            "        [-0.5787, -0.7436, -0.5023,  ...,  0.9653,  5.2314,  0.1279],\n",
            "        [ 0.4035,  1.1786,  0.7228,  ..., -0.5303,  1.4114,  0.5925]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2989, -0.5061, -0.0810,  ..., -1.1428, -0.5905, -0.2856],\n",
            "        [-0.3383,  0.1248,  2.8823,  ..., -1.3329,  0.1985, -0.6101],\n",
            "        [ 0.8977,  0.1210, -1.9830,  ...,  1.3669,  0.8798, -0.2699],\n",
            "        ...,\n",
            "        [-1.0608, -0.7388, -1.1733,  ...,  0.2010,  1.2947,  0.0585],\n",
            "        [-0.3056, -0.9083, -0.9288,  ...,  0.1969,  0.6407, -1.1814],\n",
            "        [ 1.6652,  0.8572,  0.3514,  ...,  0.3088,  0.1097, -0.9026]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3432, -0.4859, -0.9853,  ..., -1.0687, -1.5745, -0.6741],\n",
            "        [ 0.1478, -0.1228,  0.9026,  ...,  0.1015, -0.7666,  2.3323],\n",
            "        [-0.2958, -0.8619, -1.2956,  ..., -1.4009, -0.8073, -0.3647],\n",
            "        ...,\n",
            "        [-0.6219, -0.3814,  0.4966,  ...,  0.2189, -0.4097, -1.3631],\n",
            "        [ 0.6557,  0.3651, -0.8647,  ...,  0.7579,  0.2894, -0.5237],\n",
            "        [ 0.2973,  0.1874, -0.8940,  ..., -0.6678,  0.1087, -0.3366]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.0210,  2.5671,  1.8209,  ..., -0.1736, -0.2364,  0.4376],\n",
            "        [-0.3816, -0.7965, -0.2136,  ...,  0.1270, -0.4634,  0.6788],\n",
            "        [-0.0824,  0.2989, -0.6078,  ..., -0.1904,  0.2132,  1.2037],\n",
            "        ...,\n",
            "        [ 0.7978,  0.8222, -0.4544,  ..., -0.1850, -0.2871, -0.8005],\n",
            "        [-0.4687,  0.3479, -0.3701,  ...,  1.1456,  1.3231,  0.1797],\n",
            "        [ 4.6319,  2.2586, -0.4176,  ...,  0.4256, -1.5048, -1.2870]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5119, -1.2342,  1.0302,  ..., -0.0740,  0.3622,  1.4200],\n",
            "        [-0.9232, -0.7625, -0.4357,  ...,  0.1690,  1.1331, -0.3763],\n",
            "        [ 0.5077,  1.5135,  1.1120,  ...,  0.0994, -0.5034,  0.5206],\n",
            "        ...,\n",
            "        [ 1.2413,  1.0896,  0.8555,  ...,  0.5352, -1.0561, -0.2277],\n",
            "        [-0.8478, -1.6638, -1.7834,  ..., -0.1305, -0.6929, -0.7987],\n",
            "        [-1.2514, -1.3871, -1.2495,  ...,  0.0476,  0.0201, -0.3281]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5247, -0.3365,  0.3752,  ..., -0.7684, -0.7588, -1.0339],\n",
            "        [ 0.7512,  0.0063, -0.0181,  ..., -0.9600, -1.4606,  0.0972],\n",
            "        [-0.1638, -0.3446, -0.7423,  ..., -0.9359, -0.7154, -0.0742],\n",
            "        ...,\n",
            "        [ 0.9311, -0.9949,  0.2211,  ..., -1.0710, -0.7083, -0.5179],\n",
            "        [ 0.2490,  0.0895, -1.1592,  ...,  1.5258, -1.2546,  0.0737],\n",
            "        [ 3.4189,  0.1683,  0.5062,  ..., -0.3995, -1.1984, -1.7747]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3760, -0.9261,  0.1593,  ..., -0.3629,  0.2551, -0.6799],\n",
            "        [ 0.2930,  1.5402,  0.0640,  ..., -0.0810, -0.7320, -0.0577],\n",
            "        [-0.5463, -0.9471, -1.0822,  ..., -0.2188, -1.0991, -1.3760],\n",
            "        ...,\n",
            "        [ 0.4820, -1.2213,  1.8695,  ..., -0.8773,  0.2688, -0.3947],\n",
            "        [-0.7738,  0.4192, -0.2306,  ...,  1.5088, -0.5252,  1.6766],\n",
            "        [-0.5667, -1.1466, -0.0669,  ...,  0.3289,  2.8265,  0.3695]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3036, -1.5088, -0.2982,  ..., -1.0984, -1.3808,  0.6703],\n",
            "        [ 1.5324,  0.1483,  0.7380,  ...,  0.3346, -1.0216,  0.1403],\n",
            "        [ 1.5578,  0.2551, -1.1364,  ...,  1.4316,  0.3575, -0.4585],\n",
            "        ...,\n",
            "        [-0.8883, -1.2347, -1.3256,  ..., -0.4096, -1.3280, -1.4833],\n",
            "        [ 0.3289,  1.4462, -0.0433,  ...,  0.1130, -1.0017,  0.3902],\n",
            "        [-0.9080, -1.8521, -2.0035,  ...,  0.7780, -0.1662, -0.4872]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.3785,  0.0734,  0.2420,  ..., -0.1941, -0.7778, -0.5731],\n",
            "        [-0.5112, -0.9490,  0.0189,  ..., -0.9400, -0.2806, -0.3362],\n",
            "        [ 0.7296,  0.9755, -2.0078,  ...,  1.9949, -0.1838, -0.0524],\n",
            "        ...,\n",
            "        [-0.2372,  0.8372, -0.1244,  ...,  0.4994,  0.0470,  0.7128],\n",
            "        [ 0.2667, -0.3760, -0.3529,  ...,  0.6156, -0.8247, -0.6141],\n",
            "        [ 0.8561, -0.8246,  0.9326,  ..., -0.0221, -0.6966, -0.2508]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0962, -0.1139, -0.7240,  ..., -0.5249, -0.8224, -1.2799],\n",
            "        [ 1.0853, -0.7566,  1.1643,  ..., -0.2597, -1.0866, -0.7318],\n",
            "        [-0.3757,  0.9995, -0.2751,  ...,  0.1564,  0.9142,  0.1164],\n",
            "        ...,\n",
            "        [ 0.1249,  1.4858,  0.2271,  ..., -0.0972,  1.3598,  0.4138],\n",
            "        [-0.2835, -0.8729,  2.0066,  ..., -1.5023,  0.0249, -0.7061],\n",
            "        [-1.1335, -2.0207, -1.9992,  ..., -0.1586, -0.2076, -0.1134]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5821, -1.3550, -1.0737,  ..., -0.8820, -1.0387, -1.0811],\n",
            "        [-0.7417,  0.0261, -0.2774,  ..., -0.0712,  6.8358, -0.2591],\n",
            "        [ 3.1430, -0.2865,  0.3390,  ..., -0.2811, -1.8912, -0.0600],\n",
            "        ...,\n",
            "        [ 0.6772, -0.4080, -2.0619,  ...,  1.7912, -0.6945,  0.1074],\n",
            "        [ 0.5434,  0.1381, -0.6377,  ...,  0.2356,  0.7502,  0.8407],\n",
            "        [ 1.5056,  0.6361,  0.2357,  ..., -0.0128, -1.2414, -0.3391]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-5.1484e-01, -1.5490e-01, -3.8324e-01,  ..., -1.2777e-01,\n",
            "         -7.5279e-01,  1.2983e+00],\n",
            "        [ 1.8607e-01,  1.4970e-01, -6.8018e-01,  ...,  9.2615e-01,\n",
            "          1.9432e+00,  3.9552e-02],\n",
            "        [-5.8327e-02, -6.2392e-02,  1.2455e+00,  ..., -3.7673e-02,\n",
            "         -6.4625e-01,  7.2774e-01],\n",
            "        ...,\n",
            "        [-9.7541e-01, -5.9598e-02, -7.1227e-01,  ...,  6.8633e-01,\n",
            "         -4.4275e-01,  6.1665e-02],\n",
            "        [-1.2604e+00,  2.0296e-01,  1.5863e+00,  ..., -1.2355e-03,\n",
            "          1.5373e+00,  1.9202e+00],\n",
            "        [ 7.2844e-02,  1.9462e+00,  4.3356e+00,  ..., -1.4354e+00,\n",
            "         -6.0092e-01,  4.0181e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3039,  0.2832,  2.1835,  ..., -0.3997, -0.2395,  0.7955],\n",
            "        [-1.4691, -2.0202, -1.6717,  ...,  0.0151, -0.1805,  0.1683],\n",
            "        [-0.6002, -1.2311,  0.3999,  ..., -1.1429, -1.7533,  0.0973],\n",
            "        ...,\n",
            "        [-0.5465,  0.5019,  0.5619,  ..., -0.4061, -1.1036,  0.2869],\n",
            "        [ 4.6228,  0.5813, -0.0082,  ..., -0.0838, -2.0573, -1.8743],\n",
            "        [-0.8258, -1.0924, -2.0209,  ..., -0.5407, -0.2128, -0.7825]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.4275, -1.1400,  0.8492,  ..., -1.4603, -0.2940, -0.1333],\n",
            "        [-0.5657, -0.4389,  0.0079,  ..., -0.0412, -0.7465,  0.9040],\n",
            "        [ 0.4144,  1.9304, -0.0068,  ..., -0.4383, -0.3942, -0.2550],\n",
            "        ...,\n",
            "        [ 2.2976,  1.5506,  1.5076,  ..., -0.8046, -1.7765, -0.2677],\n",
            "        [ 0.2034,  0.4041,  0.8296,  ...,  1.5076, -0.6561,  3.0747],\n",
            "        [ 1.1703,  0.4893, -1.3191,  ...,  1.2601,  0.0860, -0.3845]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7240, -0.6113, -1.9291,  ...,  1.2449, -0.6607, -1.2497],\n",
            "        [ 2.9275,  0.5946,  0.3855,  ...,  0.8982, -1.5154, -0.2757],\n",
            "        [-1.1876, -1.7585, -1.6271,  ...,  0.1806,  1.3756, -0.4031],\n",
            "        ...,\n",
            "        [-0.0650,  0.3508,  0.7829,  ...,  0.2332,  1.2179,  0.8363],\n",
            "        [ 0.4526, -0.6277, -0.2709,  ..., -0.8629, -0.3902, -0.7144],\n",
            "        [-0.7469, -0.9634, -1.0014,  ...,  1.2116,  0.2826,  0.9959]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4846, -1.3443, -0.5005,  ...,  0.1068,  1.4820, -0.6850],\n",
            "        [ 0.4645, -1.1974, -0.0529,  ..., -0.5965, -0.9184, -0.0527],\n",
            "        [ 0.2542, -0.2911, -1.6134,  ..., -0.0325, -0.7147, -1.0398],\n",
            "        ...,\n",
            "        [ 0.5096,  0.4398,  1.1982,  ..., -0.3387, -0.0675, -0.5969],\n",
            "        [ 3.7447, -0.7275, -0.8529,  ...,  0.7479, -0.8047, -1.2092],\n",
            "        [ 3.3429,  0.6248,  1.5333,  ...,  1.2675, -1.3014, -0.3487]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.4255, -0.0959,  0.2619,  ..., -1.0501, -0.5701, -0.1091],\n",
            "        [-1.1255, -0.1407,  0.0278,  ..., -0.1847, -0.0384, -0.4825],\n",
            "        [-0.6655,  0.0502, -0.4199,  ...,  1.4465,  3.4946,  0.3056],\n",
            "        ...,\n",
            "        [ 0.5746, -0.3370,  0.3056,  ..., -0.2334, -0.7854, -0.1782],\n",
            "        [ 0.8706,  0.7084, -2.2815,  ...,  6.9165, -0.1605,  0.6363],\n",
            "        [-0.3750, -1.1606, -0.5232,  ...,  0.1545,  1.5890, -0.6928]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.7411e+00,  1.2620e+00,  1.9973e-01,  ..., -7.7358e-02,\n",
            "         -7.8576e-02, -1.3390e+00],\n",
            "        [ 3.4881e+00,  8.8035e-01,  7.0818e-01,  ...,  7.9723e-01,\n",
            "         -7.8251e-01, -1.8148e-01],\n",
            "        [ 9.7153e-01, -8.5211e-01, -2.4594e+00,  ...,  1.3074e+00,\n",
            "         -7.2262e-01, -7.8984e-01],\n",
            "        ...,\n",
            "        [-1.5148e-01, -2.7539e-01, -7.3720e-01,  ...,  1.1814e+00,\n",
            "         -4.1795e-01,  6.4039e-02],\n",
            "        [-8.1907e-01, -1.5252e+00,  4.7502e-01,  ..., -1.0499e+00,\n",
            "         -1.0792e+00,  3.3866e-02],\n",
            "        [-4.1528e-01, -3.1351e-01,  1.0688e-03,  ...,  3.3103e-01,\n",
            "         -4.8694e-01, -1.6990e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5958,  1.7931, -0.1275,  ..., -0.6072, -0.0845, -0.3204],\n",
            "        [-0.5311, -1.2463, -1.2292,  ...,  0.0718,  0.0445, -0.0518],\n",
            "        [ 5.8728,  0.9380,  0.1905,  ...,  0.7513, -1.3292, -1.8616],\n",
            "        ...,\n",
            "        [ 0.0583, -1.0141, -0.8234,  ..., -1.3657, -0.9874, -0.2856],\n",
            "        [-0.3643, -0.8045,  0.4827,  ..., -0.5491, -0.1350, -0.2157],\n",
            "        [ 3.9249,  1.1337,  0.2764,  ...,  0.4270, -1.7617, -1.3809]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-7.6284e-01, -1.4780e-01,  3.4558e-01,  ..., -1.0018e+00,\n",
            "         -3.8145e-01, -1.2543e+00],\n",
            "        [-1.1006e+00, -1.5579e-01,  2.5856e-01,  ...,  5.6684e-01,\n",
            "          5.2725e-01,  7.1323e+00],\n",
            "        [ 4.3696e-01, -3.1815e-03,  8.8824e-01,  ...,  2.3998e-01,\n",
            "         -1.0505e+00,  1.5920e+00],\n",
            "        ...,\n",
            "        [-1.1294e+00,  1.6191e-02,  1.6283e-01,  ..., -1.1751e+00,\n",
            "         -5.8922e-01, -7.0293e-01],\n",
            "        [-7.8612e-01, -7.3469e-02, -1.3553e+00,  ...,  2.6735e+00,\n",
            "         -5.0788e-01,  1.3858e+00],\n",
            "        [-1.3233e-01, -1.4341e+00,  2.5126e+00,  ..., -1.7177e+00,\n",
            "         -1.7765e+00, -2.9330e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9275,  1.0221, -0.8436,  ...,  1.3811,  0.2970,  1.4435],\n",
            "        [ 0.8671,  0.6290, -2.3298,  ...,  6.5000, -0.0736,  1.1043],\n",
            "        [ 2.2851,  1.0150, -0.6047,  ...,  2.0935, -0.4927, -0.6557],\n",
            "        ...,\n",
            "        [-0.3988, -1.0460, -1.3223,  ..., -0.7235, -0.4686, -0.5269],\n",
            "        [-0.7510,  0.4866,  1.0412,  ..., -1.1687,  0.9462,  0.0730],\n",
            "        [-0.3516, -0.5192, -0.9538,  ..., -0.8040, -0.5694, -0.6858]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3863, -0.5308, -1.7216,  ...,  2.8777,  0.3231,  1.0751],\n",
            "        [-0.9706, -0.2948,  0.0526,  ..., -0.6519,  2.0987, -0.1492],\n",
            "        [-0.8538, -0.2929,  0.1691,  ..., -0.0924, -0.5947, -1.3787],\n",
            "        ...,\n",
            "        [ 0.3691,  1.5557,  3.2653,  ..., -0.9097, -0.2861,  0.1872],\n",
            "        [-0.9259, -0.1601, -0.5919,  ..., -1.0531, -0.2862, -1.4497],\n",
            "        [-0.0571,  0.7632,  0.1152,  ..., -0.0057,  0.9136,  0.6505]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-2.1681e-01, -3.9493e-01, -7.2289e-01,  ..., -5.5290e-02,\n",
            "          4.0555e-01,  8.2973e-02],\n",
            "        [-1.0787e-01,  1.7048e+00,  9.7374e-01,  ..., -9.0742e-01,\n",
            "          1.1410e+00,  4.0374e-01],\n",
            "        [-5.8933e-01, -1.3273e+00, -1.7719e+00,  ..., -2.5062e-04,\n",
            "          1.4563e+00, -1.7803e-02],\n",
            "        ...,\n",
            "        [-5.5261e-01, -3.0840e-02, -1.0181e-01,  ..., -3.9609e-01,\n",
            "          3.2892e-01,  1.1621e-01],\n",
            "        [-3.5033e-01, -3.9073e-01, -1.3729e+00,  ...,  2.3878e+00,\n",
            "         -1.8575e-01,  1.5163e+00],\n",
            "        [-1.3815e+00, -6.0520e-02, -3.4837e-02,  ..., -8.9658e-01,\n",
            "         -3.2361e-01, -3.8446e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.6978, -0.2627,  0.0300,  ...,  0.3430, -0.2056, -1.4596],\n",
            "        [ 1.2999,  0.9922, -0.5536,  ...,  0.1765, -0.8929, -1.0906],\n",
            "        [ 1.9414,  0.2093, -0.9741,  ...,  1.0308, -0.2235, -1.0628],\n",
            "        ...,\n",
            "        [-0.5259,  0.0807, -0.3137,  ...,  0.3331,  6.9305,  0.3085],\n",
            "        [-0.4804,  1.3506, -0.6612,  ...,  0.4099, -0.4257,  0.6788],\n",
            "        [ 0.6863, -0.8544,  1.4524,  ..., -1.3769, -0.7020,  0.3390]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0561,  0.1796,  0.2226,  ...,  0.9508,  1.2159,  0.9926],\n",
            "        [ 3.3994, -0.0299, -1.2863,  ...,  2.2926, -2.1926, -0.8302],\n",
            "        [-0.5920, -0.4345,  1.2490,  ..., -0.7467,  0.1534, -1.4391],\n",
            "        ...,\n",
            "        [ 0.9919,  2.6553,  1.2743,  ...,  0.2526, -0.9140, -0.0123],\n",
            "        [ 2.0286,  0.8400,  1.0494,  ...,  1.1139, -1.6180,  0.7313],\n",
            "        [-0.7500, -0.6897, -0.0944,  ..., -0.7850,  0.7643, -0.7171]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.3051, -0.1849, -1.0019,  ..., -0.7691, -0.1943, -0.3759],\n",
            "        [ 0.2719,  0.4351,  0.0157,  ...,  0.3179,  0.1909,  0.1549],\n",
            "        [-0.5951, -0.1569, -1.1478,  ...,  1.8675, -0.0710,  1.5293],\n",
            "        ...,\n",
            "        [ 0.2803, -0.2205,  1.2009,  ..., -1.5496, -1.0469, -0.8676],\n",
            "        [ 1.7850,  0.5409, -1.3677,  ...,  0.3047, -0.3842, -1.4915],\n",
            "        [ 0.9375,  0.4942, -1.9667,  ...,  4.8182,  1.5185,  0.1372]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4120, -0.5330, -0.3773,  ...,  0.0443,  0.3846,  0.2856],\n",
            "        [-1.0612, -0.6976,  0.4397,  ..., -0.8853,  1.2310, -0.4671],\n",
            "        [ 0.1384,  0.5675, -0.2761,  ...,  1.7045, -0.6091,  1.8562],\n",
            "        ...,\n",
            "        [-0.6646, -0.5832, -1.5119,  ...,  1.4793, -0.0977,  1.3892],\n",
            "        [-1.0286, -1.4615, -1.0677,  ...,  0.1472,  0.2254,  0.0875],\n",
            "        [ 0.4605, -0.0174, -2.8218,  ...,  3.5324,  1.6469, -0.2714]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.2494,  0.5003,  0.6641,  ..., -1.4516, -0.7034, -0.3531],\n",
            "        [-0.7225, -0.5595,  0.6054,  ..., -0.4787, -1.0720,  0.4444],\n",
            "        [ 0.7824,  2.4609,  0.3467,  ...,  0.3427, -0.6350, -0.0311],\n",
            "        ...,\n",
            "        [ 1.0457,  0.2046, -1.1258,  ..., -0.3367,  0.4174, -0.5333],\n",
            "        [ 3.0176, -1.1462,  0.1114,  ..., -0.2695, -1.1887, -1.1819],\n",
            "        [ 0.1424,  0.1428, -0.4814,  ...,  1.0434, -1.2327,  0.4789]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9147, -0.5629, -0.9511,  ...,  1.1458,  0.2627,  0.1001],\n",
            "        [ 1.7422, -0.0260, -1.4178,  ...,  0.7438, -0.5559, -0.9555],\n",
            "        [-0.8420, -0.1287, -0.3797,  ...,  0.5900, -0.5964, -1.4530],\n",
            "        ...,\n",
            "        [-1.0649, -0.1705,  0.1074,  ..., -0.5202, -0.2345, -0.6046],\n",
            "        [ 1.1893, -0.6591,  0.4514,  ..., -0.9237, -1.0771, -0.6919],\n",
            "        [ 2.0018,  0.3210, -0.3001,  ...,  0.6380, -1.0834,  0.1021]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,400  of  2,811.    Elapsed: 1:03:07.\n",
            "logits :  tensor([[-1.0993e+00,  4.0380e-01,  5.6663e-01,  ...,  8.2189e-01,\n",
            "          1.2589e-01,  6.8208e+00],\n",
            "        [-1.7682e-01,  6.2716e-01,  1.7739e-01,  ..., -1.1197e+00,\n",
            "          2.9278e-01, -1.1600e-01],\n",
            "        [-2.5441e-01,  7.6990e-01, -2.4495e-01,  ..., -6.9933e-01,\n",
            "          1.9561e-01,  8.8276e-02],\n",
            "        ...,\n",
            "        [ 1.0495e+00,  1.5399e+00, -4.4975e-01,  ...,  1.5936e-01,\n",
            "         -2.5508e-01, -1.7635e+00],\n",
            "        [-4.5087e-01,  7.4101e-01,  1.3288e-01,  ...,  2.9603e-01,\n",
            "         -4.9726e-01,  7.4885e-02],\n",
            "        [-1.7799e-01, -7.6200e-01,  3.1254e-01,  ..., -5.9009e-01,\n",
            "         -4.7280e-01,  3.9569e-03]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3434, -0.1027, -0.1158,  ..., -1.2194, -0.4111, -0.2941],\n",
            "        [-0.8334,  0.0469, -1.0657,  ...,  0.2783, -0.7875, -1.6664],\n",
            "        [-0.4830, -0.2960, -0.4551,  ..., -0.4436, -0.8679, -1.5721],\n",
            "        ...,\n",
            "        [-0.2513, -0.9746, -1.0319,  ..., -0.6604,  0.1567, -0.2694],\n",
            "        [-0.3602, -1.4265, -0.5705,  ...,  1.0222,  0.9481, -0.4168],\n",
            "        [-1.1351,  0.3749,  0.3190,  ..., -0.3800,  0.4479,  0.7894]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7788, -0.8181, -1.5724,  ...,  0.5101,  0.5771, -0.0249],\n",
            "        [-0.0701,  0.3122, -1.5846,  ..., -0.0335,  0.1207, -0.4725],\n",
            "        [ 1.0693, -0.0917,  1.4702,  ..., -0.2072, -0.7084, -0.7681],\n",
            "        ...,\n",
            "        [-0.2704, -0.2989,  0.1894,  ..., -0.5763, -1.2198,  0.3812],\n",
            "        [ 0.0752, -0.3643, -0.3173,  ..., -0.1485, -0.4429,  0.3161],\n",
            "        [-0.9738, -0.7615, -0.6245,  ..., -1.0171, -1.0428, -0.6421]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.0609,  1.7880,  0.0255,  ...,  0.4054, -0.3158, -1.2873],\n",
            "        [-0.9547, -0.8337, -0.3076,  ..., -0.2571,  0.4032, -0.5997],\n",
            "        [-1.1764, -1.0003,  0.2140,  ..., -0.5798,  2.0517,  0.8009],\n",
            "        ...,\n",
            "        [-1.3104, -0.2268, -0.6168,  ..., -0.7457, -1.4853, -1.1288],\n",
            "        [-0.8822, -1.3088, -0.7257,  ...,  0.6209,  2.1148, -0.4910],\n",
            "        [-0.6151,  0.3283, -0.7561,  ...,  1.2514, -0.1453,  1.0913]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.6873,  1.3590, -0.4594,  ...,  1.5664, -0.1800, -0.6591],\n",
            "        [ 2.1165,  0.6717,  0.6841,  ...,  0.0145, -1.8733, -0.4153],\n",
            "        [ 1.9674,  0.3347, -1.5704,  ...,  0.2234, -1.1255, -0.4474],\n",
            "        ...,\n",
            "        [ 0.8780, -0.4988, -0.8260,  ...,  0.2903, -0.0613,  0.2359],\n",
            "        [ 1.0681,  2.2553,  0.1669,  ...,  0.7031, -0.5450, -0.0784],\n",
            "        [-0.9703, -0.4959,  0.4654,  ..., -0.2070, -0.0906, -0.5881]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3983, -0.6045,  0.5092,  ..., -0.5401,  0.4425, -0.9812],\n",
            "        [-0.3754,  1.0735, -0.2095,  ..., -0.6298,  0.3668, -0.7022],\n",
            "        [-0.5574, -1.0904, -0.9059,  ...,  0.8788,  2.7126,  1.3574],\n",
            "        ...,\n",
            "        [-1.1826, -0.2558,  0.0891,  ..., -0.7552, -0.3280, -0.5202],\n",
            "        [ 0.2075,  1.1030, -0.7286,  ...,  0.4288,  0.3328,  0.4400],\n",
            "        [ 2.7633,  0.0849,  0.1370,  ...,  0.5095,  0.0585, -1.2646]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3330, -0.4797, -0.5435,  ..., -1.2660, -0.7422, -0.6435],\n",
            "        [-0.6449, -0.3905,  0.4888,  ...,  0.3667, -0.3914, -0.9828],\n",
            "        [ 1.0422,  0.2327, -1.5599,  ...,  0.2504,  0.4769, -0.3209],\n",
            "        ...,\n",
            "        [-0.7899,  0.1845, -0.1012,  ...,  0.0455, -0.6113, -0.3159],\n",
            "        [-0.9677, -0.1537, -0.7596,  ...,  0.7729,  5.1466,  0.8956],\n",
            "        [-0.7268,  0.5947,  1.5375,  ...,  0.1077, -0.2547,  1.3152]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2900,  0.0888, -0.6407,  ...,  1.1697, -0.3585, -0.2187],\n",
            "        [-1.4161, -1.0676, -0.1057,  ..., -1.7466,  0.3055, -1.0070],\n",
            "        [ 0.3022, -1.1414,  0.7175,  ..., -0.9702, -0.2621,  0.1187],\n",
            "        ...,\n",
            "        [-0.4015, -0.7909, -1.7580,  ...,  2.4706,  0.5845,  1.1150],\n",
            "        [ 0.5486, -1.4852,  0.8677,  ..., -1.4462, -0.2393,  0.1739],\n",
            "        [ 0.7994, -0.3459,  2.9680,  ..., -1.6370, -1.0262, -0.6040]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7985, -0.2900, -0.5635,  ..., -0.7259, -0.6748, -1.5804],\n",
            "        [-0.3152, -0.8210,  1.4776,  ..., -1.2232, -0.1945, -0.9075],\n",
            "        [-0.5417, -0.4971, -0.0293,  ..., -0.3182,  0.2544, -0.0652],\n",
            "        ...,\n",
            "        [ 0.5758, -1.1011, -1.2126,  ..., -0.6582, -0.9123, -0.1812],\n",
            "        [ 0.3166,  0.3400, -0.7888,  ...,  1.1236,  0.8078, -0.0645],\n",
            "        [ 1.4373, -0.7242, -1.7539,  ..., -0.7945, -0.6737, -0.5639]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7448, -0.6002, -0.1019,  ..., -0.1621, -1.2481,  0.2722],\n",
            "        [ 0.5997, -0.7592, -0.7331,  ...,  0.3424, -1.1384, -0.7901],\n",
            "        [-0.7886,  0.1177,  1.0558,  ...,  0.1677, -0.3105,  0.1547],\n",
            "        ...,\n",
            "        [-0.3624, -0.5497, -0.3025,  ..., -0.2023, -0.2674, -0.1134],\n",
            "        [-0.1361, -0.6329, -1.2540,  ..., -0.8491, -0.5416, -0.5534],\n",
            "        [-0.1676,  0.1359,  0.1744,  ..., -0.1207,  2.2411,  0.9487]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0199,  0.2762, -1.1440,  ..., -0.2168,  0.4257, -0.4793],\n",
            "        [ 0.0640, -0.2251, -0.4969,  ...,  0.1312, -1.0335,  0.7717],\n",
            "        [-0.2987,  0.1800, -0.2201,  ...,  0.1221, -0.5323,  1.4875],\n",
            "        ...,\n",
            "        [ 1.5295,  1.5724, -1.7986,  ...,  0.9978, -0.7002, -0.2557],\n",
            "        [ 1.6626,  0.1863,  0.7534,  ..., -0.2678, -0.2804, -1.1176],\n",
            "        [-1.6824, -0.2743, -0.2044,  ...,  0.1418,  1.8633, -0.1581]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.9054,  0.3883,  0.1029,  ...,  0.2691,  0.4222, -0.6941],\n",
            "        [-1.0825, -1.0903, -0.3095,  ..., -0.5610,  0.7919,  0.8760],\n",
            "        [-0.7773, -0.2935, -0.5689,  ...,  0.2407,  7.0358,  0.4878],\n",
            "        ...,\n",
            "        [ 1.4118,  1.4719, -0.8817,  ...,  1.1484,  0.4860,  0.2994],\n",
            "        [ 2.9500,  0.9618, -0.3109,  ...,  1.4011, -0.6564, -0.3551],\n",
            "        [ 2.5969,  0.3966,  0.0586,  ...,  0.1344, -1.3706, -0.4333]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7991, -0.1007,  0.0066,  ..., -0.8652,  0.3526, -1.2125],\n",
            "        [-0.5929, -0.9066,  0.4655,  ..., -0.6197, -1.0601, -0.4198],\n",
            "        [ 0.5094, -0.1971, -0.0122,  ...,  0.7937, -0.0855,  0.1633],\n",
            "        ...,\n",
            "        [-1.1052,  0.2362, -0.0526,  ..., -1.3790, -0.8223, -1.3993],\n",
            "        [-0.4727,  0.0472, -0.7732,  ..., -0.3321, -0.3226,  1.2264],\n",
            "        [ 0.1936, -0.3244, -0.1626,  ..., -1.1781, -0.5024, -0.7008]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.0738,  0.9726, -0.0355,  ..., -0.2555,  0.6061, -0.2129],\n",
            "        [ 0.3660,  0.6108, -0.2072,  ..., -0.9742,  0.1815, -0.5042],\n",
            "        [-0.9785, -1.5862, -1.6445,  ..., -0.6426, -1.0276, -0.8845],\n",
            "        ...,\n",
            "        [ 0.1535,  0.1602, -0.0289,  ...,  0.9301, -1.4485,  0.3856],\n",
            "        [ 3.3794,  0.8638, -0.4702,  ...,  1.0801, -1.3173, -1.2437],\n",
            "        [ 0.1166,  0.7727,  1.3516,  ..., -0.5527, -0.1778, -0.4499]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2425,  0.0608, -1.6015,  ...,  1.6042, -0.4799,  0.0214],\n",
            "        [ 1.9438,  1.0441, -1.4400,  ...,  1.8489, -0.6081, -1.0434],\n",
            "        [ 2.0936,  1.5050,  1.3678,  ...,  0.7044, -1.1888,  0.9967],\n",
            "        ...,\n",
            "        [ 1.0619, -0.1718, -1.1224,  ...,  0.3192,  0.0327, -1.4169],\n",
            "        [ 0.2021,  0.5746,  0.0261,  ..., -0.9531, -0.1443, -0.1869],\n",
            "        [ 1.3442,  0.9273, -1.2497,  ...,  1.3369,  0.1857, -0.3696]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8975, -0.6797, -0.2765,  ..., -1.5003, -1.3317, -0.7729],\n",
            "        [-0.5157, -1.3799, -0.8342,  ...,  0.0291,  1.1381, -0.7522],\n",
            "        [ 4.7172,  1.1820, -0.7253,  ...,  1.5267, -1.2270, -0.8172],\n",
            "        ...,\n",
            "        [-0.9593, -0.7663,  2.0255,  ..., -0.9504, -0.9372, -0.8690],\n",
            "        [-0.9829, -0.2317, -0.8012,  ..., -0.4906, -0.1836, -0.9865],\n",
            "        [-1.3104, -0.6945, -0.6987,  ..., -0.5971, -0.5262, -0.1379]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2007,  0.3389,  0.3919,  ...,  0.3982, -0.7009,  1.1025],\n",
            "        [-0.6791, -0.4260, -1.2042,  ...,  1.7982,  0.1851,  1.7981],\n",
            "        [ 0.4647,  1.2925,  0.9478,  ...,  0.0937, -0.6789,  0.2670],\n",
            "        ...,\n",
            "        [ 0.2323, -0.1322, -0.8065,  ...,  0.3561, -0.7934, -0.2732],\n",
            "        [ 0.6116, -0.8930,  1.1231,  ...,  0.2136, -0.9631, -0.8892],\n",
            "        [ 0.0755,  0.7182,  0.0347,  ..., -1.0595,  0.2675, -0.4704]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.3754, -0.2461, -0.3696,  ..., -0.2547, -0.4406, -0.2337],\n",
            "        [-0.6704, -1.1848, -0.0682,  ...,  0.1237,  3.4458,  0.8153],\n",
            "        [ 1.5474,  0.0393,  0.0516,  ...,  0.2630, -0.2337, -0.8993],\n",
            "        ...,\n",
            "        [-0.5882, -0.6158, -0.4455,  ...,  0.1670,  0.5275, -1.0116],\n",
            "        [ 0.6258,  0.3804, -1.2191,  ...,  0.2775, -0.8329, -1.5055],\n",
            "        [-0.6756, -0.8033, -0.8900,  ...,  0.0155,  0.5213, -0.0046]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1990,  0.3699, -1.9356,  ...,  3.8977, -0.7132,  1.0773],\n",
            "        [ 1.9359,  0.7609, -0.8915,  ...,  0.7344, -0.5037, -0.6335],\n",
            "        [-0.8760,  0.3231,  0.0517,  ..., -0.1285,  0.2797,  0.0742],\n",
            "        ...,\n",
            "        [ 2.5058,  0.4782, -0.5256,  ...,  0.2307, -1.1387, -1.0876],\n",
            "        [ 1.1661, -0.4558,  0.0465,  ...,  0.2060, -1.4320, -0.2288],\n",
            "        [ 0.9132, -0.6204, -1.7334,  ...,  1.3207, -0.5868, -0.4850]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.4051,  0.7503,  2.2454,  ..., -0.8425, -0.4773,  0.3395],\n",
            "        [-1.0340, -1.0035, -0.3456,  ...,  0.6685,  2.6007,  3.4742],\n",
            "        [-0.3824, -0.5248,  0.7043,  ..., -0.4161,  0.2632, -0.6815],\n",
            "        ...,\n",
            "        [-0.5927, -0.0279, -1.1400,  ...,  0.4879, -0.3476, -0.4661],\n",
            "        [-0.7738, -0.2516,  1.8011,  ..., -1.2110, -1.4559, -0.1558],\n",
            "        [-0.6069, -1.5692, -0.2028,  ...,  0.7181,  0.8356, -0.3935]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1873e-01,  2.5379e-01,  6.9487e-02,  ...,  1.1992e-02,\n",
            "         -2.6275e-01, -1.7673e-01],\n",
            "        [-7.0730e-01,  3.7367e-04, -4.1411e-01,  ...,  1.0583e-01,\n",
            "         -2.9596e-01,  3.6227e-01],\n",
            "        [-3.8207e-01, -7.4779e-01, -1.2314e+00,  ..., -9.6272e-01,\n",
            "          1.3688e+00, -5.2299e-01],\n",
            "        ...,\n",
            "        [ 2.7169e+00,  9.8707e-01,  6.8401e-01,  ...,  5.5349e-01,\n",
            "         -7.4171e-01, -1.3684e+00],\n",
            "        [-1.1469e-01, -1.3618e+00, -1.2475e+00,  ...,  1.3274e+00,\n",
            "          2.8935e-01, -3.7431e-02],\n",
            "        [ 1.1938e+00, -8.7506e-01,  8.1696e-01,  ...,  2.1767e-01,\n",
            "         -6.3512e-01, -8.9714e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7563,  1.1883,  0.9519,  ...,  0.0668, -0.5536,  0.2343],\n",
            "        [-0.9110, -0.8355, -0.6731,  ..., -0.2373,  0.2087, -0.6260],\n",
            "        [-1.0390,  0.5221,  0.2074,  ..., -0.7151,  1.1987,  0.0272],\n",
            "        ...,\n",
            "        [ 0.5886, -0.9024,  0.2159,  ..., -0.4896, -0.7831,  0.1062],\n",
            "        [ 0.1937, -1.6753,  1.1162,  ..., -1.1412, -1.7498, -0.2452],\n",
            "        [ 0.5083,  0.1906, -1.4151,  ...,  2.1142, -0.3944,  0.4247]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0731, -0.1464, -0.5110,  ...,  0.8421,  0.4357,  0.6574],\n",
            "        [-0.1340, -0.5031, -1.4105,  ...,  3.0299,  0.4596,  1.4827],\n",
            "        [-0.1211, -0.9872, -1.0748,  ...,  0.0503, -1.1164, -0.6216],\n",
            "        ...,\n",
            "        [-0.4595, -0.2055, -0.7868,  ...,  0.4140, -0.3925,  0.7684],\n",
            "        [-0.7793, -1.3121, -1.3899,  ..., -0.2533, -0.8372, -0.5906],\n",
            "        [-0.1250,  0.4881,  1.4968,  ..., -0.2651, -0.6808,  0.7404]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.6231,  1.3643,  0.6468,  ...,  0.3570, -0.6547, -0.8116],\n",
            "        [ 0.6413, -1.0025,  0.8056,  ..., -0.6964, -0.2363,  0.8029],\n",
            "        [ 0.7602,  0.3961, -0.0346,  ..., -0.0314, -1.0565,  0.8570],\n",
            "        ...,\n",
            "        [-0.7439, -1.5370,  0.3439,  ..., -1.7294, -0.3956, -0.4750],\n",
            "        [ 0.9105, -0.7666, -0.6652,  ..., -0.3750, -1.3181, -0.8488],\n",
            "        [-0.2147, -0.5819,  0.7408,  ..., -0.8621, -0.6772, -0.8991]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1243,  1.0189,  1.2211,  ...,  0.9789,  0.0997,  7.1741],\n",
            "        [ 0.3415,  0.2446, -0.7300,  ...,  0.9464, -0.7252,  0.2545],\n",
            "        [ 0.0286,  1.4079,  5.4891,  ..., -2.1672, -0.8132, -0.3088],\n",
            "        ...,\n",
            "        [-0.3938,  0.4225,  0.2568,  ..., -0.0936,  2.6682,  0.3069],\n",
            "        [-0.4812, -0.3750, -0.3737,  ..., -0.0981,  0.2917,  0.0512],\n",
            "        [-0.3044, -0.5530, -0.0867,  ..., -0.9996,  1.0465, -0.8511]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1572,  6.6626,  1.3174,  ...,  0.0663, -0.1602,  0.4699],\n",
            "        [ 0.8164, -0.8904,  0.3806,  ..., -0.8472, -0.2474,  0.0677],\n",
            "        [-0.1674,  0.6492, -0.9216,  ...,  0.8180,  0.3896,  0.2495],\n",
            "        ...,\n",
            "        [-0.0341, -0.8502, -0.3908,  ..., -0.2047, -1.0956,  0.3865],\n",
            "        [-0.0353, -0.7763, -1.0989,  ...,  0.5677,  1.7523, -0.9184],\n",
            "        [ 2.4865,  0.1642, -0.0984,  ..., -0.6420, -0.7272, -1.3921]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0096, -1.5949, -1.3365,  ..., -0.1857, -0.3137, -0.9621],\n",
            "        [ 1.1022, -1.1169,  0.3418,  ..., -0.4411, -0.2935, -0.3872],\n",
            "        [-1.1872, -0.5151, -0.2439,  ..., -0.5214,  0.5014, -0.9814],\n",
            "        ...,\n",
            "        [-1.1234, -0.7067, -0.5217,  ...,  0.5965, -0.0787, -0.0922],\n",
            "        [ 1.9834, -0.1230, -1.3572,  ...,  1.5869, -0.3778, -0.2071],\n",
            "        [-0.9260, -0.2051,  0.6502,  ..., -1.4739, -0.4118, -0.5516]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5450, -0.9055, -1.3949,  ..., -0.2536, -0.6158, -1.0058],\n",
            "        [ 1.5596,  1.0145, -1.7592,  ...,  1.6162,  0.2743, -0.5938],\n",
            "        [ 0.8524,  0.1586, -0.6703,  ..., -0.2227, -0.1001, -0.4334],\n",
            "        ...,\n",
            "        [ 1.2443,  0.8951, -0.8066,  ...,  2.1588,  0.9969,  0.9412],\n",
            "        [ 0.2690, -0.7631, -0.9341,  ..., -0.6083,  0.6626, -0.7203],\n",
            "        [ 0.4776, -1.5137,  0.4484,  ..., -1.1242, -0.1748, -0.2177]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3651,  0.5260,  5.7354,  ..., -2.0716, -0.4281,  0.0189],\n",
            "        [-0.1727, -0.5395,  1.4533,  ..., -1.5786, -0.9395, -1.1066],\n",
            "        [-0.5048, -0.3837, -0.5666,  ...,  0.4275, -0.5748,  2.2629],\n",
            "        ...,\n",
            "        [-0.3317, -0.7911, -1.1339,  ..., -0.5539, -0.9570, -1.6131],\n",
            "        [ 3.6469,  0.0939, -0.4702,  ...,  0.0753, -0.5877, -1.6425],\n",
            "        [ 0.1439,  0.6382,  0.0243,  ...,  0.7591,  0.2485,  0.7934]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4630, -1.6591, -0.3377,  ..., -1.1335, -0.5815, -0.0774],\n",
            "        [-0.3376,  0.5982, -0.0174,  ..., -0.5620, -0.4981,  0.2385],\n",
            "        [-0.7416, -0.0261,  0.8478,  ...,  0.0619, -0.4479, -1.3165],\n",
            "        ...,\n",
            "        [ 4.2957,  0.3612,  0.4396,  ...,  0.6786, -0.5925, -1.8098],\n",
            "        [ 0.5196, -0.1347, -1.7037,  ...,  3.4578, -0.7499,  0.5563],\n",
            "        [ 1.1137,  0.1135, -0.9237,  ...,  0.3302, -0.2276, -1.0362]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.7954e-01, -4.4893e-01, -1.0645e+00,  ...,  1.6231e+00,\n",
            "         -3.9552e-01,  9.0174e-04],\n",
            "        [ 8.1195e-01, -5.8102e-01, -2.1002e+00,  ...,  1.3826e+00,\n",
            "         -1.2996e+00, -4.7578e-01],\n",
            "        [-1.2141e+00, -7.3721e-01, -8.8967e-01,  ..., -7.5373e-01,\n",
            "          9.7880e-01,  5.8718e-01],\n",
            "        ...,\n",
            "        [ 7.9434e-01, -8.0423e-02, -1.8646e+00,  ...,  2.5298e+00,\n",
            "          1.6510e+00, -4.4693e-01],\n",
            "        [-4.3225e-01, -1.9177e-01, -2.8656e-01,  ..., -8.5071e-01,\n",
            "         -7.1393e-01, -1.7461e+00],\n",
            "        [ 1.0547e+00, -5.3725e-01,  1.9551e+00,  ..., -8.1463e-01,\n",
            "         -8.4899e-01, -5.4083e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5528, -0.1124, -0.6829,  ...,  1.2053,  1.2373,  0.2985],\n",
            "        [-0.2581, -0.9936, -0.4508,  ..., -0.8958,  1.5196, -1.0375],\n",
            "        [-0.7408, -0.8169, -1.0979,  ...,  0.6949,  6.3653, -0.3536],\n",
            "        ...,\n",
            "        [ 0.1685,  0.3941, -0.9813,  ...,  1.3810,  0.2901, -0.3030],\n",
            "        [ 2.6365,  0.4358, -0.6961,  ...,  0.7909, -0.7529, -0.6611],\n",
            "        [-1.0664, -0.9184, -0.8117,  ..., -0.6311, -0.0320, -0.8560]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9693, -0.9105, -1.2981,  ..., -0.3982, -0.8296, -0.3601],\n",
            "        [-0.7985,  0.0247,  0.3224,  ...,  0.2646,  0.6780,  0.8080],\n",
            "        [-0.5702, -0.6283,  0.1317,  ..., -0.0097,  1.9933,  0.0235],\n",
            "        ...,\n",
            "        [-0.0773,  0.0367,  0.2120,  ...,  0.4524,  0.8687,  0.0518],\n",
            "        [-0.6230, -1.2524, -1.2089,  ...,  0.0262,  0.5490,  0.1696],\n",
            "        [ 1.6193, -0.2965, -2.8101,  ...,  3.1047, -0.5606, -1.0195]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3871, -0.6471, -0.8427,  ..., -0.7267, -0.4646, -0.8896],\n",
            "        [-0.0894,  0.1409,  0.1021,  ..., -0.7418,  1.8962,  0.1676],\n",
            "        [-0.8392, -0.3918,  0.0409,  ..., -0.4487, -0.3572, -0.3867],\n",
            "        ...,\n",
            "        [-0.7022,  0.0351, -0.3942,  ..., -0.9253, -0.2936, -1.5338],\n",
            "        [-1.3252, -0.3045, -0.0454,  ..., -1.2032, -0.7217, -1.4472],\n",
            "        [ 1.1717,  1.1506, -0.8149,  ...,  2.2926, -0.6643, -0.3124]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1634, -0.7898, -0.6960,  ..., -0.3812, -1.2221, -1.0971],\n",
            "        [ 0.7984, -0.8223,  1.3024,  ..., -0.2982, -0.7805, -0.5678],\n",
            "        [ 0.7844,  0.6962, -1.0204,  ...,  1.8429,  0.5090, -0.2842],\n",
            "        ...,\n",
            "        [ 0.6087,  0.2387, -1.6869,  ...,  0.9927, -0.5479, -0.8613],\n",
            "        [-0.9187,  0.0350, -0.2831,  ...,  1.7597,  3.3213,  0.7700],\n",
            "        [-0.1399,  0.0823, -1.0783,  ..., -0.1098,  0.0560,  0.9536]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8442, -1.2396, -1.1245,  ...,  0.5777, -0.2676,  0.6521],\n",
            "        [-1.0131, -0.9114,  0.7243,  ..., -1.2912, -0.1987, -1.3239],\n",
            "        [-0.9315,  0.2528,  0.1087,  ..., -0.9195, -0.3490, -0.3504],\n",
            "        ...,\n",
            "        [ 0.5509, -1.2473,  1.0473,  ..., -1.1920, -1.5724,  0.2643],\n",
            "        [-0.4398, -0.0041, -0.6399,  ..., -0.0083,  0.1377,  0.5115],\n",
            "        [-0.5621, -0.0212, -0.8794,  ..., -0.1092,  0.0363,  0.6959]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2858, -1.4125, -0.3222,  ..., -2.0582, -1.0305, -0.8458],\n",
            "        [-0.9376, -1.1728, -0.8655,  ..., -1.2101, -0.5472, -0.6366],\n",
            "        [ 1.0683, -0.3186, -0.8709,  ..., -0.7287, -0.6155, -0.7679],\n",
            "        ...,\n",
            "        [ 0.1261, -0.6681, -0.0805,  ..., -0.5490, -1.5989, -0.4802],\n",
            "        [-0.6685, -0.9778, -1.2745,  ..., -0.0385, -0.9655, -0.7160],\n",
            "        [-0.9238, -1.2560,  0.1376,  ...,  0.2803,  0.9126, -0.3308]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0700e-02, -1.4256e-01, -1.7862e-01,  ..., -2.6849e-01,\n",
            "          1.4870e+00, -7.7904e-02],\n",
            "        [ 1.0431e+00,  6.7828e-02, -2.6213e+00,  ...,  3.9489e+00,\n",
            "          1.0735e-01, -4.6879e-02],\n",
            "        [ 1.3523e+00, -2.0400e-01,  5.7085e-01,  ...,  1.5236e-01,\n",
            "         -5.6611e-01, -7.8137e-01],\n",
            "        ...,\n",
            "        [ 1.9204e+00,  1.1456e+00, -1.4804e-01,  ...,  8.5028e-01,\n",
            "         -8.1009e-03, -4.1836e-01],\n",
            "        [-7.5336e-01, -1.3028e+00, -1.3674e+00,  ..., -1.3295e-03,\n",
            "         -5.3525e-01, -1.3659e+00],\n",
            "        [-2.1689e-01,  7.0408e-01,  3.1243e-01,  ..., -3.1357e-01,\n",
            "          3.4900e-02, -7.4677e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 4.0502e+00,  9.3373e-01, -2.3170e-02,  ...,  6.2143e-01,\n",
            "         -1.2111e+00, -8.0554e-01],\n",
            "        [ 9.1492e-01, -7.1220e-01, -1.3450e+00,  ...,  3.1666e-01,\n",
            "          9.7056e-02, -1.4549e+00],\n",
            "        [ 2.5342e-01, -3.0231e-01, -1.3274e+00,  ...,  1.5906e+00,\n",
            "         -8.2854e-01,  4.2690e-01],\n",
            "        ...,\n",
            "        [-1.9112e-01, -1.8538e+00, -3.2467e-01,  ..., -1.2417e+00,\n",
            "         -4.8165e-01, -5.0338e-01],\n",
            "        [ 7.5772e-01, -7.2595e-01, -2.5948e-01,  ...,  4.0277e-01,\n",
            "         -3.1807e-03, -4.8862e-02],\n",
            "        [-7.0124e-01, -5.8021e-01,  1.6317e+00,  ..., -2.4696e-01,\n",
            "         -5.5005e-01,  8.3921e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2649, -0.4569,  1.4614,  ..., -0.5465, -1.3591,  1.0558],\n",
            "        [-0.0330,  0.5254, -0.5887,  ...,  1.6589,  0.1694,  1.0647],\n",
            "        [-0.8406, -0.7013, -0.4763,  ..., -0.2326, -0.2353,  0.9339],\n",
            "        ...,\n",
            "        [ 0.0363, -0.8277, -1.6892,  ...,  0.0153, -0.9061, -0.1526],\n",
            "        [-0.3051, -0.4492,  1.3149,  ..., -1.4957, -0.8260, -1.2810],\n",
            "        [-1.0767, -1.1456, -0.8381,  ..., -0.9008,  1.2495,  0.2595]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,440  of  2,811.    Elapsed: 1:04:10.\n",
            "logits :  tensor([[-0.5495, -1.1234, -0.3407,  ...,  0.3845,  1.9529,  1.8312],\n",
            "        [-0.9266, -1.0005, -0.3137,  ..., -1.0454, -1.6827, -0.9785],\n",
            "        [ 2.4821,  0.1769, -2.3822,  ...,  1.5728, -1.2396, -0.7998],\n",
            "        ...,\n",
            "        [ 0.0758, -0.2987, -0.1352,  ..., -1.2907, -0.6765,  0.0904],\n",
            "        [-0.3376, -1.2408,  1.2255,  ..., -0.5400,  2.2485, -1.0308],\n",
            "        [-0.8879, -1.4605,  1.3874,  ..., -1.2859, -0.7639,  0.7984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.8528e-01,  2.6500e+00,  3.0342e+00,  ..., -9.4610e-01,\n",
            "         -2.3229e-01,  8.8555e-02],\n",
            "        [-5.9003e-01, -5.1148e-01,  7.3416e-01,  ..., -6.9386e-01,\n",
            "          5.3086e-01,  1.8712e-03],\n",
            "        [-9.3597e-01, -2.9127e-01, -3.4405e-01,  ...,  1.2502e+00,\n",
            "          2.7249e+00,  3.3016e-01],\n",
            "        ...,\n",
            "        [-3.7764e-01, -6.4952e-01, -2.2465e-02,  ...,  1.9040e-01,\n",
            "         -7.3120e-02, -2.4923e-01],\n",
            "        [ 2.3680e-01, -5.6121e-01,  2.4531e-01,  ..., -2.2713e-01,\n",
            "         -8.2128e-01, -1.5969e-01],\n",
            "        [-1.4674e-01,  3.6137e-01, -9.1589e-01,  ...,  1.4633e+00,\n",
            "         -1.4138e+00,  1.5101e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6261,  0.2020, -0.5739,  ...,  0.8775,  7.2483,  0.7576],\n",
            "        [ 1.0878,  1.1202, -0.1916,  ...,  1.1916, -1.1265, -0.2774],\n",
            "        [ 2.2866,  0.7441, -0.8818,  ...,  1.5633, -0.1034, -0.5917],\n",
            "        ...,\n",
            "        [-0.6155, -1.8551,  1.1615,  ..., -1.4187, -1.1382,  1.2227],\n",
            "        [-0.5191, -0.6012,  0.0463,  ..., -0.0776, -0.9623,  0.4967],\n",
            "        [-0.7078,  0.1035, -0.7940,  ..., -0.2778,  0.2204,  0.9787]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0212,  1.0073,  0.2463,  ...,  0.2693,  1.1631,  0.2782],\n",
            "        [-0.6398, -0.0705,  0.0781,  ...,  0.3156,  1.1419,  0.6610],\n",
            "        [ 3.7464,  0.1352,  0.3249,  ...,  0.2084, -0.4408, -1.4943],\n",
            "        ...,\n",
            "        [-1.0053, -1.2375,  1.2230,  ..., -1.2793, -0.3597,  2.2184],\n",
            "        [-0.4316,  0.4840,  0.0256,  ...,  0.0695,  2.4678,  0.3917],\n",
            "        [ 1.9578,  0.4029, -2.1326,  ...,  2.3054,  0.3227, -0.5185]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-7.9415e-01, -1.0019e-01,  2.0230e-01,  ..., -8.4783e-01,\n",
            "          1.3946e+00, -6.8597e-01],\n",
            "        [-1.5445e-01, -5.3114e-01, -9.9135e-02,  ..., -7.2398e-01,\n",
            "         -4.9278e-01, -1.1508e+00],\n",
            "        [-7.2542e-01, -1.3585e-01,  4.2123e-01,  ...,  6.3238e-01,\n",
            "          1.1626e-01,  7.2370e+00],\n",
            "        ...,\n",
            "        [-3.2513e-01, -1.0130e+00, -2.6831e-01,  ..., -6.5447e-01,\n",
            "         -7.5679e-01, -1.7781e+00],\n",
            "        [-9.0237e-01,  1.1328e+00,  1.9085e-01,  ...,  1.0987e+00,\n",
            "          2.9180e-01,  6.7478e+00],\n",
            "        [-1.3502e+00, -1.8174e+00, -1.4677e+00,  ..., -2.7845e-01,\n",
            "         -2.8860e-01, -2.0708e-03]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8588, -1.7891, -0.0741,  ..., -0.0174,  0.8302, -0.6601],\n",
            "        [-0.9071, -1.3676, -1.0386,  ..., -0.1502, -1.0884, -0.7602],\n",
            "        [-0.2774, -1.3944, -0.4865,  ..., -0.8470, -1.5281, -1.1518],\n",
            "        ...,\n",
            "        [-0.0559,  0.4152,  0.4019,  ..., -1.2278,  0.2648, -0.4148],\n",
            "        [-0.5970,  0.0676, -0.5421,  ...,  0.4980,  7.3042,  0.4572],\n",
            "        [ 2.0093, -0.7214, -0.5448,  ..., -0.4481, -1.7701, -1.2846]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5809,  0.2164, -0.3737,  ...,  0.5985,  0.4235,  0.5084],\n",
            "        [-1.0700,  0.1778, -0.4111,  ..., -0.1984,  0.1325,  1.1841],\n",
            "        [ 0.7896,  0.2354, -2.6544,  ...,  7.3155, -0.1117,  1.1407],\n",
            "        ...,\n",
            "        [-0.7391, -0.1938,  0.3175,  ..., -0.2990, -1.6474,  0.7799],\n",
            "        [ 0.2698, -0.7514, -1.7133,  ...,  1.1342, -0.6014, -1.0511],\n",
            "        [-0.4200, -0.6367, -0.4507,  ..., -0.3759,  1.6238, -1.3562]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-2.9086e-01,  1.1731e+00, -6.4864e-01,  ..., -4.7194e-01,\n",
            "          7.5340e-01, -5.7321e-01],\n",
            "        [-1.2758e+00,  1.8294e-03, -2.2288e-01,  ...,  9.2398e-01,\n",
            "          2.3371e+00,  9.3021e-01],\n",
            "        [-6.6436e-01,  1.2643e-01, -1.0091e+00,  ...,  6.1406e-01,\n",
            "          4.9207e-01,  7.5441e-01],\n",
            "        ...,\n",
            "        [ 1.9311e-01, -5.1377e-01, -6.0879e-01,  ..., -8.6342e-01,\n",
            "         -2.0252e-02, -9.2171e-01],\n",
            "        [-4.3458e-01, -1.9444e-01, -1.4716e+00,  ...,  1.9930e+00,\n",
            "          4.5182e-01,  1.5340e+00],\n",
            "        [-6.5141e-01, -1.2218e-01, -4.7565e-03,  ...,  1.4058e+00,\n",
            "          2.4829e+00,  1.0151e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-3.9075e-01,  1.7970e-01, -3.8903e-01,  ...,  2.3329e-01,\n",
            "          7.0296e+00,  5.3984e-01],\n",
            "        [-8.8104e-01,  3.4261e-01, -3.6852e-01,  ..., -9.1487e-01,\n",
            "         -5.9676e-01, -1.4342e+00],\n",
            "        [ 2.5501e+00,  3.9553e-01,  7.8744e-01,  ...,  1.6580e-01,\n",
            "         -1.6389e+00, -3.8077e-01],\n",
            "        ...,\n",
            "        [ 5.2444e+00,  7.0314e-01, -3.9824e-01,  ...,  1.1503e+00,\n",
            "         -1.5088e+00, -1.4190e+00],\n",
            "        [-5.4399e-01, -1.0298e+00, -1.1265e+00,  ..., -1.2056e+00,\n",
            "         -1.2678e+00, -7.6212e-01],\n",
            "        [ 1.0196e+00,  4.7934e-01, -9.9898e-01,  ..., -1.1665e-03,\n",
            "          3.7964e-01, -5.3506e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0244, -1.1885,  1.6398,  ..., -0.3435, -0.7586, -0.2760],\n",
            "        [ 0.1497,  0.3690,  0.1440,  ..., -0.9550, -0.5101,  0.1036],\n",
            "        [ 0.1984,  0.6571,  0.3893,  ...,  0.9355,  0.8233,  0.9102],\n",
            "        ...,\n",
            "        [-1.2231, -0.6924, -0.4287,  ..., -0.7183, -0.6260, -0.7245],\n",
            "        [ 1.1181, -0.1239, -1.1818,  ..., -0.1388,  0.2179, -0.6004],\n",
            "        [-0.4714,  0.3678, -0.3312,  ...,  0.3380,  6.6314,  0.4649]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-8.1401e-01, -6.6782e-01, -8.9935e-01,  ..., -1.7308e-03,\n",
            "          6.6834e-01,  7.0864e-01],\n",
            "        [-3.7974e-02, -8.4632e-01, -9.3466e-01,  ..., -9.0719e-01,\n",
            "         -1.3798e+00, -9.3501e-01],\n",
            "        [ 3.7526e+00,  3.8439e-01,  8.0877e-01,  ...,  5.9978e-01,\n",
            "         -1.2701e+00, -5.7627e-01],\n",
            "        ...,\n",
            "        [-4.5467e-02,  1.4757e+00,  2.2029e-01,  ..., -3.3025e-01,\n",
            "          7.9896e-01,  4.1453e-02],\n",
            "        [ 3.3040e+00,  1.7547e+00, -6.8072e-01,  ...,  1.3841e+00,\n",
            "          3.2171e-02, -1.0135e+00],\n",
            "        [-4.0536e-01, -6.1508e-01, -2.1364e-01,  ..., -2.5705e-02,\n",
            "         -1.2351e+00,  5.4667e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-9.7859e-01, -5.3684e-01,  4.7302e-01,  ..., -6.5569e-01,\n",
            "          1.2967e+00, -5.0142e-01],\n",
            "        [-7.6957e-01, -1.0436e+00, -8.6327e-01,  ..., -9.8294e-01,\n",
            "         -1.1074e+00, -9.8024e-01],\n",
            "        [-7.5035e-01,  6.0142e-01,  6.1264e-01,  ..., -5.2523e-01,\n",
            "          9.4740e-01, -1.0141e-01],\n",
            "        ...,\n",
            "        [-7.6186e-01, -1.1964e+00,  2.1911e-04,  ..., -1.3959e-01,\n",
            "         -5.6369e-02, -1.8177e-01],\n",
            "        [-4.1883e-01,  7.2277e-02, -8.2609e-01,  ...,  1.0557e+00,\n",
            "          7.2127e+00,  2.8620e-01],\n",
            "        [ 7.2047e-01,  2.1933e+00,  1.7452e+00,  ..., -4.0421e-01,\n",
            "         -3.3941e-01,  5.3896e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-5.9333e-01, -2.7364e-01,  4.0854e-01,  ..., -1.5681e-01,\n",
            "         -1.0505e+00,  1.0265e+00],\n",
            "        [-4.3052e-01, -1.1727e+00,  2.3786e-01,  ...,  1.1519e-01,\n",
            "          1.3045e+00, -8.8842e-01],\n",
            "        [-4.7106e-01, -9.6252e-01,  1.0464e+00,  ..., -1.0269e+00,\n",
            "         -1.3070e+00,  3.8560e-01],\n",
            "        ...,\n",
            "        [-2.2151e-01,  2.8583e-01,  1.3687e-02,  ..., -8.5342e-01,\n",
            "          2.3230e-01,  1.1324e-03],\n",
            "        [-7.2891e-01, -7.5536e-02,  8.7316e-01,  ...,  9.8446e-03,\n",
            "         -4.1649e-01, -1.1101e+00],\n",
            "        [ 2.6282e+00,  1.1936e+00, -7.7500e-01,  ...,  1.2033e+00,\n",
            "         -4.1671e-01, -5.2980e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3643, -0.6191,  0.0167,  ..., -0.7445, -1.1690, -0.9380],\n",
            "        [-0.8430,  0.6574,  1.6228,  ..., -0.8098, -0.3235, -0.6738],\n",
            "        [ 1.4636,  0.7557,  0.8580,  ...,  1.1505, -0.6946,  0.9696],\n",
            "        ...,\n",
            "        [-0.8887,  0.0796,  0.7271,  ..., -0.2352, -0.5193, -1.1409],\n",
            "        [-0.5096, -0.5519, -0.0343,  ..., -0.5965, -1.1128, -1.6806],\n",
            "        [-0.1019, -0.8363,  0.2180,  ..., -0.5655, -0.3220, -0.8903]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9612,  1.0862,  0.5116,  ..., -0.0312, -0.6077, -0.1646],\n",
            "        [-0.7514, -0.5617,  0.2094,  ..., -0.5788,  2.2476, -0.0808],\n",
            "        [ 1.1716,  0.1103, -1.0998,  ...,  0.9209,  0.2960, -0.3352],\n",
            "        ...,\n",
            "        [-0.0489, -0.2351, -0.7746,  ...,  0.6712, -0.2147,  1.4362],\n",
            "        [ 1.7243,  0.1943, -0.0799,  ...,  0.1236, -0.3905, -0.5069],\n",
            "        [ 0.2303, -0.3981,  2.0974,  ..., -0.2461, -1.0282,  2.6910]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.7669, -0.2155,  2.4404,  ..., -0.5710, -0.8561, -0.5829],\n",
            "        [-1.0660, -0.1754, -0.2424,  ...,  0.2188, -0.4244,  0.1799],\n",
            "        [-1.1009, -0.4161,  0.4639,  ..., -0.8397,  0.9863, -0.4158],\n",
            "        ...,\n",
            "        [ 5.4714,  0.5747, -0.7096,  ...,  1.4701, -1.0902, -1.0720],\n",
            "        [-0.4538, -0.5821,  0.5063,  ..., -0.3739, -0.1186, -0.6069],\n",
            "        [-0.9540, -1.6146, -1.4311,  ...,  0.0960, -0.1137, -0.3672]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1049, -0.8944,  0.0608,  ..., -0.2486,  0.9488, -0.0841],\n",
            "        [-0.6571, -0.0566, -0.9102,  ...,  1.1368,  0.1349,  1.7474],\n",
            "        [-0.4419,  0.0921, -0.9851,  ...,  0.9623,  0.4224,  0.7148],\n",
            "        ...,\n",
            "        [-0.5190, -0.6818, -0.8674,  ..., -0.5465,  1.0172,  0.0160],\n",
            "        [-0.4836,  0.4050, -0.4234,  ...,  1.4529, -0.6788,  0.4976],\n",
            "        [-0.0313,  1.1721,  0.6220,  ..., -0.9305,  1.2575,  0.4119]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0399,  1.2886,  6.7491,  ..., -2.3366, -0.4037, -0.8929],\n",
            "        [ 1.8554,  0.2369, -0.3012,  ...,  1.2757, -1.3069,  0.8203],\n",
            "        [ 1.6397,  0.1885, -0.5317,  ..., -0.2652, -0.6385, -0.4928],\n",
            "        ...,\n",
            "        [-0.2478, -0.6562, -0.8080,  ..., -0.5022, -0.5778, -0.2157],\n",
            "        [ 0.2530, -0.7260,  0.0579,  ...,  0.5125,  0.2535,  0.0237],\n",
            "        [-0.6206, -0.6811,  1.0122,  ..., -0.6409,  0.5767, -1.0984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6713,  0.3496,  0.1140,  ..., -0.0249, -0.0528, -0.4034],\n",
            "        [-0.8916, -0.2665, -0.8579,  ...,  0.7911, -0.3273, -0.1667],\n",
            "        [ 3.3342,  1.0938, -0.3502,  ...,  0.8004, -0.1808, -0.8055],\n",
            "        ...,\n",
            "        [ 2.3997,  1.0228,  0.5497,  ...,  0.8631, -1.1303,  0.3999],\n",
            "        [ 0.2853,  1.4673,  0.0631,  ...,  0.6513,  1.2187,  1.2452],\n",
            "        [-0.5953, -0.4407,  0.4800,  ..., -0.2302, -0.2451, -0.1871]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5167,  0.2245, -0.4668,  ...,  1.7299, -0.5845,  1.8031],\n",
            "        [-0.0575,  0.9293,  0.4920,  ..., -0.7718, -0.0085, -0.1524],\n",
            "        [-0.3351, -1.5776,  0.3000,  ..., -1.6487, -0.6066, -0.3637],\n",
            "        ...,\n",
            "        [ 0.1850, -0.2253,  0.2604,  ..., -1.2055,  0.1615, -0.4479],\n",
            "        [ 2.3543,  0.6800, -1.1927,  ...,  0.9837,  0.0490, -0.4511],\n",
            "        [-1.1602, -0.6975, -1.8194,  ...,  0.2044, -0.1460, -0.5401]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.7111,  0.6638,  0.2336,  ...,  0.5823, -1.5123, -0.5001],\n",
            "        [ 1.2070,  0.3819, -0.8239,  ...,  0.3740, -0.6860,  0.0118],\n",
            "        [-0.5851, -0.7513, -1.0250,  ...,  1.4639,  0.0680,  0.7310],\n",
            "        ...,\n",
            "        [-0.6024, -0.5359, -1.4239,  ...,  2.3462,  0.1594,  1.4046],\n",
            "        [-0.2087, -0.1665, -0.0615,  ..., -0.0089, -0.2474, -0.3200],\n",
            "        [-0.9481, -0.0710,  0.0402,  ..., -1.1915, -0.2402, -2.1108]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4728, -1.6863, -0.2232,  ..., -0.5935, -1.3456, -0.6555],\n",
            "        [-0.3901,  0.1557, -0.4721,  ...,  0.9266,  1.5677,  0.8440],\n",
            "        [ 0.5561, -0.6334, -0.1165,  ...,  0.4618, -0.1009, -0.4357],\n",
            "        ...,\n",
            "        [-0.2580,  1.0979,  0.0353,  ..., -0.8124,  0.5001, -0.3625],\n",
            "        [-0.6772, -0.0237,  0.0307,  ..., -0.3501, -0.4826, -0.4586],\n",
            "        [-1.5031,  0.2232,  0.9471,  ..., -1.0511,  0.8869, -0.5329]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0226, -2.0147,  0.4818,  ..., -1.2721, -1.1411, -1.0218],\n",
            "        [-1.5138, -1.6316, -0.0337,  ..., -1.4014, -0.2129, -0.6990],\n",
            "        [ 1.2019, -0.9062,  0.1940,  ..., -1.6208, -0.6537, -0.3286],\n",
            "        ...,\n",
            "        [-0.0918,  1.1674,  7.0721,  ..., -2.2529, -0.1234,  0.1061],\n",
            "        [ 0.0195,  0.4945,  1.0834,  ..., -0.0395, -0.2205,  0.6223],\n",
            "        [-0.2527,  0.2539, -0.2458,  ...,  2.0242, -0.8687,  1.6123]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0807,  0.1138, -0.5477,  ..., -0.6236, -0.5669, -1.5377],\n",
            "        [ 1.0003, -0.3226, -0.2292,  ..., -0.3209, -1.2636, -0.8110],\n",
            "        [-0.6975, -1.4293,  0.3983,  ...,  0.0695,  0.7655,  0.1340],\n",
            "        ...,\n",
            "        [ 0.9190, -0.5440, -0.1930,  ...,  0.4037, -0.3645, -0.3187],\n",
            "        [-0.7978, -0.5071,  0.3008,  ..., -1.4299, -0.6039, -0.8339],\n",
            "        [-0.2534, -1.2929, -0.1586,  ..., -1.4559, -1.5180, -1.0634]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.3411, -1.8474, -1.6778,  ...,  0.2285, -0.0445, -0.3064],\n",
            "        [ 1.3835,  3.3787,  3.2182,  ..., -0.9026, -0.1145, -0.2287],\n",
            "        [-1.2107,  0.1473,  0.1753,  ...,  0.6501,  4.5703, -0.0109],\n",
            "        ...,\n",
            "        [-0.3767, -1.1537, -0.5974,  ...,  0.3011,  1.3684, -0.5684],\n",
            "        [ 0.0667,  0.4416, -0.0738,  ...,  1.2654,  0.4021,  0.8557],\n",
            "        [-0.1748, -0.7728, -0.6875,  ..., -0.5236, -1.1974, -0.1924]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0361, -0.9706,  1.0119,  ..., -0.8296,  0.4663, -0.4643],\n",
            "        [-0.1445, -0.5357, -0.9254,  ..., -0.6536, -0.9696, -0.2259],\n",
            "        [-0.3367, -0.5114, -0.8114,  ..., -0.9002, -0.4184, -0.7700],\n",
            "        ...,\n",
            "        [-0.2406, -1.5919, -0.5563,  ..., -0.7854, -0.6089, -0.7493],\n",
            "        [-1.6945, -0.5651,  0.0634,  ..., -1.1856, -0.3178, -0.5902],\n",
            "        [-0.6153, -0.9513,  0.0671,  ..., -0.1127, -0.4974,  0.3470]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4769,  0.2057,  3.2782,  ..., -0.9693, -0.5073,  0.3639],\n",
            "        [-0.4318, -0.2606, -0.8300,  ..., -0.5452, -1.1890, -0.5531],\n",
            "        [ 0.6124,  0.1015, -2.5674,  ...,  3.7574, -0.5895, -0.5652],\n",
            "        ...,\n",
            "        [ 1.4322,  0.5527,  0.7121,  ...,  1.3087, -1.5904,  1.2402],\n",
            "        [-0.2268,  0.0906,  0.4791,  ...,  0.3722,  0.5258,  0.5670],\n",
            "        [ 0.0198, -1.3596, -0.0361,  ..., -1.0094, -1.7938, -0.5704]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5073, -1.0201,  0.1040,  ...,  0.0150,  0.7149, -0.5249],\n",
            "        [-0.8082, -0.4637, -0.1284,  ..., -0.6747, -0.2342, -1.2702],\n",
            "        [ 0.6969,  0.2998,  0.3154,  ..., -0.8198,  1.0836, -0.1566],\n",
            "        ...,\n",
            "        [ 0.0218, -0.7100, -1.5711,  ...,  0.6931, -0.5994, -0.4522],\n",
            "        [-0.2496, -1.0775, -0.6766,  ..., -0.6153, -0.4305, -0.4351],\n",
            "        [ 0.9534,  2.1028,  0.6735,  ...,  1.0456, -0.0862, -0.3105]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1873e+00,  3.5030e-01,  4.9872e-07,  ...,  1.0326e+00,\n",
            "          1.9197e+00,  1.5803e-01],\n",
            "        [-3.0959e-01, -2.7196e-01,  6.7708e-01,  ..., -6.7024e-01,\n",
            "         -1.4720e+00,  5.4302e-01],\n",
            "        [-4.9485e-01, -4.8354e-01, -2.8178e-01,  ..., -4.8029e-01,\n",
            "         -7.4256e-01, -1.7213e+00],\n",
            "        ...,\n",
            "        [-8.1915e-01, -1.6107e+00, -1.1926e+00,  ..., -1.4648e-01,\n",
            "          1.0629e+00, -9.3388e-01],\n",
            "        [-4.5560e-01, -7.3172e-01, -1.0011e+00,  ...,  2.5365e-01,\n",
            "          1.4092e-01,  1.6767e-01],\n",
            "        [-1.4273e+00, -1.5340e+00, -1.3648e+00,  ...,  8.2937e-02,\n",
            "          2.4752e-01, -2.2132e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.9120,  1.9954,  2.0687,  ..., -0.2979, -1.1553,  0.8920],\n",
            "        [-0.6797, -0.1992,  0.5983,  ..., -0.3262, -0.1579,  0.4940],\n",
            "        [ 0.2343,  0.9662,  1.0157,  ..., -0.2723, -0.5998,  0.2016],\n",
            "        ...,\n",
            "        [ 0.1264, -0.3658,  0.2732,  ..., -0.5483, -1.6380,  0.3413],\n",
            "        [-0.0296, -0.2403, -0.8265,  ..., -0.2803,  0.7976, -0.4777],\n",
            "        [ 1.4814,  1.0642, -0.1719,  ...,  0.4551, -0.4927, -1.6679]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7110,  0.5649, -0.5988,  ...,  0.5512,  0.1395,  0.6345],\n",
            "        [-1.1541, -1.3423, -2.1759,  ..., -0.1525, -0.6730, -0.8291],\n",
            "        [ 0.5445, -1.1260,  0.7361,  ..., -0.4789, -0.7561, -0.4747],\n",
            "        ...,\n",
            "        [-0.7600, -0.1677, -0.4749,  ...,  0.7194,  6.8400,  0.6816],\n",
            "        [-1.0054, -0.6209, -0.9449,  ..., -0.3365, -1.2809, -0.8849],\n",
            "        [-1.3341, -0.2120,  0.4107,  ..., -0.6688, -0.7051, -1.2886]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1903, -0.5992, -0.4683,  ..., -0.2327,  1.3080, -0.9622],\n",
            "        [ 0.3660, -0.9566,  1.8577,  ..., -0.1647, -0.7117, -0.3842],\n",
            "        [-0.7057,  0.5732,  0.6453,  ..., -1.2077,  1.0689, -0.6480],\n",
            "        ...,\n",
            "        [ 3.7368, -0.2728,  1.1259,  ...,  0.3505, -0.4292, -1.5161],\n",
            "        [-0.4834, -0.7384, -0.4100,  ...,  0.2640,  1.3838, -0.8588],\n",
            "        [ 2.1250,  0.4819, -1.3221,  ...,  2.0459, -0.9394, -1.5272]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4720, -0.6349,  1.2475,  ..., -0.6842, -0.5051,  0.0654],\n",
            "        [-0.8747, -0.6138, -0.3835,  ..., -0.5191, -0.2632, -0.5326],\n",
            "        [-0.3440, -0.7903, -0.3906,  ..., -0.9501, -0.3631, -0.8330],\n",
            "        ...,\n",
            "        [ 0.7175, -0.0737, -1.0204,  ..., -0.8391,  0.3749, -0.7335],\n",
            "        [-0.3014,  0.0968, -0.4869,  ..., -0.4814, -0.1395,  0.6550],\n",
            "        [-1.1307, -0.5286,  0.0086,  ...,  0.4832,  3.6641,  0.7248]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5699,  0.0154, -1.4856,  ...,  1.7198,  0.7007,  0.9672],\n",
            "        [-1.4430, -0.5114, -0.3097,  ..., -1.0138, -1.2401, -1.1538],\n",
            "        [-1.1333, -0.1441,  0.5121,  ..., -1.2866,  0.6051, -1.2235],\n",
            "        ...,\n",
            "        [ 0.0586,  6.7006,  1.2048,  ...,  0.5781, -0.5298,  1.2423],\n",
            "        [-1.0538,  0.1537,  0.2724,  ..., -0.4051,  0.2210,  0.9432],\n",
            "        [-0.5909, -1.5974,  0.6919,  ..., -0.1800,  0.4323, -0.3393]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5938, -0.6448, -0.2038,  ...,  0.3388, -0.9102,  0.8648],\n",
            "        [ 0.1515, -1.0540,  1.7258,  ..., -1.1406, -1.3127,  0.0384],\n",
            "        [-0.3900, -0.1453, -2.4124,  ...,  4.1592, -0.6585,  1.3148],\n",
            "        ...,\n",
            "        [-0.2677, -0.8016, -1.6540,  ...,  2.3671,  0.3756,  0.8931],\n",
            "        [-0.2143,  0.6854,  0.4807,  ..., -0.0218, -0.7974,  0.3817],\n",
            "        [ 0.6525, -1.1129,  0.9250,  ..., -1.0788, -1.0693, -0.7636]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1387,  0.1379,  0.1580,  ..., -1.2220, -0.5937, -0.6510],\n",
            "        [-0.7500, -1.1425, -0.0981,  ..., -0.0978, -0.4907,  0.2088],\n",
            "        [ 0.0683, -0.7131, -0.8726,  ..., -0.7908,  0.1338, -0.3927],\n",
            "        ...,\n",
            "        [-0.2204, -0.0062,  0.1817,  ...,  0.5315,  1.3029,  0.2330],\n",
            "        [-0.3886, -0.6276, -0.0209,  ..., -0.4584, -0.2799,  0.5480],\n",
            "        [-0.4969, -0.6958, -0.0237,  ..., -0.2449, -0.7250, -0.1161]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.3523,  1.6167,  0.4138,  ...,  0.2619, -0.5791,  0.0716],\n",
            "        [-0.8166, -0.0813, -0.9868,  ..., -0.2082, -1.1155, -1.4554],\n",
            "        [-0.6948, -1.1459, -0.4605,  ..., -0.0453, -0.1855,  0.7252],\n",
            "        ...,\n",
            "        [ 1.0086,  1.1547, -0.4136,  ..., -0.1128, -0.5500, -0.5838],\n",
            "        [-0.2463,  1.0264, -0.1211,  ..., -0.7253,  0.3927, -0.5917],\n",
            "        [-0.7905, -0.5750,  0.0400,  ..., -0.5971,  2.6375,  0.1585]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7147, -1.2575, -0.3054,  ...,  0.1648,  1.0402,  0.2369],\n",
            "        [-0.0124,  1.5879,  0.6630,  ..., -0.8603, -0.6727, -0.3684],\n",
            "        [ 0.4625,  0.9748,  1.3186,  ..., -0.6486, -0.4410, -0.7867],\n",
            "        ...,\n",
            "        [-0.0805,  0.0190,  0.2772,  ..., -0.9250, -0.2513, -0.2144],\n",
            "        [-0.0939,  0.7979,  0.3925,  ..., -0.9136, -0.7007, -0.1969],\n",
            "        [-0.6662, -0.4013,  0.9157,  ..., -0.4721, -0.8634, -1.3991]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.8344,  0.8513, -0.4822,  ...,  0.6920, -0.6057, -0.9227],\n",
            "        [ 4.0094,  2.1664,  0.3698,  ...,  1.0704, -1.3685, -0.7207],\n",
            "        [ 1.2009,  0.0318, -1.3350,  ...,  2.1181, -1.1629,  1.1618],\n",
            "        ...,\n",
            "        [-0.1919,  0.5219,  0.9136,  ..., -0.9943, -0.3445, -0.0066],\n",
            "        [-0.1466, -1.0289, -0.7329,  ..., -0.8487,  0.6922, -0.4579],\n",
            "        [ 0.7478,  0.3091, -0.1872,  ..., -0.0745, -0.7997,  0.4251]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5348, -0.5488, -0.0120,  ...,  0.0141,  0.2061, -0.5700],\n",
            "        [-0.3711,  1.3267, -0.4994,  ..., -0.5915,  1.6670,  0.0584],\n",
            "        [-0.4576,  0.0386, -0.6566,  ..., -0.2863,  0.0179,  0.8008],\n",
            "        ...,\n",
            "        [-1.2039,  0.4802,  0.3055,  ..., -1.1153, -0.6438, -0.2151],\n",
            "        [-0.2983, -0.0681, -0.6492,  ..., -0.4743, -1.4516, -1.6169],\n",
            "        [-0.8250, -0.8777,  0.4722,  ...,  0.0707,  2.4123,  1.7683]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,480  of  2,811.    Elapsed: 1:05:14.\n",
            "logits :  tensor([[-5.9326e-01, -2.1139e-01, -4.4504e-01,  ..., -3.7317e-01,\n",
            "          5.2401e-01,  4.9880e-01],\n",
            "        [ 6.6910e-01, -1.4619e-01, -3.2478e-02,  ..., -1.1364e+00,\n",
            "         -6.8109e-01, -6.2175e-01],\n",
            "        [ 4.0897e-03, -2.1986e-01,  5.3868e-01,  ..., -8.4127e-01,\n",
            "          2.4803e-01, -5.5089e-01],\n",
            "        ...,\n",
            "        [-7.7750e-01,  5.6306e-02,  6.7076e-02,  ...,  4.8145e-01,\n",
            "          7.2207e+00,  7.2285e-02],\n",
            "        [ 1.6119e+00, -2.6702e-01,  6.8129e-01,  ...,  2.7198e-01,\n",
            "         -5.6526e-01, -4.9439e-01],\n",
            "        [-1.4970e+00, -6.6496e-01,  4.5243e-01,  ..., -1.5317e+00,\n",
            "         -1.0550e+00, -9.2504e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0994, -1.6543, -0.0838,  ..., -1.1511, -1.5543, -0.7708],\n",
            "        [ 0.8126,  0.7565,  1.1675,  ..., -0.1718, -0.8192,  0.4773],\n",
            "        [-0.9266, -1.6671,  1.1389,  ..., -1.4467, -1.5038,  0.6045],\n",
            "        ...,\n",
            "        [ 0.5538,  0.0886,  0.5192,  ...,  0.0220, -0.1829,  0.7212],\n",
            "        [-0.5120, -0.6626, -0.6400,  ..., -0.4066,  0.1854,  0.3699],\n",
            "        [ 0.8756, -0.2287, -0.3610,  ...,  0.7656, -0.4253, -0.2567]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.2166,  0.7612, -0.8868,  ...,  1.7160, -0.7853, -0.5259],\n",
            "        [ 1.8924,  0.6166, -0.3069,  ...,  2.2104, -1.0388,  1.1778],\n",
            "        [ 0.1600, -0.3322,  0.8878,  ..., -0.4842, -1.1665,  0.8318],\n",
            "        ...,\n",
            "        [-0.1008,  0.0082,  1.5932,  ..., -0.3078, -0.7841,  0.6539],\n",
            "        [-0.2271, -0.6346,  0.0067,  ..., -0.2446,  0.4449, -1.3434],\n",
            "        [-0.6326,  0.2518,  0.6068,  ...,  0.0770,  1.4332,  0.4553]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2077,  0.7908, -1.2666,  ...,  0.5716, -0.8426,  0.3085],\n",
            "        [-0.4162,  1.8911,  0.3139,  ..., -0.4937, -0.4879,  0.0429],\n",
            "        [ 1.1896,  4.2303,  2.1516,  ..., -0.0803, -1.1989, -0.0708],\n",
            "        ...,\n",
            "        [-0.5266, -0.7449,  0.0290,  ..., -0.0378, -1.0479,  0.8841],\n",
            "        [ 0.2299, -0.2469, -0.5217,  ...,  0.8167,  0.6380, -0.1667],\n",
            "        [-0.8780, -0.5641, -1.0125,  ..., -0.0556,  0.4435,  0.0174]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.0461,  1.7172,  0.3059,  ..., -0.1032, -0.8673, -0.5541],\n",
            "        [-0.4840, -0.7289, -0.3409,  ..., -0.2443,  1.4492, -0.2278],\n",
            "        [-0.0489, -0.5802, -0.3337,  ...,  0.3795, -0.9449,  1.2289],\n",
            "        ...,\n",
            "        [ 0.4253,  0.1921, -0.7706,  ..., -0.1492, -0.9018, -1.0285],\n",
            "        [-1.1074, -0.1515,  0.3354,  ..., -1.1890, -0.6318, -1.6237],\n",
            "        [-0.6446, -0.5348,  0.4440,  ..., -0.5598,  0.1457, -0.7333]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6821,  0.5754,  0.6141,  ..., -1.5294,  0.9340, -0.4484],\n",
            "        [-0.2261,  1.6020,  0.7743,  ...,  1.7039, -0.9418,  5.8933],\n",
            "        [-0.3486,  0.0658, -0.2632,  ..., -0.2028, -0.9101,  1.1149],\n",
            "        ...,\n",
            "        [ 2.4684,  0.1628, -0.5512,  ...,  0.5461, -1.3166, -0.8339],\n",
            "        [ 1.6475,  0.0088, -0.3025,  ...,  0.5236, -1.0975, -0.5511],\n",
            "        [-0.5408, -1.4663, -0.0548,  ..., -0.1470,  0.0338,  1.8333]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6897, -0.7337, -0.5262,  ...,  0.4489,  6.2193,  0.0834],\n",
            "        [-0.0447,  0.0959,  0.2574,  ...,  0.0477, -0.4727, -0.0944],\n",
            "        [-1.0457, -1.1351,  0.1039,  ...,  0.0181,  2.2707,  1.8187],\n",
            "        ...,\n",
            "        [-1.1197, -0.6196,  1.3584,  ..., -0.6314, -0.0596,  1.1117],\n",
            "        [ 3.3616,  0.3152, -0.1298,  ..., -0.1574, -1.8776, -1.4972],\n",
            "        [ 0.0533,  0.5110, -0.2158,  ...,  0.6542,  0.3260,  0.1576]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2131,  0.5490,  0.5029,  ..., -0.0299, -0.9475,  0.2558],\n",
            "        [-0.1462,  6.6374,  1.3860,  ...,  0.0333, -0.4458,  0.2631],\n",
            "        [-0.6922, -0.3820, -1.3711,  ...,  1.6365,  0.1172,  1.0418],\n",
            "        ...,\n",
            "        [-0.3327, -0.3088, -0.3474,  ...,  0.3272,  0.6749,  0.2785],\n",
            "        [-0.9276, -0.7462, -0.3423,  ...,  0.8377,  2.5464,  3.2285],\n",
            "        [-0.5609,  0.8880, -0.1625,  ..., -0.5365,  2.1566,  0.2874]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8892, -0.8249, -1.8368,  ..., -0.2378, -0.5256, -1.0651],\n",
            "        [-1.0571, -1.4800, -1.6369,  ...,  0.0062, -0.5822,  0.6205],\n",
            "        [-0.8367, -1.0687,  0.1751,  ...,  0.4765,  1.1351, -0.3416],\n",
            "        ...,\n",
            "        [-0.3557, -0.7813, -0.8803,  ..., -0.3009, -0.7619, -0.1957],\n",
            "        [-0.9858, -0.2990,  1.7466,  ..., -1.4477, -0.2093, -0.7455],\n",
            "        [-1.3490,  0.1136,  0.4022,  ..., -0.5232,  0.5041,  1.3562]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.3108, -0.6806, -0.1401,  ..., -0.8105,  0.4903, -1.1517],\n",
            "        [ 0.2466,  0.3325,  0.4246,  ...,  0.2278,  1.9373,  0.0161],\n",
            "        [ 0.7381,  0.4191, -1.4412,  ..., -0.1383,  0.0232, -0.6513],\n",
            "        ...,\n",
            "        [ 1.3968,  0.5015,  1.0458,  ...,  0.2159, -1.2591,  0.8237],\n",
            "        [-0.7668, -1.3282, -1.5612,  ..., -0.0873, -0.2027, -0.9327],\n",
            "        [-0.2648,  0.2836, -1.5894,  ...,  1.7521,  0.0259,  0.4887]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.3277,  0.5298,  0.3889,  ..., -1.1577, -0.5360, -0.2520],\n",
            "        [ 2.2318, -0.6723,  0.8446,  ..., -0.0336, -0.6755, -1.0619],\n",
            "        [ 0.5962,  2.5459,  0.8314,  ..., -0.4019, -0.6287, -0.0064],\n",
            "        ...,\n",
            "        [ 1.6921, -0.0766, -0.1776,  ..., -0.4743, -1.4570, -0.4466],\n",
            "        [-0.6763, -0.1844,  4.1093,  ..., -2.6297, -0.9368, -0.5198],\n",
            "        [-0.2208,  0.1502, -1.2264,  ...,  2.1394,  0.1350,  1.6047]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3397, -0.5365,  0.2045,  ..., -0.3723,  0.6868, -1.1161],\n",
            "        [ 1.4533, -1.2076,  0.3297,  ..., -1.0957, -0.9452, -0.7416],\n",
            "        [-0.2806,  0.9682, -0.1985,  ..., -0.7364,  2.5497, -0.0068],\n",
            "        ...,\n",
            "        [ 0.3939,  0.2795, -1.4264,  ..., -0.9251,  0.2649, -0.8202],\n",
            "        [-0.2079, -0.6331, -0.7728,  ..., -0.6690, -0.4350, -1.2292],\n",
            "        [-0.8055, -0.6855, -0.3057,  ..., -0.8156, -0.0628, -0.0984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2727,  0.2455, -0.3591,  ...,  0.2934, -0.3050, -1.4062],\n",
            "        [-0.3146, -1.9766,  0.3538,  ..., -1.4477, -0.6375, -0.3584],\n",
            "        [ 1.2191,  0.1744, -2.5803,  ...,  6.9360,  0.3194,  0.8787],\n",
            "        ...,\n",
            "        [-1.1963,  0.4648, -0.1016,  ...,  1.4030,  0.2366,  7.4478],\n",
            "        [ 0.0165, -0.2724, -0.4090,  ..., -1.1507, -0.4103, -0.7903],\n",
            "        [-0.0812, -0.7630, -0.2233,  ..., -0.7703,  1.8500, -0.5047]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9147,  0.5729, -0.2057,  ...,  0.2980, -0.8806, -0.4387],\n",
            "        [-0.7413, -0.9086, -0.4620,  ...,  0.1377,  2.1079, -1.1613],\n",
            "        [ 0.2972,  0.7381,  0.2271,  ..., -1.1613, -0.0586, -0.3988],\n",
            "        ...,\n",
            "        [ 0.6067, -0.5322,  2.3988,  ..., -1.7311, -1.3283, -0.3919],\n",
            "        [ 0.6765, -0.5042, -0.6954,  ..., -0.0194, -1.5496, -0.7257],\n",
            "        [-0.1650, -0.3367, -0.6591,  ..., -0.5104,  0.4213,  0.1201]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1681, -0.8453,  0.8941,  ..., -0.9867,  0.0310, -0.2472],\n",
            "        [-0.9486, -0.8154,  1.6063,  ..., -0.9903, -0.9363, -0.8682],\n",
            "        [-0.2268,  0.7327, -0.2337,  ...,  0.0086, -0.2483,  0.3732],\n",
            "        ...,\n",
            "        [-0.8005, -0.3683,  1.0261,  ..., -1.2146, -0.9024, -0.9377],\n",
            "        [-0.6034, -1.0000,  2.8629,  ..., -2.0827, -0.5393, -0.9375],\n",
            "        [ 1.3605,  0.3490, -0.5479,  ..., -0.1241, -0.2618, -0.6082]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7137, -0.9963,  0.3042,  ..., -0.5883, -0.4105, -0.3578],\n",
            "        [ 0.7751,  1.0705,  0.6099,  ...,  1.1678, -0.7068, -0.3900],\n",
            "        [-0.3783, -0.3372, -0.0815,  ..., -0.3657, -1.4779, -0.1738],\n",
            "        ...,\n",
            "        [-0.7144,  0.2033,  0.4385,  ..., -0.4461,  0.4747,  0.9432],\n",
            "        [-0.6776, -1.0596, -1.1345,  ...,  0.7684,  2.8014,  0.1885],\n",
            "        [ 0.5152,  1.0750,  0.0348,  ...,  0.3093,  0.6350,  0.7337]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6206,  0.4022,  0.7472,  ..., -1.2993, -0.0083, -0.0991],\n",
            "        [-0.4843, -0.5462, -0.2110,  ..., -0.9757, -0.6618, -0.3729],\n",
            "        [ 2.9101,  0.1120, -1.3897,  ...,  1.9392, -0.7895, -1.0963],\n",
            "        ...,\n",
            "        [ 0.9415, -0.4612, -1.8462,  ..., -0.2211, -1.2251, -0.5494],\n",
            "        [ 0.6439,  0.9013,  0.5714,  ...,  1.0551, -1.0289, -0.4641],\n",
            "        [-0.8115, -1.0972, -0.5291,  ..., -0.2822,  0.9621,  0.3100]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6090, -1.3652,  1.0113,  ..., -0.8566, -0.7142,  2.3073],\n",
            "        [-0.1887,  0.2530,  0.6993,  ..., -1.6927, -0.9092, -0.8807],\n",
            "        [-0.3339, -0.2578, -0.1330,  ..., -0.2298,  0.5959, -0.7098],\n",
            "        ...,\n",
            "        [-0.6543, -0.4049, -0.1469,  ..., -1.1018, -1.1053, -1.7092],\n",
            "        [ 0.2137, -0.6250, -0.4952,  ..., -0.2477, -1.3311, -0.5524],\n",
            "        [-0.9006, -1.2648, -1.5439,  ...,  0.8277, -0.0916, -0.8956]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1086,  0.6672, -0.6136,  ..., -0.9718, -1.2450, -1.2502],\n",
            "        [-0.1414, -0.8328, -0.7881,  ...,  0.5241,  1.0870, -1.0237],\n",
            "        [-1.0834, -1.4819, -1.3367,  ...,  0.4163, -0.1099, -0.2001],\n",
            "        ...,\n",
            "        [ 1.3104, -0.6823,  1.6293,  ...,  0.0072, -0.5846, -0.7645],\n",
            "        [ 0.7001,  0.6981,  2.0842,  ..., -0.9890, -0.4589, -0.1490],\n",
            "        [ 0.9190,  5.3728,  1.8084,  ..., -1.2825,  0.6193, -0.6468]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.3053,  0.0287,  0.0731,  ..., -1.2554, -0.0703, -0.3976],\n",
            "        [ 1.9789, -0.0573, -1.6154,  ...,  1.2126,  0.2181, -0.6203],\n",
            "        [ 1.0642,  0.9558, -0.2022,  ...,  1.1171, -0.5268, -0.6787],\n",
            "        ...,\n",
            "        [ 0.0890, -0.0091,  0.0925,  ..., -0.6759, -0.4737, -0.0257],\n",
            "        [ 0.2437, -0.9325,  2.7794,  ..., -1.3512, -1.0727,  0.0652],\n",
            "        [-0.4335, -0.4778,  0.8109,  ..., -0.4209,  0.0193, -0.4582]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.7502,  0.8180, -0.6887,  ...,  0.9444, -0.5899, -0.5764],\n",
            "        [ 5.1082,  0.3212, -0.9443,  ...,  0.4729, -2.0631, -1.5879],\n",
            "        [-0.5716,  0.0628, -0.5735,  ..., -0.3688, -0.0269,  1.0352],\n",
            "        ...,\n",
            "        [-0.1657, -0.6490,  0.2595,  ..., -0.8624,  0.1873, -0.7494],\n",
            "        [ 0.2446, -0.4642,  0.9226,  ..., -0.8048, -0.5881,  0.7922],\n",
            "        [ 2.8384, -0.7535,  0.1341,  ...,  1.0738, -1.1149,  0.0841]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1397, -0.0930,  0.1154,  ..., -0.0210, -0.2034,  1.2869],\n",
            "        [-0.9611,  0.3800, -0.2313,  ...,  0.9310,  0.0121,  7.3893],\n",
            "        [-0.5063,  0.0223, -0.6432,  ...,  1.0093, -0.6200,  0.1716],\n",
            "        ...,\n",
            "        [-0.9926, -0.8853, -0.1274,  ..., -0.3673,  1.2516, -0.6033],\n",
            "        [-0.6997, -0.5827,  0.5312,  ..., -0.5318,  0.0096, -0.5549],\n",
            "        [-0.7802, -0.4394,  0.1986,  ..., -0.6341,  1.0625,  0.0698]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3722, -0.1305,  1.0536,  ..., -0.9469, -0.7885, -0.1304],\n",
            "        [-0.6496, -1.6950,  1.4808,  ..., -1.0081, -1.4551,  0.9149],\n",
            "        [-0.1746,  0.5633,  0.4532,  ..., -1.0781, -0.2520,  0.0486],\n",
            "        ...,\n",
            "        [-0.9374, -0.0502,  0.0063,  ..., -0.1759,  0.0301, -0.5052],\n",
            "        [-0.5636, -0.0176,  0.5037,  ..., -0.6147, -0.9290,  0.4190],\n",
            "        [ 0.4158, -0.6821,  1.9481,  ..., -1.3156, -0.9006,  0.0917]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.4228,  0.0018,  1.4665,  ..., -0.2048, -0.5395, -0.7043],\n",
            "        [-0.0911, -0.6796, -0.9062,  ..., -0.5171, -0.6104, -0.6910],\n",
            "        [-0.5020,  0.6794,  0.7123,  ..., -1.1123,  0.8889, -0.3178],\n",
            "        ...,\n",
            "        [-0.1606, -0.6521,  0.3574,  ..., -0.3487,  0.2842, -0.3594],\n",
            "        [-0.7484, -0.8902, -1.1772,  ...,  0.2060, -0.1030, -0.2023],\n",
            "        [ 0.3202, -1.6227,  0.5928,  ..., -1.4451, -0.4764, -0.1548]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4790, -1.0902, -1.6618,  ..., -0.5580,  1.3241, -0.5491],\n",
            "        [-1.0762, -0.8266, -1.0967,  ..., -0.1443,  0.5627,  0.6774],\n",
            "        [-0.7627, -1.3966, -0.0190,  ..., -0.0992,  1.5929, -0.2031],\n",
            "        ...,\n",
            "        [-0.4959,  0.6810,  0.5357,  ..., -0.8386,  1.8702,  0.5158],\n",
            "        [-0.6592,  0.1977, -0.8121,  ...,  0.8146, -0.1019, -0.0791],\n",
            "        [-0.4915, -0.9692,  0.5877,  ..., -0.4942,  1.1478,  1.7412]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3072, -1.6039, -0.1468,  ..., -1.5615, -1.2614, -0.7790],\n",
            "        [ 1.8787, -0.0603, -2.5376,  ...,  2.0974, -0.4669, -1.0049],\n",
            "        [-0.2998,  1.2029, -0.6068,  ...,  0.0454, -0.5254,  0.2465],\n",
            "        ...,\n",
            "        [-0.1407,  0.4027, -1.2051,  ...,  0.7445, -0.0658, -0.3128],\n",
            "        [ 0.1678, -1.9566, -0.5033,  ..., -1.2595, -1.3864, -0.8590],\n",
            "        [ 1.3058, -0.1881,  1.5259,  ..., -0.2440, -1.2009, -0.5638]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1560,  7.6534,  2.0093,  ..., -0.2880,  0.3611,  0.2348],\n",
            "        [-0.4221,  1.4317, -0.3004,  ..., -0.4150,  0.5633, -0.3256],\n",
            "        [-0.5522, -0.6285, -0.8223,  ...,  0.4694, -0.6273,  1.4769],\n",
            "        ...,\n",
            "        [-0.2658, -0.7402,  1.5706,  ..., -1.1756, -0.5859, -0.7045],\n",
            "        [-0.6020,  0.2442, -1.4379,  ...,  1.8597,  0.2222,  0.7562],\n",
            "        [-0.6434, -0.4244, -0.8909,  ...,  1.4370, -1.3239,  1.8396]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7341, -1.2063,  0.2963,  ..., -1.3095, -0.5974, -0.9721],\n",
            "        [ 0.0712,  0.4014,  0.4380,  ...,  0.2133,  0.8433,  0.3433],\n",
            "        [ 0.0332, -0.6910, -0.4303,  ..., -0.5469, -1.5044, -0.5808],\n",
            "        ...,\n",
            "        [ 0.1640,  7.4022,  1.5528,  ...,  0.0692,  0.3408,  0.3006],\n",
            "        [-0.6689,  0.2740,  0.3525,  ..., -0.3141,  0.2910,  0.8029],\n",
            "        [-1.2761, -0.0799, -1.1972,  ..., -0.5546, -0.6976, -0.8143]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0859, -1.2475, -0.2845,  ..., -0.0767, -1.2564,  1.1705],\n",
            "        [ 0.0254, -0.7532, -0.3377,  ..., -1.0617, -0.1731, -0.4940],\n",
            "        [-0.6896,  0.3993,  0.6162,  ..., -1.4507,  0.2883, -0.5708],\n",
            "        ...,\n",
            "        [ 0.3727,  2.4546,  1.0282,  ..., -0.3493, -0.4578, -0.2370],\n",
            "        [-0.2132, -0.0088,  0.5593,  ..., -0.3409, -1.0278,  0.4200],\n",
            "        [-0.5524, -0.2097, -0.0320,  ...,  0.4842, -0.3040,  0.4511]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6658,  0.7113,  0.1903,  ..., -0.7116,  1.8165,  0.2270],\n",
            "        [-0.3746, -1.1499, -0.5357,  ...,  0.1452, -1.0694, -0.3154],\n",
            "        [-0.3890, -0.5244,  0.5174,  ..., -0.7287, -0.3245, -0.0106],\n",
            "        ...,\n",
            "        [-0.9630, -1.1228, -1.0612,  ..., -0.0084,  1.3378,  0.2313],\n",
            "        [-0.4422, -0.3672,  0.2007,  ...,  0.3179,  0.9071,  0.4503],\n",
            "        [ 0.1816,  0.6687,  0.1249,  ..., -0.8684,  0.1745, -0.3976]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7698,  2.8832,  0.8995,  ..., -0.4528, -0.4715, -0.3800],\n",
            "        [-0.6086, -1.8100, -1.0845,  ...,  0.0630,  0.8827, -1.1440],\n",
            "        [-0.8474, -0.2742, -0.0927,  ..., -0.2043,  1.4347, -0.4014],\n",
            "        ...,\n",
            "        [ 0.4292,  0.6117,  1.7581,  ..., -0.6373, -0.6870,  0.2139],\n",
            "        [-0.9786, -0.4886, -1.1326,  ...,  0.2964,  0.5713, -0.2108],\n",
            "        [-0.2705,  2.4405,  0.5432,  ..., -0.9881, -0.8133,  0.0670]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8244, -1.4449,  0.7192,  ...,  0.5409,  0.5523, -0.3312],\n",
            "        [ 0.2171,  0.5311, -1.4546,  ...,  0.0230, -0.0206, -0.4357],\n",
            "        [-0.8904, -0.5204, -0.9529,  ...,  1.1978, -0.8295,  1.2519],\n",
            "        ...,\n",
            "        [ 3.2147,  0.1593,  0.7323,  ..., -0.0397, -1.1328, -0.7497],\n",
            "        [-1.0991, -0.7484,  2.1551,  ..., -0.4905, -0.1331,  0.5046],\n",
            "        [ 0.6111, -0.4872, -2.1605,  ...,  0.5605, -1.1690, -0.6067]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2738, -0.2139,  0.3974,  ..., -0.9160, -0.3731, -0.1199],\n",
            "        [ 0.6149,  0.4458, -1.3458,  ..., -0.3020,  0.5484, -0.7199],\n",
            "        [ 0.0948,  2.7536,  0.8715,  ..., -0.2024, -0.4856,  1.1426],\n",
            "        ...,\n",
            "        [-0.7849, -0.0438,  0.3175,  ...,  0.9632,  3.1642, -0.2947],\n",
            "        [-0.7868,  0.0375, -0.2335,  ..., -0.4222, -0.5119, -0.5638],\n",
            "        [-0.4491,  0.7793,  0.6879,  ..., -1.1031, -0.1477,  0.5148]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.3722, -0.4945, -0.4463,  ..., -1.0710,  0.0864, -1.1290],\n",
            "        [-0.5187, -1.0258, -0.3484,  ..., -0.8476, -1.4550,  0.0619],\n",
            "        [-1.0013, -1.2517,  1.7264,  ..., -1.2270, -0.8841,  1.2421],\n",
            "        ...,\n",
            "        [-0.1035,  1.2361,  0.7307,  ..., -0.4385,  1.3976,  0.3994],\n",
            "        [-0.4315, -1.2141, -1.6067,  ...,  0.1147, -0.0874, -0.4669],\n",
            "        [-0.3586, -0.0672,  0.5842,  ..., -0.5566, -1.2999,  0.7447]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 4.9606e-01,  3.9696e-01, -6.0661e-01,  ...,  1.8401e+00,\n",
            "          1.4026e+00,  8.2696e-01],\n",
            "        [ 1.1939e+00,  3.5277e-01, -9.7781e-01,  ..., -2.2774e-01,\n",
            "          1.1740e-01, -9.5963e-01],\n",
            "        [ 1.6869e-01, -7.1569e-04, -7.3673e-01,  ...,  5.4749e-01,\n",
            "          4.9967e-02, -2.3032e-01],\n",
            "        ...,\n",
            "        [-8.0295e-01,  1.2193e-01, -3.8730e-01,  ...,  6.7118e-01,\n",
            "         -5.9301e-01,  2.3415e-01],\n",
            "        [-9.7664e-01, -6.8693e-01, -6.5410e-01,  ..., -4.3620e-01,\n",
            "         -1.3506e+00, -4.1075e-01],\n",
            "        [ 4.3264e-01,  1.3059e-01,  3.1809e+00,  ..., -1.2180e+00,\n",
            "         -7.7164e-01, -8.3346e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2939, -0.9883, -0.6495,  ...,  0.5025, -0.4017,  0.2431],\n",
            "        [-0.6743,  0.1631, -0.7738,  ...,  0.9388, -0.4284,  0.1290],\n",
            "        [ 1.5277, -0.0811,  3.3230,  ..., -0.8682, -1.1945, -0.8333],\n",
            "        ...,\n",
            "        [-0.9798, -0.5254, -0.0772,  ..., -0.6007, -1.8617, -1.0269],\n",
            "        [ 0.7616,  0.9566,  1.4819,  ..., -0.5764,  0.0781, -0.4291],\n",
            "        [-0.9500,  0.1185,  2.3196,  ..., -1.3419, -0.7075, -0.1840]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1893,  0.3711,  0.3322,  ..., -0.5390, -0.0692,  1.0531],\n",
            "        [ 0.8596,  1.7267, -0.8675,  ...,  0.8315, -0.6448,  0.8102],\n",
            "        [ 1.5995, -0.7927,  1.0046,  ..., -0.8174, -1.8598,  0.1715],\n",
            "        ...,\n",
            "        [ 0.2508, -0.9949, -0.2986,  ..., -1.0572, -0.0266, -0.1954],\n",
            "        [ 1.4341, -0.4438, -0.6915,  ...,  0.6391, -0.2466, -0.5584],\n",
            "        [-0.3487, -1.0024, -0.1679,  ..., -0.3276, -1.0297, -1.4445]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.5231, -0.3244, -0.2856,  ..., -0.3674, -1.1669, -1.7022],\n",
            "        [-0.7691, -0.6892, -0.5927,  ..., -0.0560, -0.0679,  0.4096],\n",
            "        [-0.1948, -0.5316, -0.2008,  ...,  0.0697,  0.8498, -0.9084],\n",
            "        ...,\n",
            "        [ 2.0332,  2.6510,  0.4503,  ..., -0.0398, -0.4949, -1.3194],\n",
            "        [ 0.8260, -1.4036,  0.6002,  ..., -1.5914, -0.8828,  0.0497],\n",
            "        [ 2.4987,  0.9071,  0.3545,  ...,  0.6400, -0.7206, -0.7402]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7424, -1.4378,  0.2857,  ...,  0.0152,  0.3212, -0.4704],\n",
            "        [ 0.8117, -0.9292,  0.3999,  ..., -0.6555, -0.2012, -0.4463],\n",
            "        [-0.1182,  0.9604,  0.7634,  ..., -1.2547,  0.0177,  0.1706],\n",
            "        ...,\n",
            "        [ 5.7743,  0.8760,  0.2806,  ..., -0.0863, -1.7038, -1.5829],\n",
            "        [ 0.9187,  0.9874,  1.1336,  ...,  0.9747, -0.5382, -0.3588],\n",
            "        [-0.8147, -0.0956,  0.0511,  ...,  0.4271,  5.1369,  0.8304]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.3580, -0.8858,  3.2599,  ..., -0.9598, -1.1196,  0.2145],\n",
            "        [ 0.0334, -0.5688, -0.4478,  ..., -0.6907, -1.1648, -1.2078],\n",
            "        [-0.5558, -0.0111, -0.6317,  ...,  0.9294, -0.2882,  0.2367],\n",
            "        ...,\n",
            "        [ 0.0754, -0.7959, -0.2618,  ..., -0.0626, -0.8272,  0.4842],\n",
            "        [-0.4873, -0.1104, -0.3940,  ..., -0.1938,  0.2263,  0.0713],\n",
            "        [-1.1579, -0.1698, -0.6041,  ..., -0.7870, -0.4818, -1.4860]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,520  of  2,811.    Elapsed: 1:06:17.\n",
            "logits :  tensor([[-0.7334, -0.6373, -1.7260,  ...,  1.7309, -0.4920,  0.2843],\n",
            "        [ 0.1544,  1.1171, -0.6550,  ...,  1.3181,  1.9055,  1.5141],\n",
            "        [ 0.0781, -0.6709, -0.2026,  ...,  0.4830,  1.3224, -0.8774],\n",
            "        ...,\n",
            "        [-0.3101,  1.4713,  0.1906,  ..., -0.4172,  1.3290,  0.5662],\n",
            "        [-0.8499, -0.6258,  0.3176,  ..., -1.1339,  0.2562, -0.5264],\n",
            "        [-0.6871, -0.5155, -0.0615,  ..., -1.1116, -1.0077, -0.5561]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6671, -0.8266,  0.2349,  ..., -0.6998,  0.0872, -0.9283],\n",
            "        [-0.7052, -0.1592,  0.7264,  ..., -0.4227,  0.0317, -1.6084],\n",
            "        [-0.4358, -0.8625,  0.4985,  ..., -0.8944, -1.0103, -1.7218],\n",
            "        ...,\n",
            "        [-0.6739, -0.7767, -1.3223,  ...,  1.9359,  0.1659,  0.6689],\n",
            "        [ 4.0225,  2.4690, -0.5109,  ...,  1.3810, -1.0099, -0.7710],\n",
            "        [-0.2871, -1.3450,  0.1915,  ..., -0.8921, -0.7531, -0.1168]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2979, -0.1856,  0.4955,  ...,  0.3661, -0.4985,  0.2383],\n",
            "        [-0.0523, -0.4713,  0.0050,  ...,  0.8681,  0.0693,  0.0132],\n",
            "        [ 0.1533,  0.2242, -0.7515,  ...,  1.1890, -0.5891, -0.0802],\n",
            "        ...,\n",
            "        [-0.7840, -0.6647, -0.6095,  ..., -0.4716,  2.1981, -0.2951],\n",
            "        [-0.3430, -1.1182, -0.6241,  ..., -0.9860, -1.5057, -1.0291],\n",
            "        [ 0.5006,  0.0329, -0.8282,  ..., -1.4888, -0.8431, -0.4462]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3401, -1.0914, -0.7060,  ..., -0.2902,  0.0333, -1.1111],\n",
            "        [ 0.8665,  0.4435,  3.3988,  ..., -1.1440, -0.7576, -0.3610],\n",
            "        [-0.6297, -0.2747,  0.5888,  ..., -0.6440, -0.2649, -0.4242],\n",
            "        ...,\n",
            "        [-0.1688,  0.4573,  0.3365,  ...,  0.5867,  0.8500,  0.4451],\n",
            "        [ 1.4340,  0.3756, -1.7458,  ...,  2.4628,  0.6395, -0.5502],\n",
            "        [ 0.0443, -0.6499, -0.5404,  ..., -0.8438, -1.4307, -1.1384]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.6287, -0.2294, -1.6950,  ...,  0.3527, -0.0670, -0.7855],\n",
            "        [ 0.8723, -0.7504,  1.1579,  ...,  0.0046, -1.1633, -0.4397],\n",
            "        [-0.2390, -0.0973, -1.5857,  ...,  2.6207,  0.4869,  1.2582],\n",
            "        ...,\n",
            "        [ 0.8584, -1.1147, -0.0234,  ..., -1.4059, -1.0844, -0.2304],\n",
            "        [ 1.3901,  0.1131,  1.8142,  ..., -0.2674, -1.8226,  0.0048],\n",
            "        [ 0.2993, -0.3440, -0.8392,  ..., -0.9229, -0.4594, -1.0267]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9795, -0.8047,  0.1975,  ...,  0.7116,  2.7680,  1.4935],\n",
            "        [-0.0792,  1.4066,  0.8869,  ..., -0.5229,  1.3960,  1.1524],\n",
            "        [-0.0830,  0.3261, -0.2351,  ...,  1.2383,  1.4695,  0.9370],\n",
            "        ...,\n",
            "        [ 2.6429,  0.7838, -0.7850,  ...,  2.9548, -0.7249,  0.0735],\n",
            "        [ 0.8029,  0.3127,  1.0721,  ...,  0.1549, -1.1669,  1.0483],\n",
            "        [-1.2308, -0.9108, -0.9095,  ..., -0.7759, -1.4207, -1.0653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6699, -0.1503, -1.2205,  ..., -0.1726, -0.7074, -0.1178],\n",
            "        [ 0.0123,  0.0375, -0.2185,  ..., -0.4338,  1.7531, -0.0371],\n",
            "        [ 0.2672, -0.9479,  0.9349,  ...,  0.1161, -1.0431, -0.3994],\n",
            "        ...,\n",
            "        [ 0.6480, -0.8048, -0.3561,  ..., -0.9300, -0.1713, -0.7445],\n",
            "        [ 0.1603, -0.8492, -0.9034,  ..., -1.3421, -0.0177, -0.7202],\n",
            "        [-0.8524, -0.5861,  0.3702,  ..., -0.8903, -1.0837, -1.3477]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7204,  0.7713,  0.2969,  ...,  0.9461, -0.4875, -0.4733],\n",
            "        [-0.6633, -0.9653, -1.0458,  ..., -0.7858, -1.0428, -1.1897],\n",
            "        [-1.4066, -1.4892, -1.6461,  ..., -0.0681, -0.3021, -1.0830],\n",
            "        ...,\n",
            "        [ 0.2925, -0.8341,  2.9668,  ..., -0.8813, -0.6338, -0.0404],\n",
            "        [-0.2681, -1.2234, -0.8657,  ..., -1.1114,  0.6113, -0.3692],\n",
            "        [-0.7353,  0.2466, -0.3029,  ...,  0.3908, -0.2032,  0.1098]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8341,  0.9299, -0.3645,  ...,  0.8692,  0.8664,  0.5140],\n",
            "        [ 0.0849, -0.5583,  2.0633,  ..., -0.6520, -0.1217,  0.8026],\n",
            "        [-0.7421, -1.2638, -1.4097,  ...,  0.6799,  3.5673,  0.9745],\n",
            "        ...,\n",
            "        [ 0.3944,  0.7751, -0.4094,  ...,  0.0566, -0.5710, -0.9467],\n",
            "        [ 0.4527, -0.5569, -0.4894,  ...,  0.0926, -0.5636, -0.1867],\n",
            "        [-1.1669,  0.8684, -0.3353,  ...,  1.3452,  0.0490,  6.9728]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5662,  1.0360, -0.3640,  ..., -0.7422,  0.4496, -0.3335],\n",
            "        [-0.3219, -1.2538, -0.3962,  ..., -0.8683,  1.1607, -0.5393],\n",
            "        [ 0.4243,  1.2899,  1.8228,  ..., -0.6931,  0.1389, -0.2446],\n",
            "        ...,\n",
            "        [-0.1968, -0.3067, -0.1612,  ..., -0.8392,  0.6117, -1.0052],\n",
            "        [-0.7761, -0.7293, -0.7046,  ..., -0.8773, -0.6368, -0.2287],\n",
            "        [-0.8336, -0.7824,  0.3222,  ..., -0.8355, -0.4946, -1.6226]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7028,  1.4397,  1.3200,  ..., -0.0519, -0.7973,  0.3432],\n",
            "        [-0.4197, -0.5615, -1.1880,  ...,  0.2912,  0.4829,  0.1280],\n",
            "        [-0.0882,  0.8345,  6.5404,  ..., -2.7580, -0.6631, -0.2040],\n",
            "        ...,\n",
            "        [-0.6788, -0.9207, -0.7590,  ..., -0.7240, -0.1715, -0.5320],\n",
            "        [ 0.3622,  1.3761,  0.2030,  ...,  0.4591,  1.3330,  0.9983],\n",
            "        [ 0.3321,  0.9753,  1.6853,  ..., -0.6717, -1.3004,  0.9664]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3067, -0.3767,  0.3136,  ...,  0.4053,  0.6219,  0.7297],\n",
            "        [-0.9482, -0.6272, -0.5890,  ..., -0.5292,  0.9272, -0.9178],\n",
            "        [-0.4086, -1.2201,  1.5128,  ..., -1.1282, -1.4975,  0.1450],\n",
            "        ...,\n",
            "        [ 0.8834,  1.3370,  0.4331,  ..., -0.3661, -0.1498, -0.5397],\n",
            "        [-0.6457, -0.4519,  0.5127,  ..., -0.4130, -0.6207,  0.0253],\n",
            "        [-0.8930, -1.1791,  0.0924,  ...,  0.2010,  2.5739,  1.2680]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1743,  0.6718, -1.1422,  ..., -0.2310,  0.2251, -0.6551],\n",
            "        [ 2.4056,  0.9339,  0.6442,  ...,  0.5553, -2.1825,  0.0438],\n",
            "        [-0.9204, -0.6530, -0.7572,  ...,  0.3217,  1.6147, -0.1138],\n",
            "        ...,\n",
            "        [ 1.1823,  1.2367,  0.6763,  ...,  1.2241, -0.4659, -0.2504],\n",
            "        [ 1.5523, -0.0782, -0.1038,  ...,  0.7537, -1.2199,  0.0198],\n",
            "        [-1.2681, -0.5085, -0.2608,  ..., -0.7351,  1.0019, -0.9031]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6058, -0.6445, -1.4679,  ...,  0.2933, -1.1113, -0.3574],\n",
            "        [ 1.1623, -0.0102, -1.2542,  ..., -0.4646,  0.0306, -0.6064],\n",
            "        [-0.7738, -0.0942, -0.0582,  ..., -0.3999, -0.4079, -0.6048],\n",
            "        ...,\n",
            "        [-0.5190,  0.7214, -0.7509,  ..., -0.1560, -0.3786, -0.7761],\n",
            "        [-0.3065, -1.4803, -0.0995,  ..., -1.1756, -1.0404, -0.5994],\n",
            "        [ 0.9045,  0.4845, -1.1364,  ...,  0.4442,  0.2013, -1.2178]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7523,  0.2467, -1.9661,  ...,  2.1487,  0.8683, -0.2261],\n",
            "        [ 1.9205,  0.8711, -1.8230,  ...,  1.9876, -0.5380, -0.7614],\n",
            "        [-0.2500, -0.3589, -0.1852,  ..., -0.1505,  0.3158,  0.4903],\n",
            "        ...,\n",
            "        [-0.5761, -0.5619, -1.6424,  ..., -0.3530, -1.1746, -1.1418],\n",
            "        [ 1.0178,  0.5184, -0.0150,  ...,  1.5830, -0.9398,  1.7080],\n",
            "        [-0.2004, -0.3547, -0.0212,  ...,  0.8334, -0.1214, -0.2019]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.7573, -0.4435, -0.1477,  ..., -1.0552, -0.6336, -1.2436],\n",
            "        [-0.2338, -0.4120, -0.1761,  ..., -0.0698,  0.2330,  0.4502],\n",
            "        [ 0.8947,  0.3424, -1.1960,  ..., -0.0785, -0.4150, -1.7805],\n",
            "        ...,\n",
            "        [-0.2162, -0.8059,  0.2691,  ..., -0.4372, -0.7654, -0.5166],\n",
            "        [ 0.9561, -1.1520, -0.0514,  ..., -0.4509, -0.6569, -0.5062],\n",
            "        [-1.0449, -0.4822,  0.3249,  ..., -1.2277,  1.0907, -1.0723]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.3014, -1.1781,  1.8952,  ..., -1.4838, -0.9107,  1.4235],\n",
            "        [-1.1843,  0.4602,  0.7061,  ..., -0.8367, -0.4897, -0.3369],\n",
            "        [ 1.0142,  1.1591,  0.9265,  ...,  0.9842, -0.9475, -0.7113],\n",
            "        ...,\n",
            "        [ 0.1030, -0.3067, -0.7910,  ...,  0.7287, -0.8984, -0.7627],\n",
            "        [-0.9701,  0.0560,  0.2991,  ..., -0.3191,  0.8075,  1.0552],\n",
            "        [ 2.7375,  0.3364, -0.2418,  ..., -0.2760, -0.6005, -0.7953]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2454, -1.1764,  0.8344,  ..., -1.8447, -1.7979, -0.8173],\n",
            "        [-1.0940, -0.7910, -0.0657,  ..., -0.8055,  0.3113, -0.1100],\n",
            "        [ 0.2583, -1.0574, -1.6758,  ...,  1.1304, -0.1751,  1.1906],\n",
            "        ...,\n",
            "        [-1.5365, -0.6944,  0.3888,  ..., -0.6628,  0.2290,  3.0034],\n",
            "        [-0.7852, -0.1104,  1.2036,  ..., -0.2128,  0.0267, -0.2322],\n",
            "        [-1.2480, -1.9147, -1.5658,  ...,  0.0216,  0.4697, -0.3855]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1534, -0.3645, -0.1815,  ..., -0.4327, -1.7686, -1.0647],\n",
            "        [-0.4073, -1.4635,  0.5570,  ..., -0.0962,  0.8717, -0.3885],\n",
            "        [-0.6930,  0.0669,  0.2339,  ...,  0.0941, -0.2125, -0.3457],\n",
            "        ...,\n",
            "        [-0.5189, -0.7464,  0.3659,  ..., -0.7347,  0.0625, -1.0560],\n",
            "        [-1.1066, -0.3244,  1.2943,  ..., -1.7886, -0.5193, -1.1675],\n",
            "        [ 1.4764,  0.1200, -1.5378,  ...,  0.7012,  0.1952, -0.4283]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1357, -0.2659,  0.3762,  ...,  0.5109,  3.3644,  0.8999],\n",
            "        [ 0.9461, -0.1980,  1.4381,  ...,  0.1577, -0.6725, -0.5094],\n",
            "        [-0.6912,  0.5904, -0.2306,  ...,  0.7975,  0.6342,  0.7275],\n",
            "        ...,\n",
            "        [-0.5767,  0.3747, -0.6984,  ...,  1.6108, -0.9301,  0.9918],\n",
            "        [-1.2748,  0.2420,  0.4168,  ..., -1.4130, -0.4186, -0.2589],\n",
            "        [-1.1638,  0.0633, -0.5477,  ...,  2.3190,  0.7820,  5.8824]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9704, -0.8049,  0.3780,  ..., -0.4584, -0.8212,  0.2701],\n",
            "        [ 0.3453,  0.0422,  1.0093,  ..., -0.7314, -0.3894, -0.4358],\n",
            "        [-0.4594, -0.1078,  0.1349,  ..., -0.0784, -0.8015,  1.1949],\n",
            "        ...,\n",
            "        [-0.6962, -1.5311, -1.1727,  ..., -0.0840, -0.5741, -0.3405],\n",
            "        [-0.2316, -0.0170, -0.3271,  ..., -0.1166,  0.4836,  0.0632],\n",
            "        [ 3.9665,  1.0941,  0.9927,  ...,  1.0714, -1.0731, -0.4658]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2709, -0.7198, -0.0388,  ...,  0.9573,  0.1530,  0.3621],\n",
            "        [-0.7994, -0.4620, -1.0145,  ...,  1.4249,  0.3063,  0.6262],\n",
            "        [-0.6210, -0.8485, -1.1215,  ..., -0.2695,  0.8297, -0.4972],\n",
            "        ...,\n",
            "        [-0.2318, -0.8679, -0.2609,  ..., -0.7336, -1.4189, -1.2827],\n",
            "        [-0.4818,  0.5431, -0.4411,  ...,  0.9548, -0.0801,  0.0258],\n",
            "        [ 0.1253,  0.1849, -0.3613,  ..., -0.7865, -0.8459,  0.0541]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.4035,  0.0040,  0.4755,  ..., -0.1427, -1.0348,  0.1325],\n",
            "        [ 0.0711,  0.0542, -0.3218,  ...,  1.3952, -1.5867,  0.7472],\n",
            "        [-0.1780,  0.1324, -1.9318,  ...,  1.1934, -0.2723, -0.8162],\n",
            "        ...,\n",
            "        [-0.0625, -0.1425,  0.5740,  ..., -0.5307,  0.1541,  0.0694],\n",
            "        [-0.7188, -0.2435, -0.4726,  ..., -0.2748,  0.6284,  0.8866],\n",
            "        [-0.1355, -0.6412, -0.7793,  ..., -0.4748, -0.3431, -0.0281]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.0954,  1.7111, -0.3004,  ..., -0.1563, -1.0669, -1.3542],\n",
            "        [-0.5268, -0.9395, -0.1829,  ..., -0.1646, -0.9159,  0.6238],\n",
            "        [ 1.1628,  0.2329, -0.9190,  ..., -0.7144,  0.1771, -0.8476],\n",
            "        ...,\n",
            "        [-1.3436,  0.4316,  0.2089,  ...,  0.6205,  3.2255,  0.9318],\n",
            "        [ 0.2520,  0.7852,  0.0236,  ...,  1.2503,  1.0307,  1.3364],\n",
            "        [ 0.3821,  1.0209, -0.0912,  ..., -0.5577, -1.0038, -0.8974]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7565, -0.6835,  0.4594,  ..., -0.6367,  0.9206, -0.3702],\n",
            "        [-0.8843, -1.2031,  0.2644,  ...,  0.2196,  2.9600,  1.5730],\n",
            "        [-0.4868, -1.0180,  0.0726,  ..., -0.1619, -1.3235,  0.7186],\n",
            "        ...,\n",
            "        [-1.3895, -0.0808, -0.0045,  ..., -0.3214,  0.7654, -0.7989],\n",
            "        [-0.5659, -0.2217,  1.7397,  ..., -0.4749, -0.3423,  0.1884],\n",
            "        [ 0.6565,  1.3664, -1.2434,  ..., -0.0938, -1.1614, -0.3015]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1065, -0.6145,  0.0233,  ..., -0.7472, -1.0671, -0.2334],\n",
            "        [-0.1301,  0.1716, -1.1609,  ..., -0.0854, -0.4844, -1.0710],\n",
            "        [-0.6553,  0.3362, -0.1578,  ..., -0.1818,  1.2016, -0.0738],\n",
            "        ...,\n",
            "        [ 2.6187,  1.0317,  0.5705,  ...,  1.6861, -1.4287,  0.3937],\n",
            "        [ 3.8343,  0.6922,  0.7692,  ...,  0.2580, -0.4136, -0.9238],\n",
            "        [-0.7676, -1.3457,  0.5355,  ...,  0.1231,  0.5319, -0.4948]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1121e+00,  2.3745e-01, -1.9419e+00,  ...,  6.9945e+00,\n",
            "         -3.6773e-01,  7.1691e-01],\n",
            "        [ 6.7350e-01,  5.3516e-01,  1.3120e+00,  ...,  5.3280e-01,\n",
            "         -1.1039e+00,  1.3555e+00],\n",
            "        [ 7.1844e-01, -5.3557e-01, -1.3111e+00,  ...,  1.0461e+00,\n",
            "         -1.1154e-01, -1.5130e+00],\n",
            "        ...,\n",
            "        [-9.2499e-01, -8.7804e-01, -1.0274e-01,  ..., -1.8559e+00,\n",
            "         -9.8314e-01, -1.2267e+00],\n",
            "        [-1.1939e+00, -2.2411e-01,  1.7056e-03,  ..., -4.4168e-01,\n",
            "          1.7271e+00, -7.0568e-01],\n",
            "        [ 2.8491e+00,  7.2767e-01,  7.3384e-01,  ...,  5.8530e-01,\n",
            "         -1.8459e+00, -1.6130e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4345, -1.8863,  0.3170,  ..., -1.2820, -0.7376, -0.3600],\n",
            "        [ 0.0276, -1.0038, -1.8512,  ...,  0.0411, -0.6730, -0.5051],\n",
            "        [ 1.0274,  1.0294,  0.4921,  ...,  1.2719, -0.7119,  0.1091],\n",
            "        ...,\n",
            "        [ 0.3894, -0.2019, -0.9562,  ..., -0.0863, -1.3295, -0.5755],\n",
            "        [ 0.3978,  0.1933,  0.3313,  ..., -0.7698, -1.0196, -0.5020],\n",
            "        [-0.5572, -0.9325,  0.0433,  ..., -0.2705, -0.0292, -0.4596]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-2.5812e-01, -7.5471e-01, -4.2209e-01,  ..., -2.2599e-01,\n",
            "         -1.8823e-02,  3.3417e-01],\n",
            "        [ 4.9127e-01,  8.0296e-01,  6.9534e-01,  ..., -2.6349e-01,\n",
            "          1.5773e-04, -2.1692e-01],\n",
            "        [-2.2988e-01, -8.9661e-01, -3.6307e-01,  ..., -4.0809e-01,\n",
            "         -1.1697e+00,  4.9380e-01],\n",
            "        ...,\n",
            "        [-2.4298e-01, -8.8585e-01, -9.2594e-01,  ..., -5.4580e-01,\n",
            "          6.6520e-01,  4.4684e-01],\n",
            "        [ 2.7197e+00,  7.4623e-01,  5.3772e-01,  ...,  1.5013e+00,\n",
            "         -1.8478e+00,  2.5994e-01],\n",
            "        [-9.7751e-01, -7.7313e-01, -1.3130e-01,  ..., -5.8167e-01,\n",
            "          7.5643e-01, -6.5491e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.7028e-01,  6.2166e-01,  1.2489e-01,  ..., -8.5943e-01,\n",
            "          2.6396e-01, -1.4565e-01],\n",
            "        [-2.5266e-01, -5.9143e-04, -7.5307e-01,  ...,  2.3755e-01,\n",
            "          1.5119e-01,  4.4655e-01],\n",
            "        [ 2.7384e+00, -4.7300e-01, -1.3289e-04,  ...,  4.8586e-02,\n",
            "         -1.0120e+00, -7.2786e-01],\n",
            "        ...,\n",
            "        [ 3.7063e-01, -5.4717e-01, -7.0811e-01,  ..., -1.0977e+00,\n",
            "         -1.0289e+00, -9.6061e-01],\n",
            "        [-6.1172e-01, -7.6113e-01, -1.3329e+00,  ...,  4.6100e-01,\n",
            "          1.4660e-01,  2.1557e-01],\n",
            "        [-1.1594e+00,  3.2533e-01,  6.4806e-01,  ...,  1.1542e+00,\n",
            "         -5.9152e-01,  6.8021e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3497, -0.9846, -0.7333,  ..., -0.9551, -1.2665, -0.4765],\n",
            "        [ 0.4812,  1.2309,  1.7279,  ..., -0.5136, -0.7368, -0.0636],\n",
            "        [-0.9836, -2.2193, -1.8701,  ...,  0.0354, -0.7033, -0.1494],\n",
            "        ...,\n",
            "        [-0.6515, -0.5008, -1.1711,  ...,  1.4315,  3.7411, -0.0300],\n",
            "        [ 0.6632, -1.1375, -0.9077,  ...,  0.2617, -1.3422, -0.8412],\n",
            "        [-0.8620, -0.1644, -1.1098,  ...,  0.3085,  1.4627,  0.1283]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8119,  0.2685, -2.3962,  ...,  6.9349,  0.1470,  0.7108],\n",
            "        [-0.6570, -0.0642,  0.3290,  ..., -1.2824, -0.6771, -1.3706],\n",
            "        [ 0.5592, -0.4444, -0.5155,  ..., -0.8226, -1.0635, -1.0245],\n",
            "        ...,\n",
            "        [ 0.2454, -0.8767, -0.9406,  ...,  0.1587, -1.0092,  0.3765],\n",
            "        [ 1.9830, -0.5196, -0.3668,  ...,  0.8396, -0.6126, -0.4137],\n",
            "        [-0.3664,  0.0833, -0.1197,  ...,  0.6049, -0.1448,  1.9896]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5207,  1.1183, -0.2622,  ...,  0.0561, -0.1835, -0.2510],\n",
            "        [-0.1399, -0.9078, -1.2983,  ..., -0.4712, -0.6563, -1.4481],\n",
            "        [ 1.4474, -0.6282, -0.5648,  ...,  0.1393, -0.1317, -0.7096],\n",
            "        ...,\n",
            "        [-0.8771, -0.6043,  1.6174,  ..., -1.2628, -0.9384, -0.5256],\n",
            "        [-0.3421, -0.2523, -0.6632,  ..., -0.2193,  0.0747,  0.3704],\n",
            "        [ 1.1889,  0.5557, -0.3879,  ..., -0.6208, -0.9234,  0.1313]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.6080, -0.8663,  1.0820,  ..., -1.1908, -0.6107, -0.9775],\n",
            "        [-0.7361, -1.6226, -1.3786,  ...,  0.1721, -0.2523, -0.2321],\n",
            "        [-1.1178, -0.3269,  0.3273,  ..., -0.8525,  1.2448, -0.9078],\n",
            "        ...,\n",
            "        [-1.0341,  0.5589,  0.4997,  ..., -0.2147,  0.4561,  0.5961],\n",
            "        [-0.7811, -0.9677, -0.4899,  ..., -0.3152, -1.0990, -1.1130],\n",
            "        [-0.0118, -0.6248, -2.0411,  ...,  2.8917,  0.3731,  0.4341]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.4888, -2.2750, -1.2004,  ..., -0.6112, -0.0883, -0.1874],\n",
            "        [ 1.2398, -0.5668, -0.4942,  ...,  0.6402, -0.0521, -0.0878],\n",
            "        [ 0.5679,  1.3505,  1.9927,  ..., -0.4262, -0.1635,  0.3346],\n",
            "        ...,\n",
            "        [-0.0593, -0.6188, -0.1154,  ..., -0.6638, -1.1914, -0.4389],\n",
            "        [ 0.0242, -0.4380, -0.5754,  ..., -0.9131,  1.1081, -0.1944],\n",
            "        [ 0.9561,  0.1050,  0.0983,  ...,  0.6132, -1.5204,  1.4542]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3174, -0.6739, -1.6367,  ..., -0.7108, -1.2982, -1.2671],\n",
            "        [-0.8628, -0.8252, -0.7384,  ..., -0.5505, -1.3347, -0.6050],\n",
            "        [-0.8021,  0.0212, -0.6772,  ...,  0.4918, -0.3887, -0.4777],\n",
            "        ...,\n",
            "        [-0.5121, -0.2192,  1.6874,  ..., -0.8365, -0.7301, -0.8699],\n",
            "        [-0.8420,  0.1582,  1.9793,  ..., -0.7690, -1.0912, -1.1275],\n",
            "        [-0.5417, -0.9433, -1.3365,  ...,  0.3138,  0.0937,  0.0356]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0567,  7.3505,  1.6420,  ...,  0.2620,  0.2390,  0.6800],\n",
            "        [-0.0166, -1.2642,  0.8951,  ..., -0.6606, -0.1055, -0.2724],\n",
            "        [-0.5233,  0.2258, -0.2855,  ..., -0.8052, -0.5048, -1.1991],\n",
            "        ...,\n",
            "        [-0.3121,  1.0649,  0.6988,  ..., -0.1991,  1.2217,  0.5930],\n",
            "        [-0.1908, -0.2936, -0.3920,  ..., -0.5459, -1.2144, -1.2302],\n",
            "        [ 0.3595, -0.6359, -0.1352,  ...,  0.9335, -0.0239, -0.1087]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.7094,  0.7791, -0.3412,  ..., -0.1026, -0.2479, -0.9682],\n",
            "        [-0.7844,  0.7417,  0.9777,  ..., -1.5027, -0.4888, -0.6845],\n",
            "        [-0.8014, -0.2129,  0.5180,  ..., -0.3071, -0.5266,  0.4141],\n",
            "        ...,\n",
            "        [-0.6986,  0.4264,  0.7753,  ..., -1.1650,  0.7182, -0.7520],\n",
            "        [-0.2199, -0.6114,  0.3057,  ..., -0.1300, -0.8498,  0.6448],\n",
            "        [-0.1596,  0.9154, -0.2107,  ..., -0.6255,  0.2187, -0.5091]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3162, -0.6567, -0.3762,  ..., -0.9860,  1.0820,  0.3093],\n",
            "        [ 2.2322,  0.6906, -0.5782,  ...,  0.1389, -0.6231, -0.6844],\n",
            "        [-0.1815, -0.0437, -0.6981,  ..., -0.0147, -0.1345,  0.9764],\n",
            "        ...,\n",
            "        [ 0.6073,  1.6692,  1.4555,  ..., -0.1345, -0.4297, -0.0126],\n",
            "        [ 1.1998,  0.3819,  0.4820,  ..., -0.0333, -0.0051, -0.3296],\n",
            "        [-0.5680, -0.1164,  0.6310,  ..., -1.4763, -0.8403, -1.0104]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.4678, -0.2288, -2.0572,  ..., -0.0526, -0.7703, -0.9589],\n",
            "        [ 0.3748,  0.5753,  1.6472,  ..., -0.6893, -0.0123, -0.2447],\n",
            "        [-0.4884,  0.8444, -0.7908,  ...,  0.5449, -0.0908,  0.1797],\n",
            "        ...,\n",
            "        [-0.0718, -1.1514, -0.5423,  ..., -0.9928,  0.7352,  0.1526],\n",
            "        [ 0.1477, -0.2562,  0.0204,  ..., -0.5398,  1.1235, -0.3799],\n",
            "        [ 1.0229, -1.2203, -1.4591,  ..., -0.8285, -0.6842, -0.6768]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,560  of  2,811.    Elapsed: 1:07:20.\n",
            "logits :  tensor([[ 2.9157e+00,  5.6734e-01,  1.0715e+00,  ...,  1.2036e-01,\n",
            "         -1.6858e+00, -6.9722e-01],\n",
            "        [-9.8397e-01, -7.1519e-01, -7.4319e-01,  ...,  2.2839e-01,\n",
            "         -4.8830e-01,  1.0259e-01],\n",
            "        [-1.1394e+00,  4.3285e-02,  3.4552e-01,  ..., -5.2323e-01,\n",
            "          2.4343e+00, -3.7111e-01],\n",
            "        ...,\n",
            "        [-8.8269e-01, -5.2642e-02,  3.8934e-01,  ...,  2.8409e-01,\n",
            "          4.3305e+00,  6.1425e-02],\n",
            "        [-7.6226e-01, -1.2057e-03,  3.4703e-01,  ...,  3.3952e-02,\n",
            "         -2.8475e-01, -3.7829e-01],\n",
            "        [ 1.4224e-01,  4.0095e-01, -1.0714e+00,  ...,  5.9168e-01,\n",
            "         -1.4674e-02,  1.3632e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0158, -0.9548, -0.7110,  ..., -0.3093,  0.8959,  0.7837],\n",
            "        [-0.8758,  0.0468, -0.1330,  ...,  0.7395,  0.7235,  0.5207],\n",
            "        [-1.3641, -0.1461,  0.0473,  ..., -1.3089, -0.9811, -1.7158],\n",
            "        ...,\n",
            "        [ 0.2363, -0.3486,  0.6187,  ..., -1.1565,  0.4480, -0.2751],\n",
            "        [-1.0854,  0.2791, -0.4969,  ...,  0.8733,  2.8873, -0.2210],\n",
            "        [-0.5578, -0.8060, -1.4620,  ..., -0.4677, -1.3669, -0.7240]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1553, -1.0975,  0.0211,  ..., -0.5554, -1.1867, -0.2065],\n",
            "        [-0.3009,  0.2270,  2.0388,  ..., -0.7562, -0.4496,  0.3337],\n",
            "        [-0.8209, -1.1360, -0.9648,  ...,  0.0766,  1.2447,  0.3828],\n",
            "        ...,\n",
            "        [-0.3996, -0.6160, -0.8947,  ..., -0.7384, -1.2205, -1.1824],\n",
            "        [-1.1655, -0.0629, -0.6383,  ...,  0.8276,  3.5427,  0.2057],\n",
            "        [ 0.3234, -0.3411, -0.8153,  ..., -0.0649, -0.1684, -0.7804]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9608,  0.1089, -0.2254,  ...,  1.2196,  0.0381,  0.4657],\n",
            "        [ 0.5481, -0.4551, -0.6988,  ..., -1.1824, -0.5696, -0.3269],\n",
            "        [-1.1640, -0.5182,  0.7744,  ..., -0.3869, -0.4561,  0.9015],\n",
            "        ...,\n",
            "        [ 1.0080,  0.3163, -1.6628,  ...,  1.4399,  0.0749, -0.5514],\n",
            "        [-0.3504, -0.8615, -1.4559,  ...,  2.2472,  0.3368,  1.2898],\n",
            "        [ 0.2349, -0.5489, -0.5047,  ...,  0.3187,  0.3466,  0.4881]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1558,  1.1532,  0.4777,  ...,  0.0780,  1.1308,  0.5981],\n",
            "        [ 4.0787,  0.6759,  0.3466,  ...,  0.6769, -1.7737, -0.1099],\n",
            "        [ 1.1079, -0.2631, -1.5220,  ...,  0.3607, -1.1790, -1.3262],\n",
            "        ...,\n",
            "        [ 2.0936,  0.8052, -1.3195,  ...,  1.7210, -0.3850, -0.3739],\n",
            "        [-1.0284, -0.5502, -0.0515,  ...,  0.9063,  1.1241,  3.3967],\n",
            "        [-0.9826, -0.1323, -0.0060,  ..., -0.4378, -0.3627, -0.6147]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.2360, -0.3136,  0.4204,  ..., -1.0697,  0.5594, -1.3046],\n",
            "        [-0.8104,  0.3229,  0.1401,  ..., -0.5339,  0.8221, -0.3498],\n",
            "        [ 0.6111, -0.0635, -1.4201,  ...,  1.0969,  0.6173, -0.8075],\n",
            "        ...,\n",
            "        [-0.8187, -1.0936, -0.9318,  ..., -0.7096, -0.9204, -0.7829],\n",
            "        [ 0.2233, -0.8728,  2.0161,  ..., -1.2513, -1.2992, -0.4319],\n",
            "        [ 1.5309,  0.0901, -1.7058,  ...,  2.7913,  0.1787, -0.3095]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1177e+00,  1.1936e-01,  2.2992e-01,  ...,  7.5943e-01,\n",
            "         -1.1642e+00,  1.1992e+00],\n",
            "        [-1.2113e+00,  9.4133e-01,  5.7685e-01,  ...,  4.8299e-02,\n",
            "          1.8329e+00,  5.6449e-01],\n",
            "        [-1.1347e+00, -1.6270e+00, -1.4186e+00,  ..., -4.2988e-01,\n",
            "         -4.3452e-01, -7.2462e-01],\n",
            "        ...,\n",
            "        [ 1.8018e+00,  3.0344e-03, -1.0963e+00,  ...,  1.1565e+00,\n",
            "          2.1109e-01, -3.3521e-01],\n",
            "        [-5.4045e-01, -6.6668e-01,  5.6991e-01,  ..., -1.1239e+00,\n",
            "          9.5637e-02, -4.4338e-01],\n",
            "        [-5.3412e-01, -4.7096e-01, -2.0552e+00,  ...,  1.1415e+00,\n",
            "          4.9042e+00, -4.6312e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1771, -0.9464,  0.9342,  ..., -0.8866,  0.8128, -1.1342],\n",
            "        [-0.3528, -0.9187,  0.1602,  ..., -0.4410, -0.5664, -0.8685],\n",
            "        [ 1.8976,  0.4420, -0.4369,  ..., -0.4383, -0.6281, -0.3915],\n",
            "        ...,\n",
            "        [-0.2569, -1.1206, -1.4096,  ...,  0.9953,  0.4480,  1.3375],\n",
            "        [-1.0904, -1.1799, -1.5071,  ..., -0.6701,  0.0264, -0.9695],\n",
            "        [-0.6904,  1.1337,  0.1184,  ..., -1.0035,  0.3904, -0.1949]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8689, -0.6830, -0.2241,  ...,  0.3846,  1.9927,  3.5891],\n",
            "        [ 3.7538,  0.3790, -0.1951,  ..., -0.5813, -0.9511, -1.2896],\n",
            "        [-0.4086, -0.0223,  0.9442,  ..., -0.2726, -0.5740, -1.4268],\n",
            "        ...,\n",
            "        [ 0.0357,  0.9936,  4.3646,  ..., -2.5777, -0.5413, -0.7572],\n",
            "        [-0.5188, -0.1498,  0.0275,  ...,  1.2990,  0.8639,  1.3696],\n",
            "        [ 1.2600, -0.1695,  0.9825,  ...,  0.5635, -1.3107,  0.0425]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-4.5687e-01, -5.1567e-01,  5.8301e-01,  ..., -6.0639e-01,\n",
            "          1.6018e+00, -1.6729e-01],\n",
            "        [ 3.6792e-01,  1.2927e+00,  4.4426e-03,  ..., -6.0800e-01,\n",
            "         -2.7061e-01, -1.3491e+00],\n",
            "        [-2.8913e-01,  2.7664e-01, -4.1698e-01,  ...,  8.3238e-01,\n",
            "          8.2074e-02,  4.8918e-01],\n",
            "        ...,\n",
            "        [-4.8602e-01, -2.1808e-01, -5.3084e-01,  ..., -5.3647e-01,\n",
            "          1.4066e-01,  7.4217e-01],\n",
            "        [ 1.1854e+00,  6.6084e+00,  2.7547e+00,  ..., -5.1769e-01,\n",
            "          4.5268e-02,  5.4413e-01],\n",
            "        [-5.2760e-01, -5.0181e-01,  3.0932e-01,  ...,  3.7309e-01,\n",
            "          1.1409e+00, -1.2019e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2962, -0.4047, -0.6412,  ..., -0.2107, -1.1922, -0.3905],\n",
            "        [-0.0121, -0.4643, -1.1353,  ..., -1.1925, -0.4435, -0.8040],\n",
            "        [-0.8886, -0.6307, -0.0774,  ..., -0.1548, -0.7971,  0.7194],\n",
            "        ...,\n",
            "        [-0.7832, -0.8365, -0.8290,  ..., -0.7843, -1.2985, -1.1507],\n",
            "        [-0.8662, -1.4120,  1.5558,  ..., -1.1260, -0.8834,  0.9281],\n",
            "        [ 0.3014,  0.6262,  0.0021,  ..., -0.6765,  0.3254, -0.3683]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7737, -1.1137, -0.2249,  ..., -0.2121,  2.1260,  0.1625],\n",
            "        [-0.9855, -0.4740,  0.1475,  ..., -0.8496,  0.3633, -0.7659],\n",
            "        [-1.1289,  0.8234, -0.1825,  ...,  1.2168,  0.5018,  6.6098],\n",
            "        ...,\n",
            "        [-0.5779, -1.7895, -0.9611,  ...,  0.2329,  0.9190, -1.0300],\n",
            "        [-0.8138, -0.3901, -1.5699,  ...,  0.0501, -1.2117, -0.7562],\n",
            "        [-0.7259, -0.8616, -0.5046,  ..., -0.7430, -1.0753, -0.2802]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.5330e-01, -4.4632e-01, -1.2276e-01,  ...,  7.3922e-01,\n",
            "          1.7976e-02, -2.0982e-01],\n",
            "        [ 1.4822e+00, -3.2417e-01, -2.1369e-02,  ...,  2.7623e-01,\n",
            "         -8.0828e-01, -4.1343e-03],\n",
            "        [-1.3497e+00, -1.2588e+00, -1.1869e+00,  ...,  5.1549e-02,\n",
            "         -1.5928e+00, -8.3035e-01],\n",
            "        ...,\n",
            "        [-2.1533e-01, -7.4495e-01, -1.6436e-01,  ..., -8.3383e-01,\n",
            "          6.2408e-01, -1.0199e-01],\n",
            "        [ 4.2732e+00,  3.9592e-01, -4.5573e-02,  ...,  2.6740e-01,\n",
            "         -1.0996e+00, -1.5523e+00],\n",
            "        [-9.7817e-01, -5.1912e-01, -7.8193e-01,  ...,  5.2285e-01,\n",
            "         -4.3176e-02, -3.0183e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9644, -0.4468, -0.3944,  ..., -0.1767, -0.4314, -0.8963],\n",
            "        [-0.1655, -1.0382, -0.1625,  ...,  0.0736, -1.0096,  1.0338],\n",
            "        [ 1.2261, -0.9988,  1.0862,  ..., -1.5006, -0.4674, -0.4322],\n",
            "        ...,\n",
            "        [-1.1823, -0.3740, -0.3289,  ..., -0.5428, -0.5056, -1.1176],\n",
            "        [-0.7080, -1.0524,  0.0973,  ..., -1.0603, -1.5148, -0.5323],\n",
            "        [-0.7789, -1.8727, -1.6636,  ...,  0.0150,  0.1112, -0.0136]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1911, -0.9294,  0.1346,  ..., -0.8497, -1.8880, -1.5181],\n",
            "        [-0.7617, -0.1673, -0.1345,  ..., -0.4645,  1.3324, -0.4965],\n",
            "        [-0.2450,  0.1094, -0.7059,  ...,  1.4044,  5.2422,  0.3365],\n",
            "        ...,\n",
            "        [-0.7093,  0.1989,  0.4467,  ..., -1.2331, -0.3314, -0.4266],\n",
            "        [ 1.3201, -0.1508, -2.5272,  ...,  6.5853, -0.3611,  1.0230],\n",
            "        [ 0.5861,  0.3215,  0.9899,  ...,  0.3334, -1.4564,  1.8163]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2685,  0.6949,  1.6845,  ..., -0.7302, -0.3104, -0.3503],\n",
            "        [-0.0622, -0.8231, -0.4326,  ..., -0.7118, -0.9307, -0.9016],\n",
            "        [ 0.0494,  0.1596, -0.4293,  ..., -0.3212,  2.3113, -0.6551],\n",
            "        ...,\n",
            "        [ 0.3505,  1.0479,  1.6667,  ..., -0.6067, -0.4450, -0.3013],\n",
            "        [ 0.3355, -0.3074, -0.2001,  ..., -1.2609, -0.4215, -0.8395],\n",
            "        [ 0.2992, -0.2192, -1.0593,  ..., -1.3092, -0.2678, -0.1561]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.4923e-01,  7.4880e+00,  1.6410e+00,  ..., -3.6077e-01,\n",
            "          4.4345e-01,  3.0016e-01],\n",
            "        [-4.5807e-01, -8.4063e-03, -6.3576e-01,  ...,  1.0825e-02,\n",
            "          9.6643e-02, -1.1435e-01],\n",
            "        [-4.1233e-01, -1.4627e+00,  1.2147e+00,  ..., -1.3165e+00,\n",
            "         -7.0324e-01,  7.0769e-03],\n",
            "        ...,\n",
            "        [-4.8309e-01, -7.0103e-01, -8.6728e-01,  ..., -3.7985e-01,\n",
            "         -1.0048e+00, -3.2611e-01],\n",
            "        [ 1.8564e+00,  8.5624e-01,  1.5774e-01,  ...,  1.1037e+00,\n",
            "         -1.2696e+00,  4.8820e-01],\n",
            "        [-9.3391e-01, -1.4133e+00, -1.4701e+00,  ...,  5.4696e-02,\n",
            "         -3.8738e-01, -4.4564e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8427,  0.0944, -0.1344,  ...,  0.3498, -1.5115, -0.7827],\n",
            "        [-0.4190, -0.2919, -0.6174,  ...,  0.5904,  6.2633, -0.0616],\n",
            "        [ 1.6788,  1.1791,  0.3220,  ..., -0.0869, -0.1578, -0.9215],\n",
            "        ...,\n",
            "        [-0.7526, -0.9108,  0.7990,  ..., -1.1049, -1.2670,  0.4594],\n",
            "        [ 0.0281, -1.4649, -0.2559,  ..., -0.8177, -1.4015, -0.6296],\n",
            "        [-0.8019, -1.4968, -1.8267,  ...,  0.2602,  0.2548,  0.0408]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.8921e-01, -7.2875e-01, -9.3607e-01,  ..., -6.7801e-01,\n",
            "         -6.8869e-01, -7.2358e-01],\n",
            "        [ 4.9598e+00, -5.6158e-02, -1.5134e-01,  ..., -4.5120e-02,\n",
            "         -8.5567e-01, -1.7137e+00],\n",
            "        [-6.7302e-02, -1.1466e+00,  1.9308e-03,  ..., -7.6166e-01,\n",
            "         -1.2860e+00, -9.4741e-01],\n",
            "        ...,\n",
            "        [-1.4308e-02,  8.6430e-02,  4.6164e-01,  ...,  5.2794e-01,\n",
            "          1.2905e+00,  8.4096e-01],\n",
            "        [-4.0562e-01,  2.3982e-01, -5.9176e-01,  ...,  1.2366e+00,\n",
            "         -1.0174e+00,  2.8929e-02],\n",
            "        [ 2.9894e-01, -1.6452e+00, -3.2768e-01,  ..., -8.8805e-01,\n",
            "         -1.1517e+00, -7.2834e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0937, -0.2074, -1.3208,  ...,  0.5671,  0.6433, -0.2160],\n",
            "        [-1.0189, -1.1891, -0.2853,  ...,  0.7162,  1.0755, -0.4086],\n",
            "        [-0.2734, -0.3154, -0.0258,  ..., -0.8150, -0.9490,  0.2482],\n",
            "        ...,\n",
            "        [-0.6723, -0.9959,  2.0585,  ..., -1.4678, -1.3770, -0.5092],\n",
            "        [-0.1189, -1.4002, -0.2026,  ..., -1.1056, -0.7023, -0.9222],\n",
            "        [ 2.5885, -0.5805, -0.7117,  ..., -0.0331, -1.0202, -1.1620]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0223, -1.2294, -0.8535,  ..., -0.3420, -1.6736, -0.3478],\n",
            "        [ 5.2990,  0.3264, -0.1240,  ...,  0.4247, -1.9235, -1.5070],\n",
            "        [-1.1243, -0.3853,  0.4049,  ..., -0.7190,  0.6237, -0.5262],\n",
            "        ...,\n",
            "        [-0.5654, -1.3051, -0.1382,  ...,  0.2778,  1.8010,  1.7765],\n",
            "        [ 0.6328,  0.7798, -0.1502,  ...,  0.8953, -0.2180,  0.4491],\n",
            "        [-0.2716,  0.3129,  0.3612,  ...,  0.4737,  1.4009,  0.6445]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3701, -1.5573, -0.3967,  ..., -1.3272, -0.4575, -0.5584],\n",
            "        [-0.7564, -0.1262,  0.2232,  ...,  0.1756, -0.5334, -1.1472],\n",
            "        [-0.5097,  0.1015, -0.5258,  ..., -0.4604, -0.0148,  0.6268],\n",
            "        ...,\n",
            "        [ 0.2198,  0.6920,  0.2675,  ..., -0.9861,  0.3392, -0.5775],\n",
            "        [ 1.1453,  1.3693, -0.0446,  ..., -0.3438, -0.5716, -1.6854],\n",
            "        [ 0.0278,  0.0436, -1.0000,  ...,  1.1588, -0.9281,  0.5183]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6683, -0.5872,  0.0236,  ..., -0.2959,  1.3743, -0.1377],\n",
            "        [-0.9836, -0.4680, -0.6867,  ..., -0.6407, -0.7733, -0.9854],\n",
            "        [-0.9644,  0.2920,  0.7450,  ..., -0.3807,  0.6423,  0.3005],\n",
            "        ...,\n",
            "        [-0.4480, -1.2288,  0.5138,  ..., -1.4302, -0.9164, -0.0667],\n",
            "        [-0.1417,  1.3773,  1.9547,  ..., -0.8421, -0.1087,  0.0455],\n",
            "        [-1.2820, -0.3053, -0.1657,  ..., -0.7701,  0.0315, -0.6622]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8473,  1.8978,  0.2003,  ...,  0.0945, -0.6747, -0.1309],\n",
            "        [ 1.8108, -0.1582, -1.6751,  ...,  2.0518, -0.8092, -0.7923],\n",
            "        [ 1.9293,  0.2273,  0.5078,  ...,  0.2073, -1.4866, -0.3114],\n",
            "        ...,\n",
            "        [ 1.1266,  0.4989,  1.6348,  ...,  0.8172, -0.8291,  1.6282],\n",
            "        [ 2.7504,  1.0943,  1.4351,  ..., -1.0959, -0.0675, -1.2167],\n",
            "        [-0.2889, -1.6274,  0.1913,  ..., -1.3717, -1.2934, -0.7054]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.0573,  0.3962, -1.0343,  ..., -0.2213,  0.3338, -0.4840],\n",
            "        [ 0.8243,  2.3569, -0.0941,  ..., -0.4066,  0.6486, -0.6196],\n",
            "        [-1.0127, -1.2754, -0.8690,  ..., -1.0968,  0.0304, -0.4494],\n",
            "        ...,\n",
            "        [ 0.0670,  0.1632,  0.7547,  ..., -1.2635, -1.3065, -1.3595],\n",
            "        [ 2.2195,  0.9298, -0.9393,  ...,  0.6523,  0.5466, -0.3480],\n",
            "        [ 0.5171,  1.3416,  1.8821,  ..., -0.1415, -0.4346,  0.4296]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7137, -0.8332, -0.6037,  ...,  0.1793, -0.8129,  1.8257],\n",
            "        [ 0.0824, -0.2169,  0.0940,  ..., -0.6859, -1.1361, -1.0546],\n",
            "        [ 0.3348,  0.4181,  1.2287,  ..., -0.2080, -0.9162,  0.5309],\n",
            "        ...,\n",
            "        [-0.2465, -0.0354,  0.9965,  ..., -0.2765, -0.6879,  2.0917],\n",
            "        [-0.0285,  0.8037,  0.0390,  ...,  0.8050,  1.2044,  1.5941],\n",
            "        [ 0.2265,  0.1037, -2.2665,  ...,  4.2155, -0.5236,  1.0068]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9908, -1.4502,  0.9101,  ..., -0.8641, -0.7584,  1.5160],\n",
            "        [-0.9554, -0.9773, -1.1322,  ..., -0.6590, -1.0210, -1.1317],\n",
            "        [-0.6185, -0.1188,  0.3881,  ..., -0.3743,  0.4596, -0.5336],\n",
            "        ...,\n",
            "        [ 0.2821,  0.8238, -1.6140,  ...,  0.5419,  0.0710, -0.8695],\n",
            "        [-0.7204,  0.1137, -0.6279,  ..., -0.3429,  0.2025,  0.9486],\n",
            "        [-0.3629, -0.3268, -1.8152,  ...,  1.6478,  2.7884, -0.4224]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9758,  0.8530, -0.1392,  ...,  0.8236, -0.1015,  7.5912],\n",
            "        [ 1.3301, -0.4872, -0.2965,  ...,  0.9315, -0.5994, -0.0628],\n",
            "        [-0.3326, -0.5006, -0.6578,  ...,  0.1053,  1.2302, -0.4011],\n",
            "        ...,\n",
            "        [-1.0051,  0.0666, -0.3880,  ...,  1.6028, -0.2633,  1.6493],\n",
            "        [ 1.1839, -0.6308,  0.9154,  ...,  0.1442, -0.5787, -0.7182],\n",
            "        [ 0.3950, -1.3873,  0.0869,  ..., -1.2535, -0.6736, -0.2508]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7842, -0.2501, -0.6083,  ..., -1.1463, -1.0464, -1.0892],\n",
            "        [ 0.2380, -0.1779, -0.9996,  ...,  1.1553,  0.8123, -0.5245],\n",
            "        [ 0.7167,  2.7842,  2.6956,  ..., -0.5936,  0.1295,  0.3566],\n",
            "        ...,\n",
            "        [ 0.4939, -0.8730, -0.6509,  ..., -0.6755, -1.2817, -0.6098],\n",
            "        [ 0.4633, -0.1908, -2.6320,  ...,  4.3685, -0.4747,  1.1307],\n",
            "        [-0.4314,  0.3667,  0.6071,  ..., -1.0372,  1.0068, -0.4424]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1029, -0.1657, -0.2179,  ...,  0.7839, -0.4096,  2.2187],\n",
            "        [-0.9656,  0.3016,  1.2241,  ..., -1.3161, -0.8974, -0.7544],\n",
            "        [-0.7123, -0.3868, -0.4873,  ..., -0.9274, -0.5514, -1.5517],\n",
            "        ...,\n",
            "        [ 0.6744,  2.2249,  1.0730,  ..., -0.3491, -0.4996, -0.5153],\n",
            "        [-0.2383, -1.0796,  0.1775,  ..., -0.3145, -1.3981,  0.3342],\n",
            "        [ 0.0811, -1.1843,  2.8331,  ..., -1.2685, -1.4277,  0.0538]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5851,  0.3202, -0.3926,  ...,  0.6824, -1.0638,  0.3982],\n",
            "        [-0.7455, -0.4503,  0.8557,  ..., -2.5947, -0.6848,  0.3552],\n",
            "        [-1.2912, -1.1318, -1.5905,  ..., -0.3687, -0.7592, -0.8494],\n",
            "        ...,\n",
            "        [ 0.7073,  1.1518,  0.7265,  ...,  0.2389, -0.9702, -0.2255],\n",
            "        [-0.3297, -0.8153, -0.2553,  ..., -1.4663, -1.1509, -1.1689],\n",
            "        [-1.1114, -0.6904,  0.0722,  ..., -0.7539,  0.4792, -0.7896]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.6375, -0.5512,  1.4486,  ..., -0.2971, -0.8289, -0.5650],\n",
            "        [-0.4193, -0.7096,  0.0912,  ..., -0.6838,  0.1756, -0.6909],\n",
            "        [-0.1500,  0.8715,  7.2669,  ..., -2.5331, -0.2874, -0.5784],\n",
            "        ...,\n",
            "        [ 0.1460, -0.9992, -1.2206,  ..., -0.7003, -1.3330, -0.7780],\n",
            "        [ 0.8737,  0.2926, -1.3053,  ..., -0.4580, -0.1315, -1.3121],\n",
            "        [-1.1734, -0.8433, -1.4821,  ..., -0.5826, -0.9989, -1.6048]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1934,  1.1033, -0.3437,  ..., -0.5111, -0.2758, -1.4121],\n",
            "        [-1.1736,  0.5260,  0.1525,  ..., -0.3881,  0.5854,  0.9443],\n",
            "        [-0.7712, -0.5256,  0.7731,  ..., -0.3620, -0.1221,  0.2801],\n",
            "        ...,\n",
            "        [-0.9689,  0.9586,  1.4879,  ..., -0.0135,  0.6859,  1.0429],\n",
            "        [ 1.4028, -0.3204,  1.9261,  ..., -0.6434, -0.5006, -1.0732],\n",
            "        [ 0.8838,  1.1193,  0.8458,  ...,  0.8338, -0.6907, -0.0991]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1984, -0.2223, -1.0633,  ...,  1.1013,  0.1138,  0.2016],\n",
            "        [ 0.9150,  1.3651,  5.7044,  ..., -2.3446, -1.0441,  0.1302],\n",
            "        [-0.1555,  7.1571,  1.1333,  ...,  0.3885,  0.5924,  0.3591],\n",
            "        ...,\n",
            "        [-0.6658, -0.4113,  1.2980,  ..., -0.2837, -0.2599,  0.1163],\n",
            "        [-1.0560,  0.4150,  0.3463,  ...,  1.2482,  1.8057,  0.8667],\n",
            "        [-0.9602,  0.5019,  0.9195,  ..., -1.0385,  0.7953, -0.2771]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-4.1292e-01, -4.4534e-01, -8.3844e-01,  ..., -3.1841e-01,\n",
            "          1.4532e-01,  9.2832e-01],\n",
            "        [ 1.8874e-02, -1.0197e+00,  8.9228e-01,  ..., -9.1676e-01,\n",
            "         -8.9100e-01,  8.1088e-02],\n",
            "        [-2.4398e-01, -7.0717e-01, -1.2289e+00,  ...,  4.4990e-01,\n",
            "         -7.0571e-01, -2.4444e-02],\n",
            "        ...,\n",
            "        [ 2.4847e-02, -8.8145e-01,  3.3198e+00,  ..., -1.4236e+00,\n",
            "         -1.4348e+00, -1.8870e-03],\n",
            "        [-4.2707e-01, -7.5224e-01, -3.0335e-01,  ..., -1.3026e+00,\n",
            "         -1.5704e+00, -9.4363e-01],\n",
            "        [-1.5975e+00, -1.5165e-01, -2.1315e-01,  ..., -1.5974e+00,\n",
            "         -9.5146e-01, -1.3158e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.0486e+00,  2.7038e+00,  2.5978e+00,  ..., -6.8313e-01,\n",
            "         -7.1044e-01, -1.2608e-01],\n",
            "        [ 9.8915e-01,  3.0940e-01,  1.7779e+00,  ...,  5.7518e-03,\n",
            "         -1.2813e+00,  9.8965e-01],\n",
            "        [ 1.0341e+00,  6.9428e-01, -1.1779e+00,  ..., -4.0538e-01,\n",
            "          1.8466e-01, -5.3347e-01],\n",
            "        ...,\n",
            "        [-1.2184e+00,  2.5891e-01, -6.7744e-02,  ...,  1.2297e+00,\n",
            "          4.6027e-01,  7.5222e+00],\n",
            "        [ 2.1656e+00, -4.5443e-01,  3.7794e-01,  ...,  5.2874e-01,\n",
            "         -1.2036e+00, -2.5952e-01],\n",
            "        [ 1.6445e+00, -2.1154e-01, -1.4242e+00,  ...,  1.3126e+00,\n",
            "         -4.6918e-01, -8.5895e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5931,  0.0279,  0.7036,  ..., -0.4717, -0.5731, -1.3270],\n",
            "        [-0.7296, -0.5720, -0.3663,  ...,  0.1888,  1.7196, -1.0674],\n",
            "        [-0.3440, -0.8561, -0.5143,  ..., -0.1662,  0.4242, -1.3544],\n",
            "        ...,\n",
            "        [ 0.6360,  0.0565, -0.2906,  ...,  0.1313,  0.3702, -0.0586],\n",
            "        [-0.2355, -0.7337, -1.1924,  ...,  0.5901,  2.0899, -0.9698],\n",
            "        [-0.2959, -1.2617, -0.7369,  ..., -0.8482, -1.4766, -1.2025]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8796,  1.8488,  2.6053,  ..., -0.4024, -0.8018,  0.5361],\n",
            "        [-0.5998, -0.7368,  0.4101,  ..., -0.6939,  0.7132, -0.8070],\n",
            "        [ 0.4875,  1.7111,  0.5736,  ...,  0.3242,  1.0472,  0.5678],\n",
            "        ...,\n",
            "        [ 4.2500,  1.0907, -0.1804,  ...,  0.3117, -1.5712, -1.4889],\n",
            "        [-0.5446, -0.9003,  0.3935,  ..., -0.2658,  0.0783, -0.2203],\n",
            "        [-0.4917, -0.6316,  0.1124,  ..., -0.2789, -0.5369, -0.3232]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7820, -0.1625,  0.9052,  ..., -0.8133, -0.4855, -1.3804],\n",
            "        [ 1.9049, -1.0052, -1.4057,  ...,  0.7438, -1.0741, -0.3052],\n",
            "        [ 0.7102,  1.1805,  1.1024,  ...,  0.7398, -0.8575, -0.0776],\n",
            "        ...,\n",
            "        [ 0.1937,  0.7489, -0.0106,  ..., -0.8513,  0.2549, -0.2353],\n",
            "        [-0.6547, -0.1271, -0.0974,  ..., -0.4074, -0.3834, -0.5594],\n",
            "        [-0.6753,  0.1425, -0.1538,  ..., -0.8519, -0.7260, -1.3092]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4274,  1.2103,  0.0829,  ...,  0.3100,  0.2172,  0.6480],\n",
            "        [ 0.2500,  0.2123,  0.8275,  ..., -1.0350, -0.1314, -0.4892],\n",
            "        [-0.7089, -1.9785,  1.1685,  ..., -1.1616, -1.1592,  0.2164],\n",
            "        ...,\n",
            "        [-0.9309,  0.0665, -0.0888,  ..., -0.2279, -0.5147, -0.3273],\n",
            "        [ 0.9786, -0.2838, -0.9686,  ..., -0.8664, -1.1704, -0.2912],\n",
            "        [-0.8639, -0.4637, -0.5161,  ..., -0.1627, -0.0584,  2.1962]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,600  of  2,811.    Elapsed: 1:08:23.\n",
            "logits :  tensor([[ 3.7040,  0.5908, -0.0542,  ...,  1.5411, -0.7742, -1.6069],\n",
            "        [ 2.4038,  0.3513,  1.5868,  ...,  0.1500, -1.5551,  0.1505],\n",
            "        [-0.0134,  1.2154, -0.5015,  ...,  0.5161,  1.1207,  1.1352],\n",
            "        ...,\n",
            "        [ 0.3146,  6.2333,  1.7178,  ..., -0.1604,  0.3786, -0.2857],\n",
            "        [-0.1496,  0.3715,  0.4167,  ..., -1.2796, -0.6367, -0.2985],\n",
            "        [-1.1014, -0.2803,  0.5072,  ..., -0.0957, -0.4229,  0.1972]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-7.5110e-01, -5.6927e-01, -2.7837e-01,  ..., -3.8423e-01,\n",
            "         -1.7302e+00, -1.1410e+00],\n",
            "        [ 2.0417e-01, -1.0327e+00,  9.9907e-01,  ..., -1.4754e+00,\n",
            "         -2.5646e-01,  4.5657e-01],\n",
            "        [ 9.5223e-02,  1.4295e-01, -9.3702e-01,  ..., -1.0908e+00,\n",
            "          4.3279e-01,  3.5747e-01],\n",
            "        ...,\n",
            "        [ 3.2197e-01,  1.0346e-03,  9.2244e-01,  ..., -5.9687e-01,\n",
            "         -1.3532e+00,  4.2860e-01],\n",
            "        [-9.7758e-01, -4.2580e-01, -5.2885e-01,  ..., -1.3645e+00,\n",
            "         -9.4454e-01, -1.4609e+00],\n",
            "        [ 1.0403e-02,  8.2049e-01,  4.6147e-01,  ..., -2.6069e-01,\n",
            "          4.7033e-01,  5.8549e-03]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5720,  1.2474,  0.3825,  ...,  1.1535, -0.5278,  1.8802],\n",
            "        [ 0.1326,  2.2924,  0.7075,  ..., -0.1024,  0.0211,  0.2757],\n",
            "        [-0.4808,  0.6649, -0.2219,  ...,  1.0343,  0.9274,  0.6841],\n",
            "        ...,\n",
            "        [ 2.4707,  1.0707, -1.1262,  ...,  1.0745, -0.9088, -0.9401],\n",
            "        [-0.1415,  0.1627,  0.4594,  ..., -1.6225, -0.2304, -0.9529],\n",
            "        [-0.0748, -0.0891,  1.3317,  ..., -1.0016, -1.2226,  0.8809]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0504, -0.5139, -0.1320,  ...,  0.7718, -0.0352,  0.2698],\n",
            "        [-1.0698,  0.4349,  0.5913,  ..., -1.0787, -0.6423, -0.5618],\n",
            "        [-0.4226, -1.1560, -1.2092,  ..., -0.1517,  0.2029, -0.2260],\n",
            "        ...,\n",
            "        [ 0.3120,  0.3136, -0.3751,  ...,  1.9017, -0.7210,  0.8287],\n",
            "        [-0.3022, -1.1951,  0.3694,  ..., -0.2916,  1.5021, -1.2903],\n",
            "        [-0.6929, -0.4594, -0.6876,  ...,  0.6135, -0.5985,  0.3129]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0283, -0.5031,  0.9592,  ..., -0.6351, -0.4772, -1.8020],\n",
            "        [ 1.3963, -0.5837, -1.5195,  ..., -0.2911, -1.7084, -1.2916],\n",
            "        [ 0.5600,  0.5333, -0.6539,  ...,  0.8898,  0.3457,  0.0362],\n",
            "        ...,\n",
            "        [-0.8692, -0.4011, -0.3576,  ..., -1.1292, -0.7957, -0.7229],\n",
            "        [ 1.1414, -0.0462, -1.8717,  ...,  0.3099,  0.0680, -1.0394],\n",
            "        [ 2.3609,  0.0491,  0.3945,  ..., -0.4226, -1.5012, -0.8113]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 6.5804e-01, -2.5942e-01,  2.1300e-01,  ..., -8.9103e-01,\n",
            "         -1.5394e+00, -1.6957e-03],\n",
            "        [-2.8210e-01, -1.4750e+00,  2.7220e+00,  ..., -1.2098e+00,\n",
            "         -1.4528e+00, -4.9949e-02],\n",
            "        [ 8.5451e-01,  3.1040e-01, -3.0168e-01,  ...,  7.4081e-02,\n",
            "          4.7443e-01, -1.1451e-01],\n",
            "        ...,\n",
            "        [-1.2288e+00, -1.4131e+00, -8.2881e-01,  ..., -6.3652e-01,\n",
            "         -1.0601e+00, -4.8168e-01],\n",
            "        [-4.6858e-01, -4.8002e-01,  9.9829e-01,  ...,  1.7586e-01,\n",
            "         -2.5503e-01, -3.4653e-01],\n",
            "        [-6.7946e-01, -1.4448e-01,  5.6357e+00,  ..., -1.8221e+00,\n",
            "         -9.7571e-01, -6.4689e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0794,  7.3435,  1.3545,  ..., -0.1126,  0.4250,  0.1437],\n",
            "        [-1.0863, -2.1055, -1.4964,  ..., -0.3334,  0.1385, -0.5175],\n",
            "        [ 0.0958, -0.5565, -0.1709,  ..., -0.7050, -0.3134, -0.9523],\n",
            "        ...,\n",
            "        [ 2.8660,  0.8471,  0.9051,  ...,  0.9900, -2.0127, -0.3756],\n",
            "        [ 4.9400,  0.6125,  0.5651,  ...,  0.9607, -0.3105, -1.5391],\n",
            "        [ 0.0171,  2.0465,  0.5917,  ..., -0.1941, -0.4108, -0.0821]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0488, -0.2610, -0.5434,  ..., -0.0801,  0.6348, -0.0838],\n",
            "        [-0.5545, -1.2488,  0.4630,  ..., -1.0356, -1.4096, -0.6223],\n",
            "        [-1.1476, -0.0109,  1.6940,  ..., -0.0167, -0.3015,  0.0842],\n",
            "        ...,\n",
            "        [ 1.4138,  2.3593,  0.9900,  ...,  0.9914, -1.3867,  1.6594],\n",
            "        [-0.2810, -0.2524, -0.0461,  ...,  0.7639,  0.2465, -0.0734],\n",
            "        [ 0.1837, -0.6054, -0.4198,  ..., -0.3287, -1.0271, -0.6716]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.6972,  0.0145, -0.8563,  ..., -0.3007, -0.8953, -0.3306],\n",
            "        [-0.7718,  0.8252,  6.9360,  ..., -2.8221, -0.3945, -0.3350],\n",
            "        [-0.0477, -0.7677, -0.4966,  ...,  0.8516,  0.2900, -0.1033],\n",
            "        ...,\n",
            "        [-0.7725,  0.7323,  0.7520,  ..., -1.0232,  1.1070, -0.2683],\n",
            "        [ 0.1301, -0.1208, -0.9038,  ...,  1.2960, -0.8369,  0.0950],\n",
            "        [-0.8775, -0.8194, -0.0985,  ..., -1.4988, -1.4550, -0.9047]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6672,  0.4556,  0.7247,  ..., -1.1766,  1.1201, -0.2198],\n",
            "        [-0.7917, -2.0297, -1.7559,  ..., -0.6491, -0.5343, -0.3376],\n",
            "        [-1.0410, -0.9630, -0.7452,  ..., -0.2735,  0.8413,  0.4137],\n",
            "        ...,\n",
            "        [-0.0876, -0.2712, -0.7499,  ...,  0.9660, -0.6446,  0.0025],\n",
            "        [ 0.8208,  0.4730, -1.4260,  ...,  1.3044,  0.4416, -0.3495],\n",
            "        [-0.4399, -0.7659, -1.0173,  ..., -0.5351,  0.2601, -0.2984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4727, -0.3758, -0.9935,  ...,  0.9229,  1.7720, -0.2757],\n",
            "        [ 1.5234, -0.8176, -1.6929,  ...,  1.8649, -0.7753, -0.5984],\n",
            "        [-0.7112, -0.3966, -1.2514,  ...,  1.8986, -0.0072,  1.0348],\n",
            "        ...,\n",
            "        [ 0.0071,  0.5823, -1.2228,  ..., -0.5265, -0.9009, -0.4292],\n",
            "        [ 1.6557,  1.5047,  1.5052,  ...,  0.2880, -1.2380,  0.0653],\n",
            "        [-0.6009,  0.1862,  0.4107,  ..., -0.1791, -0.0401, -0.2041]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.6948,  0.9005, -0.1860,  ..., -0.3674, -0.4489, -0.0231],\n",
            "        [ 0.0481, -1.2199,  0.3499,  ...,  0.0543, -0.8929,  1.0407],\n",
            "        [-1.1470, -0.4805, -0.0537,  ..., -1.0092,  0.4802, -1.0503],\n",
            "        ...,\n",
            "        [ 4.1823,  0.1117,  0.3699,  ...,  0.8312, -1.0855, -1.8226],\n",
            "        [-0.1657, -0.9483, -0.0527,  ..., -0.6550, -1.5957, -1.1238],\n",
            "        [-0.4725,  0.9949, -0.1295,  ..., -0.4099,  0.4027, -0.4985]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1111,  1.8287, -0.8056,  ...,  2.5394, -0.7568,  0.9270],\n",
            "        [-0.6702,  0.2134, -0.0122,  ...,  0.5345,  6.6061,  0.4826],\n",
            "        [-0.5253, -1.4487, -1.1427,  ..., -1.5248, -1.2379, -0.2373],\n",
            "        ...,\n",
            "        [ 3.2458,  1.6057, -0.8012,  ...,  0.1439, -1.7293, -0.5843],\n",
            "        [-0.2478, -0.3469,  0.2593,  ..., -0.3709, -0.1451, -0.0470],\n",
            "        [ 1.0642,  0.6360, -1.4376,  ..., -0.1322,  0.1201, -0.4998]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3646, -0.8362, -0.3019,  ..., -0.4438, -0.7684,  0.0853],\n",
            "        [-0.7212,  0.5417,  1.3655,  ..., -0.6570, -1.0461,  0.8563],\n",
            "        [ 0.3021,  1.1943, -0.9466,  ...,  2.1462, -0.6939,  1.3569],\n",
            "        ...,\n",
            "        [ 0.0715, -1.1471,  1.4231,  ..., -0.9041,  0.0329, -0.5989],\n",
            "        [-0.5013, -0.2465, -0.6496,  ..., -0.6801, -0.0930,  0.4187],\n",
            "        [ 0.7774, -0.7829,  1.1281,  ..., -1.3140, -0.5128, -0.1451]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3807, -0.4575, -0.7514,  ...,  0.2289, -0.7087,  1.4387],\n",
            "        [ 0.0772,  7.1160,  1.4248,  ...,  0.0860,  0.1943,  0.6746],\n",
            "        [-0.1571,  0.9225, -1.4984,  ..., -0.2527, -0.2550, -0.0938],\n",
            "        ...,\n",
            "        [ 2.3234,  0.7200, -0.2422,  ..., -0.2364, -1.6241, -2.1894],\n",
            "        [-0.1725,  0.4053,  3.9949,  ..., -1.7065, -1.2131,  0.1682],\n",
            "        [ 0.6720,  1.2858,  1.0751,  ...,  0.4589, -0.3914, -0.4673]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9384,  0.7016, -0.6146,  ...,  0.2847, -0.3346, -1.1808],\n",
            "        [ 1.2528,  2.4180,  0.9039,  ..., -0.1122, -1.3454, -0.0722],\n",
            "        [-0.4400,  0.4877,  0.1881,  ..., -0.1860,  1.2080,  0.9009],\n",
            "        ...,\n",
            "        [-0.7560,  0.4200,  0.9175,  ..., -0.5761, -0.8665,  0.4576],\n",
            "        [ 0.2918,  0.2692, -1.0853,  ...,  0.1355,  0.5446, -1.0016],\n",
            "        [-1.3584, -1.7402, -1.6218,  ..., -0.0707, -0.0508,  0.1216]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6765,  0.9600,  0.7237,  ..., -1.1359,  0.7641, -0.0737],\n",
            "        [-0.1059, -1.0184,  0.3559,  ..., -1.5242, -0.9157, -0.7032],\n",
            "        [-1.6458, -0.3372,  0.1092,  ...,  0.3298,  2.5591,  4.0640],\n",
            "        ...,\n",
            "        [ 1.5709,  6.2170,  0.5798,  ...,  0.0108,  0.4149, -0.3921],\n",
            "        [-1.5515, -0.1194, -0.0316,  ..., -0.0140,  1.4923,  5.6440],\n",
            "        [ 0.5253, -0.9219,  0.8745,  ..., -1.2413, -0.1066, -0.1351]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1542, -0.3560, -0.5374,  ..., -0.6617, -0.2523,  0.0712],\n",
            "        [-1.5217, -1.1298,  1.4480,  ..., -1.3700, -0.6884,  0.7714],\n",
            "        [-0.3253, -0.3625, -0.4254,  ...,  0.1972,  0.4159,  0.3768],\n",
            "        ...,\n",
            "        [ 0.9538, -0.3927, -0.5967,  ...,  0.6429, -0.0524,  0.2176],\n",
            "        [-0.6205, -0.3269, -0.3580,  ...,  0.5370,  6.7568,  0.3811],\n",
            "        [ 0.1365, -0.6850, -0.4139,  ...,  0.8726,  0.2178, -0.5582]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3070, -1.3235,  2.8726,  ..., -1.2571, -0.9573,  0.1336],\n",
            "        [-1.0255, -0.4581, -0.5749,  ..., -0.6635, -0.2843, -0.6563],\n",
            "        [-0.6450, -1.2893,  0.1328,  ...,  0.2569,  0.9590,  0.0172],\n",
            "        ...,\n",
            "        [-0.5112, -0.7734, -1.4190,  ...,  2.5012,  0.3162,  1.1696],\n",
            "        [-0.6491, -1.0807, -1.8252,  ..., -0.4533, -1.3168, -0.8335],\n",
            "        [-0.1736, -0.6827, -1.3541,  ..., -0.7797, -0.9491, -0.7754]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.0055,  0.1826, -0.2184,  ..., -0.0645, -0.5148, -1.3720],\n",
            "        [ 0.8282, -0.6286, -0.7627,  ..., -0.5845, -1.2732, -1.1756],\n",
            "        [-0.4333, -0.7854,  1.4270,  ..., -1.4955, -0.0169, -1.1461],\n",
            "        ...,\n",
            "        [ 0.7911,  0.9852,  0.7387,  ...,  0.8915, -1.0852, -0.2126],\n",
            "        [ 0.0040,  0.6263,  0.2987,  ..., -0.8991,  0.4063, -0.4686],\n",
            "        [-1.0814, -0.8296, -0.2400,  ..., -0.8198, -1.5663, -1.0516]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5523,  0.0258, -2.3266,  ...,  1.6851,  0.4832, -0.4692],\n",
            "        [ 0.0714,  0.3041,  0.0137,  ...,  0.0507,  0.6762,  0.3539],\n",
            "        [-0.6242, -0.0174,  0.1956,  ...,  0.1746, -0.6562, -1.3088],\n",
            "        ...,\n",
            "        [ 0.8090,  1.0291,  0.8529,  ...,  0.6363, -0.7512, -0.6086],\n",
            "        [ 0.1663,  0.7494,  1.8001,  ..., -0.5171, -0.7870, -0.0763],\n",
            "        [-0.5451, -1.5218,  0.1400,  ...,  0.1951,  0.3011, -0.5806]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.6661, -0.9989, -0.2410,  ...,  0.2296,  0.1447, -0.0341],\n",
            "        [-0.7960,  0.1983, -0.1187,  ...,  0.5300,  3.2902,  1.4377],\n",
            "        [-0.3475,  0.5754,  0.4111,  ..., -0.0763, -0.6094,  1.2931],\n",
            "        ...,\n",
            "        [ 0.8760, -1.3398,  0.1301,  ..., -0.2914,  0.5739, -0.8857],\n",
            "        [-1.3631,  0.2823,  1.3315,  ..., -1.4145,  0.6849, -0.4682],\n",
            "        [-0.4530,  0.6932, -0.0963,  ...,  0.4426,  0.6191,  0.7079]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2252,  1.3373,  0.7207,  ..., -0.3817,  0.8007,  0.3127],\n",
            "        [ 3.6267, -0.6543,  0.1515,  ..., -0.2906, -0.5492, -1.4435],\n",
            "        [-1.0442, -0.5425,  0.0792,  ..., -1.0987, -1.4466, -1.0749],\n",
            "        ...,\n",
            "        [-1.3721,  0.1951,  0.2021,  ..., -0.2551,  0.6816,  0.7300],\n",
            "        [-0.2999, -0.4176,  1.9127,  ..., -1.2136, -0.9342,  0.3048],\n",
            "        [-0.3570,  1.2936,  0.4785,  ...,  0.4035,  1.3018,  0.9257]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.6714, -0.6195, -0.2032,  ..., -1.1686, -0.8059, -1.2927],\n",
            "        [ 0.8885,  0.7573, -1.0277,  ...,  1.5819, -1.0937, -0.3001],\n",
            "        [ 0.0843, -0.3608, -0.3550,  ..., -1.6679, -0.9088,  0.0813],\n",
            "        ...,\n",
            "        [-0.6439, -0.3594,  0.3717,  ...,  0.0526, -0.6735,  1.2446],\n",
            "        [-0.4357, -1.0972,  0.5464,  ..., -0.8243,  0.2234, -1.1629],\n",
            "        [-0.4233, -0.5754, -1.4037,  ...,  0.3239,  0.3138, -0.1663]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4789, -1.1420, -1.1880,  ...,  1.0400,  0.1463,  0.3332],\n",
            "        [ 0.4657, -0.0180,  2.2313,  ..., -1.5370, -0.3515,  0.2356],\n",
            "        [-0.5514, -0.4802, -0.8777,  ..., -0.8035,  0.2938,  0.8632],\n",
            "        ...,\n",
            "        [-0.0156, -0.8714,  2.7099,  ..., -1.0666, -0.7662,  0.0689],\n",
            "        [-0.3366, -0.6283, -0.8092,  ..., -0.6081,  3.7736,  0.3595],\n",
            "        [ 0.2578, -1.4875,  0.3737,  ..., -1.4051, -0.9665, -0.8490]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6571, -1.6160,  1.6912,  ..., -0.8904, -1.0579,  0.0989],\n",
            "        [ 1.9018, -0.0866, -2.3438,  ...,  1.6307, -1.0680, -0.5730],\n",
            "        [ 1.0422,  1.0078, -1.4650,  ...,  1.0034,  0.5974, -0.8513],\n",
            "        ...,\n",
            "        [-0.5364, -1.3106, -0.2021,  ...,  0.4627,  1.8919,  1.2857],\n",
            "        [-0.9835, -0.9137,  0.7294,  ..., -1.5817, -0.4904, -1.6169],\n",
            "        [ 1.2529,  1.2363,  4.4289,  ..., -1.3591, -1.3579,  0.0378]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5772, -0.0551, -0.2276,  ...,  0.0255, -0.1002, -0.1829],\n",
            "        [ 0.8303,  0.0185, -0.6719,  ..., -0.1499, -0.7690, -1.0165],\n",
            "        [ 1.5597, -0.7398, -0.8759,  ..., -0.2555, -1.6413, -0.4762],\n",
            "        ...,\n",
            "        [-0.4094, -0.5537, -1.1539,  ...,  0.7446,  4.8886, -0.4019],\n",
            "        [-0.6317, -0.0154,  0.9448,  ..., -0.9752,  0.7199, -0.1996],\n",
            "        [-0.9841, -0.5287, -0.1539,  ..., -0.5351,  0.6718, -0.7100]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.4052e-02, -3.9107e-01, -5.1088e-01,  ..., -3.9101e-01,\n",
            "         -1.4641e+00, -1.2099e+00],\n",
            "        [ 9.6606e-01,  3.9910e-01, -1.2582e+00,  ..., -4.5735e-01,\n",
            "          6.1735e-02, -6.9026e-01],\n",
            "        [-1.1981e+00, -1.0662e+00,  8.1000e-02,  ..., -5.8197e-01,\n",
            "          3.5596e-02,  6.6963e-02],\n",
            "        ...,\n",
            "        [ 3.4924e-01,  6.8862e+00,  1.6299e+00,  ..., -9.5986e-02,\n",
            "          1.6020e-03,  4.3054e-01],\n",
            "        [-6.7879e-01,  3.1131e-02,  3.2415e-01,  ..., -3.2859e-01,\n",
            "         -2.5328e-01, -3.9879e-02],\n",
            "        [-6.2944e-01,  7.0476e-01,  3.6274e-02,  ..., -6.8778e-01,\n",
            "          2.1115e+00,  1.7317e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1194,  0.7666,  0.4657,  ..., -1.5278, -0.6579, -0.1758],\n",
            "        [-0.4463, -0.9851,  2.8166,  ..., -1.2068, -1.3281,  0.1459],\n",
            "        [ 0.6587,  0.1612, -2.5330,  ...,  7.0840,  0.2306,  1.7694],\n",
            "        ...,\n",
            "        [-0.1560,  1.2302, -0.5259,  ..., -0.8636,  0.7943, -0.7414],\n",
            "        [-0.5745,  0.0713, -0.5118,  ...,  0.2930, -1.0463, -1.3293],\n",
            "        [ 4.3978,  0.6333, -0.0980,  ...,  0.5558, -1.9113, -1.5257]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4383, -0.6900,  0.0127,  ..., -0.2764, -0.7983,  0.8840],\n",
            "        [-0.8912, -0.4690, -0.6898,  ..., -0.0884,  1.4079,  0.8646],\n",
            "        [-0.7107,  0.2834,  0.1388,  ..., -0.3356, -0.6000, -1.7194],\n",
            "        ...,\n",
            "        [ 1.4129,  0.2960, -1.2684,  ...,  1.2190,  0.4291, -0.3707],\n",
            "        [ 1.3206,  2.8027,  1.0150,  ..., -0.5740, -0.6166, -1.1884],\n",
            "        [-0.3821,  1.3976,  0.0847,  ..., -0.6242, -0.1152, -0.4538]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8772,  0.9069, -1.9885,  ...,  0.6445, -0.8846, -0.6261],\n",
            "        [ 0.8347, -0.8495,  2.3419,  ..., -1.2777, -1.4919,  0.1664],\n",
            "        [-0.9017, -1.1538, -1.6653,  ...,  0.8723,  1.1523,  1.7727],\n",
            "        ...,\n",
            "        [-0.5401, -0.6486, -1.1521,  ...,  1.7820,  0.1659,  1.0144],\n",
            "        [-0.9851, -1.5835,  1.6077,  ..., -1.2282, -0.7905,  0.8816],\n",
            "        [ 2.7959,  1.7859, -0.9184,  ...,  1.2975, -0.5727, -1.3017]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3037, -1.5583, -0.0044,  ..., -1.2501, -0.4116, -0.5832],\n",
            "        [-0.4529,  0.5462,  0.2087,  ..., -1.4245, -1.2526, -1.1824],\n",
            "        [-0.6098, -0.4075,  0.0539,  ..., -0.7603,  1.4155, -0.2666],\n",
            "        ...,\n",
            "        [-0.4704, -0.0349, -0.5193,  ...,  1.0557,  0.5237,  0.0919],\n",
            "        [-0.5583,  0.0164,  1.1084,  ..., -0.1316,  0.1861,  0.3024],\n",
            "        [ 0.8966,  1.5950,  1.2275,  ...,  0.1448, -0.6620,  0.2857]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.2288,  0.3875,  0.2431,  ...,  0.0160, -0.4772, -0.6858],\n",
            "        [-0.4356,  0.1471, -0.4674,  ..., -0.6494, -0.6141, -0.4654],\n",
            "        [-1.0178, -0.7967, -0.7121,  ...,  0.6626,  1.6453, -0.5725],\n",
            "        ...,\n",
            "        [ 1.3518,  0.7032, -0.8155,  ...,  0.4964, -1.9535,  0.6493],\n",
            "        [ 0.3585,  7.8079,  2.0596,  ..., -0.2050,  0.3239,  0.8227],\n",
            "        [-0.4279, -0.7912, -1.4378,  ...,  1.6171,  2.2015, -0.3140]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0798,  0.1052, -0.8146,  ...,  1.2331, -0.2864,  0.5730],\n",
            "        [ 0.3972,  1.1569,  2.9292,  ..., -1.2090,  0.4038, -0.0486],\n",
            "        [ 0.1679, -0.3443, -0.2596,  ...,  0.0059, -1.1419,  0.7086],\n",
            "        ...,\n",
            "        [ 0.6877,  0.1053, -1.6271,  ..., -0.5811, -1.0783, -0.5546],\n",
            "        [ 0.4643, -0.6094, -0.1832,  ..., -0.7900, -1.4503, -0.9151],\n",
            "        [-0.7832, -1.2359, -1.8100,  ..., -0.2140,  0.2121, -1.2932]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.5730, -0.6541,  1.3749,  ..., -1.3104, -0.9185, -0.4023],\n",
            "        [-0.6589, -0.3159, -0.4690,  ...,  0.1108, -0.2452, -0.3403],\n",
            "        [ 3.5160,  1.0717,  1.6332,  ...,  0.1898, -1.7003, -0.3256],\n",
            "        ...,\n",
            "        [ 0.1391,  0.8753,  0.2562,  ...,  0.0931,  1.2688,  0.7678],\n",
            "        [ 3.4766,  0.8435, -0.5390,  ...,  0.7503, -0.9170, -0.6738],\n",
            "        [ 2.6459,  0.0954,  1.0914,  ..., -0.5958, -1.6215, -0.8400]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5576, -1.0622, -1.2728,  ...,  0.2168,  0.1782, -0.2183],\n",
            "        [-0.7680, -0.0745,  0.4689,  ..., -0.4646, -0.4400,  0.4354],\n",
            "        [-0.8583, -0.0131, -1.5097,  ...,  1.8221,  0.1567,  1.1205],\n",
            "        ...,\n",
            "        [-1.1585,  0.7122,  1.5575,  ...,  0.4441, -0.2169,  6.9014],\n",
            "        [ 0.4546, -0.2393,  0.0683,  ..., -1.0872, -1.1426, -0.7578],\n",
            "        [-0.7331, -0.0515,  1.8263,  ..., -0.9152, -0.8962,  0.1594]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.7407,  0.8821,  1.0664,  ...,  0.2526, -1.5074, -0.4392],\n",
            "        [ 2.0248,  0.3180,  0.7393,  ..., -0.1868, -1.3390,  0.2456],\n",
            "        [ 0.1601,  0.7400,  0.5010,  ..., -0.8676, -0.3186,  0.3820],\n",
            "        ...,\n",
            "        [-0.5604, -0.7747, -1.9823,  ..., -0.3870, -1.1127, -1.4518],\n",
            "        [ 0.3705,  1.6413,  1.7774,  ..., -0.4148,  0.1674, -0.4305],\n",
            "        [-0.6440, -1.0716, -1.4224,  ..., -0.4738, -0.8817, -0.5460]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1423, -0.3890,  0.3895,  ..., -0.3828, -0.7417, -0.1094],\n",
            "        [ 0.0393,  0.4621, -0.4221,  ...,  0.9927,  0.0849,  0.8081],\n",
            "        [-0.4762, -0.6717, -0.4303,  ..., -0.4489,  0.3682,  0.0038],\n",
            "        ...,\n",
            "        [-0.9474,  0.9533, -0.0913,  ..., -0.5383, -0.8988,  0.2843],\n",
            "        [-0.4532, -0.5934, -1.0772,  ..., -0.9579, -0.8860, -0.5296],\n",
            "        [ 0.9178,  0.4876,  1.1263,  ..., -0.4852,  0.0988, -0.7297]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8937, -1.2450, -0.5064,  ...,  0.3431,  0.5345, -0.4475],\n",
            "        [-0.4581,  0.7081, -0.3836,  ...,  2.5233,  3.1977,  0.9699],\n",
            "        [-1.2868,  0.5987,  0.4713,  ..., -1.4223, -0.4986, -0.1308],\n",
            "        ...,\n",
            "        [-0.4189, -0.3381, -1.0221,  ...,  1.5329, -0.5206,  0.6401],\n",
            "        [-1.3054,  1.6651,  0.2767,  ..., -0.6180, -0.1369, -0.0817],\n",
            "        [ 1.6594,  2.7058,  1.1263,  ..., -0.4072, -0.0828, -0.6467]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.9909,  0.0206,  4.2909,  ..., -1.4361, -0.8222, -1.1264],\n",
            "        [-0.3869,  0.1983, -0.2776,  ..., -0.1652,  0.5352, -1.1839],\n",
            "        [-0.3311,  0.4667,  0.6113,  ..., -0.7304,  1.6948,  0.3521],\n",
            "        ...,\n",
            "        [ 1.1714,  1.5308, -0.4710,  ...,  0.6518,  1.2552, -0.0464],\n",
            "        [-0.9030,  0.0236,  0.1346,  ..., -0.4926,  1.7237, -0.7622],\n",
            "        [-1.3077,  0.4116, -0.3757,  ..., -0.3186,  0.6800, -0.3388]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,640  of  2,811.    Elapsed: 1:09:26.\n",
            "logits :  tensor([[ 2.5716,  0.3557, -1.4554,  ...,  1.4308, -0.7424, -1.1601],\n",
            "        [-1.1927, -2.1002, -1.3098,  ..., -0.0795,  1.6360,  0.0867],\n",
            "        [-0.4346, -0.6329, -0.1746,  ...,  0.3686, -1.1289,  0.8809],\n",
            "        ...,\n",
            "        [ 2.4382, -0.1893, -1.3708,  ..., -0.0483, -1.1141, -0.3515],\n",
            "        [-1.2779, -0.0457,  0.3350,  ...,  0.4334,  0.3548,  7.2486],\n",
            "        [-0.8806,  0.2799, -1.1945,  ...,  2.4155, -0.5792,  1.3484]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1506, -0.7240, -0.2057,  ...,  0.8616,  0.4288, -0.4695],\n",
            "        [-0.7789, -0.7866, -0.6692,  ..., -1.2132, -0.9338, -0.9019],\n",
            "        [-0.4992, -0.0137, -0.4267,  ..., -0.7546, -0.2526,  0.8274],\n",
            "        ...,\n",
            "        [ 0.0666, -0.3885,  0.0299,  ..., -1.3515, -0.8007,  0.0542],\n",
            "        [-0.2745,  0.4205,  0.6772,  ..., -1.2800, -0.2411,  0.0232],\n",
            "        [ 4.4293,  1.1209,  0.7720,  ...,  0.9629, -1.7067, -0.7609]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8220, -1.1418, -1.4429,  ...,  0.4671,  0.3134,  0.0780],\n",
            "        [-0.4558, -0.8862, -1.1451,  ..., -0.2985, -0.6306, -0.7539],\n",
            "        [ 4.9070,  0.1575, -0.6974,  ...,  0.4720, -0.7466, -1.3659],\n",
            "        ...,\n",
            "        [ 0.9739, -0.2052, -1.1616,  ...,  0.8725, -1.2571,  0.0946],\n",
            "        [-0.4156, -0.6343,  0.3653,  ..., -0.7845,  0.6509, -0.3695],\n",
            "        [-0.4403, -0.0844, -1.2015,  ...,  0.8441,  2.6689, -0.8836]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.0648,  0.1160, -1.3200,  ...,  0.4907, -1.0932, -0.5094],\n",
            "        [-0.7708, -0.0919,  0.2886,  ..., -0.1981,  0.0116, -0.4878],\n",
            "        [-0.6377, -0.8775, -0.6986,  ..., -0.5800, -1.6265, -0.9506],\n",
            "        ...,\n",
            "        [-0.0875,  0.1425, -0.4144,  ...,  0.6704, -0.8579,  1.5734],\n",
            "        [-0.7714, -1.0070, -0.7782,  ..., -0.5136,  1.4816,  0.2999],\n",
            "        [ 0.0484, -0.0448, -0.7561,  ...,  0.4618,  0.1211, -0.1577]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 4.1843,  0.9363, -1.9664,  ...,  1.4201, -1.6434, -2.0592],\n",
            "        [-1.0041, -0.7267, -0.6190,  ..., -0.6068, -0.8726, -0.1412],\n",
            "        [ 0.5971,  0.9679,  1.1126,  ...,  0.5731, -0.6031, -0.5128],\n",
            "        ...,\n",
            "        [-0.4357, -0.6418,  0.2221,  ..., -0.2016, -0.8372,  0.5741],\n",
            "        [ 0.0922, -0.9144, -0.8424,  ..., -0.3321, -1.5505, -0.1287],\n",
            "        [ 1.3064, -0.3719, -2.3765,  ...,  1.5081, -0.7076, -0.8989]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2056, -0.2854, -1.0650,  ...,  1.0697,  3.4319, -0.5942],\n",
            "        [-0.3602,  1.1739,  0.1389,  ..., -0.8657,  0.1686, -0.4396],\n",
            "        [-0.7298, -1.2974,  0.2551,  ...,  0.2523,  0.5891, -0.1351],\n",
            "        ...,\n",
            "        [ 0.1278,  5.3610,  3.1053,  ..., -1.0225,  0.4325, -0.3760],\n",
            "        [-0.0660,  1.1691,  7.2777,  ..., -2.1495,  0.0264, -0.3404],\n",
            "        [ 0.6622, -1.2683,  0.9092,  ..., -0.7355, -0.5302, -0.4972]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2345,  0.0217, -0.1597,  ...,  0.5572,  1.5612, -0.7908],\n",
            "        [-1.3037, -1.4387,  0.5674,  ..., -0.5022,  0.1953, -0.2683],\n",
            "        [-0.3491,  0.2166, -1.1317,  ...,  1.7216,  3.6237,  0.9745],\n",
            "        ...,\n",
            "        [-1.2328,  0.1242, -0.1917,  ...,  0.4801,  3.0425, -0.0338],\n",
            "        [-0.1683, -0.8137, -1.4199,  ...,  0.1456,  1.1382, -0.9331],\n",
            "        [-0.4479,  0.8485, -0.0406,  ..., -0.2790,  0.6298, -0.2446]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6008, -0.3239, -1.2022,  ...,  1.5318,  0.2925,  0.6317],\n",
            "        [-0.7637, -0.4144,  0.0644,  ..., -0.8501,  0.4272, -0.9466],\n",
            "        [-0.7470, -0.7043, -0.5652,  ..., -0.0081, -0.0827,  0.3276],\n",
            "        ...,\n",
            "        [ 0.3594, -1.0050, -0.5037,  ...,  0.7883,  0.3229, -0.0529],\n",
            "        [-0.1047,  1.3731,  0.1630,  ...,  0.4538,  0.9184,  1.2495],\n",
            "        [-0.6565, -1.1484,  0.3636,  ...,  0.3593,  1.0523, -0.0241]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5102, -0.8366,  2.0992,  ..., -0.2401, -0.6937, -0.1070],\n",
            "        [ 1.5063,  1.0173, -0.1958,  ...,  0.0532, -0.4604, -1.6607],\n",
            "        [-0.7705, -0.0420,  1.6243,  ..., -0.0460, -0.1831,  0.6746],\n",
            "        ...,\n",
            "        [-0.7129,  0.5280,  0.6570,  ..., -1.0497,  1.4241, -0.1378],\n",
            "        [-0.7357, -0.6704, -0.3087,  ...,  0.6748,  4.0475,  1.4423],\n",
            "        [ 0.1376, -0.9606, -0.7860,  ...,  0.8166,  1.7135, -0.8011]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1328, -1.0374,  1.8567,  ..., -1.0833, -1.8665, -0.0683],\n",
            "        [ 0.3188,  0.5446, -0.0520,  ..., -1.0999,  0.0417, -0.1165],\n",
            "        [-0.8542, -0.2106,  0.4235,  ..., -1.3723, -0.2553, -0.6805],\n",
            "        ...,\n",
            "        [-0.5035, -0.5993,  2.1360,  ..., -1.3812, -0.6233, -0.9286],\n",
            "        [-0.2950, -0.0232, -0.6346,  ...,  0.6017, -0.2033,  2.2397],\n",
            "        [ 0.7964, -0.8125, -0.9017,  ...,  0.6596, -0.0287,  0.0604]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-8.4931e-01,  8.2410e-01, -9.9194e-02,  ...,  1.2623e+00,\n",
            "          1.2878e-01,  1.7734e+00],\n",
            "        [ 7.4951e-01,  1.1668e+00,  3.5612e-01,  ..., -7.5345e-01,\n",
            "         -1.1090e+00, -1.2148e-01],\n",
            "        [ 5.7313e-01,  1.6797e+00, -4.2512e-03,  ...,  1.0428e-01,\n",
            "         -8.4073e-01,  3.3616e-01],\n",
            "        ...,\n",
            "        [ 1.1469e+00,  6.5088e+00,  1.8276e+00,  ...,  2.1404e-01,\n",
            "          1.2055e-01, -4.1638e-03],\n",
            "        [-1.0996e+00, -1.3490e+00, -1.4347e+00,  ..., -8.5742e-01,\n",
            "         -1.5972e+00, -1.3724e+00],\n",
            "        [ 2.2975e-01, -6.1156e-01, -1.3350e-01,  ..., -1.1909e+00,\n",
            "         -3.2507e-01, -5.5016e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.8680,  0.2133, -0.5559,  ...,  0.5284, -1.8764, -1.1982],\n",
            "        [-0.3897,  1.3538, -0.3070,  ..., -0.5227,  0.3769, -0.2796],\n",
            "        [ 1.5454, -0.1503, -0.9404,  ...,  2.1725, -1.2747,  0.6194],\n",
            "        ...,\n",
            "        [-0.6885,  0.8386,  0.4807,  ..., -0.7149,  0.9778, -0.5625],\n",
            "        [-1.2344, -0.3634,  0.0124,  ..., -0.1268,  1.8977, -0.4534],\n",
            "        [-0.6367, -0.0210, -0.0750,  ..., -0.7560, -0.8909, -1.4474]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8773, -0.2996,  0.1438,  ..., -0.7595,  0.6187,  0.5822],\n",
            "        [-1.2002,  0.4214,  0.6625,  ..., -1.5880, -0.7971, -0.4156],\n",
            "        [-0.2813, -0.3157, -0.6766,  ..., -0.6911, -0.9672, -0.7997],\n",
            "        ...,\n",
            "        [-0.2003,  0.8277,  0.3121,  ..., -0.7102,  1.6136, -0.2823],\n",
            "        [ 4.5780,  0.6988, -0.0539,  ..., -0.0468, -1.4425, -1.6611],\n",
            "        [-1.1694, -0.1315,  0.1997,  ..., -0.7927,  1.1990, -0.3974]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7201,  0.6421, -0.0429,  ...,  0.6246,  6.9662,  0.2594],\n",
            "        [ 0.4147,  0.7929, -2.7973,  ...,  6.3182,  0.0221,  0.9477],\n",
            "        [ 0.6109,  0.8429, -0.8821,  ..., -0.3008,  0.2874, -0.5991],\n",
            "        ...,\n",
            "        [-1.1332,  0.2542,  0.8654,  ...,  0.5375,  0.2476,  6.6017],\n",
            "        [-0.5106, -0.1397, -0.7975,  ..., -0.2157,  0.5536, -0.4191],\n",
            "        [ 2.6330, -0.4010, -0.6237,  ...,  0.1659, -1.3973, -0.8925]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.3617,  0.7382, -0.6470,  ..., -0.6645, -0.0098, -0.4724],\n",
            "        [-1.3166, -0.7665, -0.4662,  ..., -1.0272, -1.3069, -0.8056],\n",
            "        [ 1.0212, -0.6379,  1.5735,  ..., -0.3463, -0.6737, -1.0692],\n",
            "        ...,\n",
            "        [-0.6073, -0.1489,  0.3035,  ..., -0.5748,  1.8275, -0.3494],\n",
            "        [ 1.3741, -0.0153, -2.5135,  ...,  7.3148,  0.2511,  1.3246],\n",
            "        [ 0.5409,  7.5958,  1.5208,  ..., -0.1657,  0.2461,  0.2658]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6525, -0.2299, -0.0654,  ..., -0.7174, -0.1763, -0.8892],\n",
            "        [-0.1607, -0.5304, -0.2582,  ..., -0.0084,  0.5193, -0.6012],\n",
            "        [-0.6056, -0.1218, -0.3985,  ..., -0.5728, -0.6753, -1.1865],\n",
            "        ...,\n",
            "        [ 0.2145,  0.6385,  0.0651,  ..., -0.7794, -0.0283, -0.6129],\n",
            "        [ 0.4949, -0.8373,  1.0986,  ..., -1.2646, -1.1686, -0.6193],\n",
            "        [ 0.2041,  3.0173,  3.3873,  ..., -0.5600, -0.1479,  0.7007]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 5.7309e-01,  2.2435e+00,  1.5966e+00,  ...,  2.7226e-01,\n",
            "         -8.2601e-01,  9.2250e-01],\n",
            "        [-6.0313e-01, -2.9834e-01, -1.4736e-02,  ..., -1.2621e-01,\n",
            "         -3.7905e-01,  2.6937e-01],\n",
            "        [ 1.2313e+00,  2.9081e+00,  2.9729e+00,  ..., -4.3020e-01,\n",
            "         -5.4372e-01,  1.0953e-02],\n",
            "        ...,\n",
            "        [-6.4317e-02,  3.0749e-01,  4.0129e+00,  ..., -1.9556e+00,\n",
            "         -8.4974e-01, -5.2108e-01],\n",
            "        [ 4.8048e+00,  1.0308e+00, -9.1283e-01,  ...,  7.0685e-01,\n",
            "         -1.0726e+00, -1.3883e+00],\n",
            "        [-9.7188e-01, -1.1594e+00,  4.4220e-03,  ...,  7.1334e-02,\n",
            "          2.1742e-01, -4.8845e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5545, -1.3831,  1.5068,  ..., -0.4483, -0.6933, -0.4567],\n",
            "        [ 3.1641,  0.8458,  1.1006,  ...,  0.2092, -2.2433, -0.7337],\n",
            "        [-0.9356, -1.1179,  2.0624,  ..., -1.2090, -0.7810,  0.6459],\n",
            "        ...,\n",
            "        [ 1.8009,  0.8402, -0.1761,  ...,  0.0821, -0.5566, -1.4369],\n",
            "        [-0.4696, -0.8578, -0.3824,  ..., -0.2202,  1.6210, -0.6594],\n",
            "        [ 0.2698, -0.9211,  2.1600,  ..., -1.4040, -1.4234,  0.1800]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0043, -0.8835, -0.5644,  ..., -0.8005,  1.2893,  0.1700],\n",
            "        [ 2.5330,  0.7133,  0.0763,  ...,  1.5203, -1.5353,  0.1556],\n",
            "        [ 0.5473,  7.3916,  1.6969,  ...,  0.2405,  0.3253,  0.0714],\n",
            "        ...,\n",
            "        [-0.4191, -0.8129,  0.3929,  ..., -0.6060, -0.7055,  0.3252],\n",
            "        [-0.8661, -0.9579, -2.0880,  ..., -0.2857, -0.0587, -1.0559],\n",
            "        [-0.2425, -0.5850, -0.2166,  ..., -0.0786, -0.6720,  0.3473]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0773, -1.4981, -1.2506,  ..., -0.1498,  1.2677, -0.0074],\n",
            "        [-0.7275, -0.4145,  0.2005,  ..., -0.5101,  1.5526, -0.2173],\n",
            "        [-1.0526, -1.3464, -2.2994,  ...,  0.3244, -0.2941, -0.9776],\n",
            "        ...,\n",
            "        [-0.9759, -0.3492,  0.2704,  ..., -1.3763, -0.0919, -1.1908],\n",
            "        [ 3.5782,  1.3663, -0.8520,  ...,  1.6301, -0.1336, -1.2193],\n",
            "        [-0.3015, -1.5217,  0.2810,  ..., -1.2065, -0.6429, -0.4030]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2187, -0.3976, -1.0104,  ..., -0.8710, -1.2652, -0.6236],\n",
            "        [-0.8002, -1.3021,  0.5679,  ...,  0.1595,  0.8435, -0.3012],\n",
            "        [-0.2627, -1.3554, -0.0646,  ..., -1.3711, -0.9164, -0.6745],\n",
            "        ...,\n",
            "        [ 3.6809,  1.2667, -0.1978,  ..., -0.4068, -1.1015, -1.8197],\n",
            "        [ 0.3206, -0.1773, -0.9287,  ...,  1.5634, -0.9817,  0.4289],\n",
            "        [ 0.0467,  0.8438,  0.5888,  ..., -0.1840,  1.4434, -0.2676]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.7867, -0.4511, -1.1966,  ...,  1.0767, -0.4394, -0.4821],\n",
            "        [-0.7229, -1.2349, -0.4100,  ..., -1.3252, -1.3481, -0.7057],\n",
            "        [-0.2354, -0.8211, -0.3164,  ...,  0.6923, -0.1686,  0.1161],\n",
            "        ...,\n",
            "        [-0.7685, -0.5433, -1.0233,  ...,  2.0263,  0.3477,  1.1505],\n",
            "        [-1.3332, -0.0196,  0.6820,  ..., -0.0607,  0.1888,  5.3552],\n",
            "        [-0.9669, -1.3547,  1.6310,  ..., -1.1902, -1.0414,  0.5991]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3396, -1.0982, -0.8810,  ..., -0.8097, -0.2894, -0.7440],\n",
            "        [ 0.0426,  0.2572, -1.7854,  ...,  5.2621, -0.6799,  2.2643],\n",
            "        [ 0.7185,  1.2274,  0.7058,  ...,  0.0248, -0.2880, -0.3941],\n",
            "        ...,\n",
            "        [ 0.2392, -0.9921, -1.1488,  ..., -0.4949, -1.0015, -0.6609],\n",
            "        [-1.1120, -0.4552, -1.0912,  ..., -0.4504, -0.1362, -0.6758],\n",
            "        [-0.6676, -0.7255, -0.6986,  ..., -0.5627, -0.9949, -0.9531]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2909,  0.2153,  0.2919,  ..., -0.9518,  1.7075,  0.4934],\n",
            "        [-0.7520, -2.0025, -0.1163,  ..., -1.4409, -0.7141, -0.6436],\n",
            "        [ 0.1112,  0.1134, -0.4164,  ...,  0.2139, -0.7211, -1.0663],\n",
            "        ...,\n",
            "        [-0.6369,  0.4050,  0.2333,  ...,  0.5136,  0.3835,  0.9068],\n",
            "        [-0.6955,  0.7530,  1.1860,  ..., -1.2898,  0.1806, -0.6910],\n",
            "        [-0.3963, -0.5206,  0.7083,  ..., -0.8073, -0.1349, -0.4301]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1909, -1.1036, -0.5843,  ..., -0.9556,  0.7112, -0.9869],\n",
            "        [-0.3191, -0.1931, -0.4385,  ..., -0.1160, -1.7647, -0.4074],\n",
            "        [-0.3298, -0.5340, -0.9366,  ...,  0.6199,  3.1209, -0.7550],\n",
            "        ...,\n",
            "        [-0.5484,  0.3156, -0.8319,  ...,  0.3903, -1.0969, -0.1261],\n",
            "        [-0.2291,  0.5526,  0.5569,  ..., -0.2029, -0.5980,  0.5748],\n",
            "        [ 1.0569, -0.8719,  0.6181,  ..., -0.6874, -1.3084, -0.5784]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5476, -0.5856,  0.4318,  ...,  0.8612,  1.1418, -0.3215],\n",
            "        [-0.6068, -0.7024, -0.8488,  ..., -0.7415, -1.5451, -1.0754],\n",
            "        [ 0.8260, -0.7530,  1.3400,  ..., -1.0627, -0.8641, -0.0956],\n",
            "        ...,\n",
            "        [-1.0269, -1.8786, -1.3622,  ...,  0.2555,  0.1463, -0.2443],\n",
            "        [-0.1620,  0.2526,  0.5874,  ..., -1.2668,  0.1672, -0.5247],\n",
            "        [-1.1899,  0.6566,  0.4335,  ..., -1.0457, -0.6985, -0.3584]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8724, -1.1820,  1.2640,  ..., -1.3299, -0.9189, -0.6446],\n",
            "        [ 1.7019,  0.4129,  1.6083,  ..., -0.7382, -0.9025, -0.4524],\n",
            "        [ 0.8205,  0.7790, -0.9145,  ...,  0.8580, -1.5466,  0.5624],\n",
            "        ...,\n",
            "        [ 0.8006,  0.2938,  0.2558,  ..., -0.3895, -1.0527, -0.9361],\n",
            "        [ 2.7651, -0.9486, -0.5602,  ...,  0.1164, -1.2090, -1.2753],\n",
            "        [-0.7254, -0.5389, -1.2947,  ...,  2.2011,  0.2641,  1.2506]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6553,  0.2064,  0.4131,  ...,  0.0779,  0.9542,  0.7939],\n",
            "        [ 0.1008, -0.1629, -0.8291,  ...,  0.7019,  2.2754,  0.7051],\n",
            "        [ 0.4651,  0.4814,  0.0428,  ..., -0.8833,  0.5322, -0.4520],\n",
            "        ...,\n",
            "        [-0.4065, -0.4977,  0.5651,  ..., -0.3431, -0.1789, -0.7195],\n",
            "        [-0.3379, -0.4446, -0.7876,  ...,  0.6310,  3.9255, -0.7513],\n",
            "        [-0.4606,  1.3072, -0.1497,  ..., -0.5543,  0.3565, -0.3784]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2171, -0.3172,  1.1533,  ..., -0.3592, -0.2440, -0.1551],\n",
            "        [-0.7042, -0.8293,  0.6003,  ...,  0.3052,  0.3773,  1.5739],\n",
            "        [ 0.5315, -0.3985, -0.9304,  ...,  0.1561, -1.3629, -0.3449],\n",
            "        ...,\n",
            "        [-0.5886,  0.1709, -0.0556,  ..., -0.2337,  0.4946,  0.0032],\n",
            "        [ 0.6405,  1.6084, -0.2392,  ...,  0.1556, -0.4988,  0.8433],\n",
            "        [-0.3681,  0.2866,  0.1228,  ..., -1.0057, -0.9008, -0.4026]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.5822,  0.0861, -1.4408,  ..., -0.1259, -0.9528, -1.0867],\n",
            "        [ 1.3698, -0.0783, -0.5709,  ...,  1.0059, -0.8976, -0.6859],\n",
            "        [-0.4653,  0.1939,  1.2815,  ..., -1.6245,  0.6633, -0.3382],\n",
            "        ...,\n",
            "        [ 0.8320, -0.6734,  0.0228,  ..., -0.2958, -0.7691, -0.8545],\n",
            "        [-0.3801, -0.4747,  2.2122,  ..., -1.5043, -0.2257, -0.9160],\n",
            "        [ 0.6201,  2.4719,  1.4684,  ...,  0.2199, -0.4137,  0.7310]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2974,  5.2053,  2.5528,  ..., -1.0109,  0.7927,  0.6791],\n",
            "        [-0.0766,  0.7400, -0.1053,  ...,  1.9750,  2.2054,  1.1558],\n",
            "        [-1.3798, -0.8811, -0.8381,  ..., -0.0357,  1.1197,  0.6180],\n",
            "        ...,\n",
            "        [ 0.1926,  0.2060, -0.0501,  ..., -1.0996, -0.5905, -0.6428],\n",
            "        [ 2.6684, -0.6658,  0.8273,  ...,  0.3177, -1.0360, -1.1117],\n",
            "        [-0.5889, -0.7612, -1.1649,  ..., -0.3035,  0.1283, -0.3597]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.8996,  1.5389, -0.3242,  ...,  0.2393, -0.4220, -1.6369],\n",
            "        [-0.3594,  0.0749, -0.9447,  ..., -0.1113, -0.2597,  0.3239],\n",
            "        [-0.8557, -0.8175,  0.4027,  ..., -0.9122,  2.3484, -0.8609],\n",
            "        ...,\n",
            "        [ 0.5905,  0.0596, -0.9015,  ...,  1.1070, -1.2161,  0.0137],\n",
            "        [-0.2424,  0.0191,  0.3258,  ...,  0.4831,  1.0184,  0.7589],\n",
            "        [ 0.7434,  0.9033,  0.7212,  ...,  1.2051, -0.5583, -0.3098]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6933, -1.5487, -0.9151,  ..., -0.7431, -1.5447, -0.1810],\n",
            "        [-0.2503, -0.6850, -0.8015,  ..., -0.7270, -1.8412, -0.4826],\n",
            "        [-0.9320, -1.1834,  0.0982,  ...,  0.3552,  1.0993, -0.3462],\n",
            "        ...,\n",
            "        [-0.2052, -0.4430, -0.7844,  ..., -0.9237, -0.9915, -0.9205],\n",
            "        [-0.7978, -0.8164, -0.8672,  ..., -0.0567,  0.4654, -0.0439],\n",
            "        [ 1.9912, -0.2588, -1.7592,  ...,  0.3738, -1.1007, -0.9890]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.4109, -0.3528, -0.3585,  ..., -0.7829, -0.4623, -1.4463],\n",
            "        [ 0.2165,  0.3426,  0.1417,  ..., -0.6838,  0.1116, -0.2213],\n",
            "        [ 0.3188, -0.7553,  1.6422,  ..., -1.5628, -2.0284, -0.8947],\n",
            "        ...,\n",
            "        [-0.9005, -0.5082, -0.2856,  ..., -0.8959,  0.5000, -0.9205],\n",
            "        [-0.4392, -1.4506,  0.0128,  ..., -1.1782, -1.2756, -0.6328],\n",
            "        [-0.3147, -1.0770, -1.1013,  ..., -0.9130, -1.3488, -0.5098]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0384, -1.1065, -0.5843,  ...,  0.6631,  1.5851, -0.5470],\n",
            "        [-0.4615, -0.4905,  0.4551,  ..., -1.1548, -1.2065, -0.5948],\n",
            "        [-0.9087, -0.7388, -1.1633,  ..., -0.2737,  1.2266,  0.2945],\n",
            "        ...,\n",
            "        [ 3.4407,  0.4230,  0.6374,  ...,  1.4094, -0.2691, -0.4076],\n",
            "        [-1.0909, -1.0037, -0.6461,  ..., -0.8861, -0.6862, -0.6525],\n",
            "        [-0.1325, -0.5893, -0.2879,  ..., -0.7242, -0.2441, -0.8621]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5813, -0.3127,  1.5339,  ..., -0.0667,  0.3803,  0.0499],\n",
            "        [-0.5477,  0.4336, -0.1002,  ..., -0.2308,  2.1630,  0.4030],\n",
            "        [-1.6405, -1.0236, -0.0183,  ..., -1.4274,  0.6617, -0.8097],\n",
            "        ...,\n",
            "        [-0.5718, -0.5771, -0.5000,  ..., -0.0499,  0.3769,  0.5822],\n",
            "        [ 2.0909,  0.3994,  0.7641,  ...,  0.0677, -1.6897,  0.0366],\n",
            "        [-0.7527, -0.6069, -1.1419,  ..., -0.9583, -0.0067, -0.8398]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1640, -0.0524,  0.4169,  ..., -1.4351, -0.7852, -0.0854],\n",
            "        [-1.1651,  0.0615,  0.0765,  ...,  1.2185,  2.4855,  0.6538],\n",
            "        [ 0.0897,  0.4108, -0.1694,  ..., -0.8258,  0.0253, -0.0156],\n",
            "        ...,\n",
            "        [ 1.6329,  1.4841,  0.7608,  ...,  0.7060, -0.9498,  1.1085],\n",
            "        [-0.6372, -0.4353,  0.6077,  ..., -0.5011, -1.4532,  0.6046],\n",
            "        [-0.3018, -0.1860,  0.0969,  ..., -0.2524, -1.6008, -0.0852]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0597e+00, -1.1768e+00, -5.2193e-01,  ..., -1.4000e+00,\n",
            "          9.7023e-01,  1.0467e+00],\n",
            "        [-8.4796e-01,  2.0442e-01, -1.5631e-03,  ..., -5.5132e-01,\n",
            "         -9.1216e-01,  1.7498e-01],\n",
            "        [-3.7739e-01, -2.5594e-01, -5.2386e-01,  ..., -3.5006e-01,\n",
            "          6.4361e-01,  4.3516e-01],\n",
            "        ...,\n",
            "        [-2.6853e-01, -6.2965e-01, -1.4202e-01,  ..., -1.1901e-01,\n",
            "         -2.3148e-01,  7.6213e-02],\n",
            "        [-1.0640e+00, -6.7310e-01, -5.0412e-01,  ..., -3.8823e-01,\n",
            "          9.9714e-01,  7.8163e-01],\n",
            "        [-1.0449e+00, -3.7108e-01,  5.8655e-01,  ..., -8.0709e-01,\n",
            "          1.6655e+00, -1.5144e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4221, -0.3178, -0.3895,  ...,  1.0185,  0.4464,  1.3944],\n",
            "        [-0.5374, -1.0437, -1.6318,  ..., -0.7180, -0.9606, -0.8242],\n",
            "        [-0.0863, -1.0394,  1.4156,  ..., -0.7675, -0.7145, -0.1277],\n",
            "        ...,\n",
            "        [-0.3072, -0.9459, -1.2392,  ..., -0.3365, -1.0480, -0.3482],\n",
            "        [ 0.5221,  0.0471, -0.4238,  ..., -1.2739, -1.0722, -0.6379],\n",
            "        [-0.5426, -0.9794,  0.7101,  ..., -0.1621,  1.7620,  0.9935]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3791, -1.8984, -2.1164,  ..., -0.3256, -1.0675, -0.1200],\n",
            "        [-0.3336,  0.4617, -0.0457,  ..., -0.9098, -0.9743,  0.0394],\n",
            "        [-1.4470, -0.7942, -0.6990,  ...,  0.0255,  0.3336,  0.1726],\n",
            "        ...,\n",
            "        [ 1.2933,  0.5532, -0.6682,  ...,  0.9650,  0.0246,  0.6627],\n",
            "        [-0.0348, -1.7299,  0.3209,  ..., -1.0391, -0.6693, -0.4947],\n",
            "        [-0.0750,  0.5323,  0.2400,  ..., -0.6515, -0.7825, -0.1335]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,680  of  2,811.    Elapsed: 1:10:30.\n",
            "logits :  tensor([[ 0.5220,  0.3867,  0.2559,  ...,  0.6484,  1.2392,  0.6002],\n",
            "        [-0.1169,  1.7770,  1.3978,  ...,  1.6499, -0.3245,  2.5659],\n",
            "        [ 0.2954, -0.3592,  2.7490,  ..., -1.2599, -0.8490, -1.1718],\n",
            "        ...,\n",
            "        [-0.2213, -1.0003, -1.2510,  ..., -0.4484, -0.9634, -0.5106],\n",
            "        [ 1.1040, -0.1663,  0.5763,  ...,  1.0075, -1.0863,  0.8845],\n",
            "        [-0.5536, -0.2073,  1.1374,  ..., -0.7216, -0.0046, -0.8640]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.3779, -0.3964, -1.1598,  ..., -1.0064, -1.4813, -0.4572],\n",
            "        [-0.4110, -0.7815,  0.9287,  ..., -0.5818, -0.9753, -1.3362],\n",
            "        [-0.9172, -0.7712, -1.3310,  ..., -0.7063, -0.9138, -1.2385],\n",
            "        ...,\n",
            "        [-0.7599, -0.5253,  0.8444,  ..., -1.0024,  0.2529, -1.1142],\n",
            "        [-0.4982, -0.6715, -1.2076,  ..., -0.6568, -1.2174, -1.0071],\n",
            "        [ 0.4635, -0.5918, -1.2539,  ..., -0.5156, -0.6171, -1.0386]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1828, -0.8041, -0.4356,  ...,  0.0940,  1.1493, -0.7710],\n",
            "        [ 0.6119, -1.6465,  0.0606,  ..., -1.8411, -1.6784, -0.3343],\n",
            "        [ 0.2299, -1.4178, -0.3580,  ..., -1.3402, -1.3884, -1.2227],\n",
            "        ...,\n",
            "        [ 1.1641,  0.5241, -1.2654,  ..., -0.7295,  0.1823, -0.8793],\n",
            "        [-1.1851, -0.0374,  0.0738,  ..., -1.0973,  0.3139, -1.1419],\n",
            "        [-0.3921, -0.8116, -0.6510,  ..., -1.1959, -0.3289, -0.8830]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.6861,  0.2779, -0.9495,  ...,  1.7173, -0.6579, -0.5776],\n",
            "        [ 2.2376,  0.8723,  0.1181,  ...,  0.8886, -1.9822, -0.2406],\n",
            "        [ 0.0093, -0.7857, -0.1172,  ..., -0.7927, -1.4961, -0.9096],\n",
            "        ...,\n",
            "        [-0.7195, -0.7188,  2.4993,  ..., -1.2693, -1.8208,  0.6254],\n",
            "        [-0.4739, -0.1543, -0.4209,  ..., -0.2810,  1.2273,  0.0885],\n",
            "        [ 0.3369, -0.0400,  3.3681,  ..., -1.2360, -0.8630, -0.1134]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1278, -0.7885, -1.7100,  ...,  0.8242, -0.1598, -0.9660],\n",
            "        [-0.0777,  0.1395,  0.4799,  ...,  0.3670,  1.3654, -0.0441],\n",
            "        [-1.0581, -1.3757,  0.6011,  ..., -0.1669,  0.1499, -0.3819],\n",
            "        ...,\n",
            "        [-0.8671, -0.4465, -0.1989,  ..., -0.1704,  2.0147, -0.8062],\n",
            "        [-0.8659,  0.1152,  0.6245,  ..., -0.4315,  0.6167,  0.8766],\n",
            "        [ 2.5158,  0.5801, -0.0386,  ...,  0.4172, -1.6774, -0.0672]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0149, -0.7433, -0.5160,  ..., -0.8396,  0.4967,  0.0158],\n",
            "        [-1.1650, -1.1075, -0.0354,  ...,  0.0763,  0.7498,  0.2937],\n",
            "        [ 2.4639,  0.7786,  0.5707,  ...,  1.0170, -1.0765, -0.6084],\n",
            "        ...,\n",
            "        [ 0.3473, -0.8516, -1.0422,  ..., -0.8885, -1.7697, -1.1302],\n",
            "        [ 1.7693,  0.0101, -0.5047,  ...,  0.2309, -2.0562,  0.3970],\n",
            "        [ 0.2746, -1.0409,  1.7636,  ..., -1.1096, -2.0003,  0.3939]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.5348,  0.7049, -1.3423,  ...,  0.1889, -0.3089, -0.1873],\n",
            "        [-0.7843, -0.5400, -0.4936,  ...,  0.1512,  4.0345,  0.7623],\n",
            "        [-0.2355,  1.4479,  7.0119,  ..., -2.2463, -0.0365,  0.2219],\n",
            "        ...,\n",
            "        [ 0.2533,  1.3138, -0.0254,  ...,  0.8740,  1.6860,  1.1059],\n",
            "        [-0.9281, -0.3204,  0.1332,  ..., -0.2396,  0.0713, -0.5597],\n",
            "        [-0.4307, -0.0974,  0.5479,  ...,  0.1098,  1.6594,  0.3829]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0942, -0.7021, -0.1971,  ...,  0.8568,  0.6774, -0.3944],\n",
            "        [ 0.3950,  1.6634,  0.9856,  ..., -0.2878,  1.3400, -0.0558],\n",
            "        [-0.6828, -0.1340,  1.4207,  ..., -0.4091, -0.2151, -0.9050],\n",
            "        ...,\n",
            "        [-0.4118, -0.8379, -0.5538,  ..., -1.4381, -1.6909, -0.9681],\n",
            "        [-0.5183, -0.1776,  0.6379,  ..., -0.8079,  1.3161, -0.7118],\n",
            "        [-1.2468, -0.0247,  1.0102,  ..., -1.7122, -1.0665, -1.3455]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2481, -0.9827,  2.2528,  ..., -1.4615, -1.3312, -0.0515],\n",
            "        [ 0.1161, -0.2598, -0.4070,  ..., -1.2542, -1.1314, -0.4937],\n",
            "        [-0.5901, -1.0592,  0.0621,  ..., -0.1301,  1.6547, -0.7569],\n",
            "        ...,\n",
            "        [ 0.1122, -0.5800, -0.0478,  ..., -0.9561, -0.2299, -0.4564],\n",
            "        [-0.7757, -0.4968, -0.6872,  ..., -0.8680, -0.8197, -1.0383],\n",
            "        [ 0.5532, -0.0796,  1.1644,  ..., -0.2196, -0.3572,  0.4477]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9326, -0.8268, -1.7469,  ...,  0.0385, -0.0185, -0.9803],\n",
            "        [-0.1296, -0.9309,  2.3643,  ..., -1.0923, -0.6148, -0.1934],\n",
            "        [-0.8923, -0.4400, -1.8757,  ...,  2.9233, -0.5867,  0.1246],\n",
            "        ...,\n",
            "        [ 0.5503, -0.7567, -1.0575,  ...,  0.3846, -0.8307, -1.1707],\n",
            "        [-1.0409, -0.1025,  0.7659,  ..., -0.1735, -0.8834, -1.0040],\n",
            "        [-0.9821, -1.6900,  0.9513,  ..., -1.2742, -0.6955,  0.8750]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9637, -0.4660,  0.2150,  ..., -0.4235,  1.6910, -0.5348],\n",
            "        [ 0.0388, -0.6838, -0.8626,  ..., -0.8736, -0.9879, -0.8098],\n",
            "        [-0.1858,  1.5650,  0.2187,  ...,  0.8300,  1.3038,  1.1868],\n",
            "        ...,\n",
            "        [ 0.9442,  0.3745, -1.6638,  ...,  1.7609,  0.6063,  0.1652],\n",
            "        [-1.0103, -0.6931,  0.1529,  ..., -1.0772,  0.1374, -0.7145],\n",
            "        [-0.1166,  1.1077,  0.5987,  ..., -0.1879,  1.6764,  0.4089]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2925, -0.5396, -0.1638,  ..., -0.5093, -0.8028, -0.1936],\n",
            "        [ 0.1123, -0.8806,  0.7631,  ..., -1.5937, -0.0963, -0.2598],\n",
            "        [ 0.3871, -0.4175, -0.0500,  ...,  0.2643, -1.1330, -0.3837],\n",
            "        ...,\n",
            "        [-0.5635, -1.5475, -0.0682,  ..., -1.0529, -0.9033, -0.4502],\n",
            "        [-0.2167, -0.2999,  0.0558,  ..., -1.3444, -0.2956, -1.1430],\n",
            "        [-0.3687, -0.8470, -1.5693,  ...,  1.9667,  0.3028,  0.8624]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.2926,  0.7017,  1.0830,  ..., -0.2799,  0.1861, -0.6844],\n",
            "        [-0.7398, -0.2099, -1.1928,  ...,  0.8904,  5.8342,  1.4755],\n",
            "        [-0.4234, -0.6270, -0.7853,  ..., -0.7619, -0.5253, -0.6632],\n",
            "        ...,\n",
            "        [ 6.0136,  1.2254, -0.1806,  ...,  0.4807, -1.1825, -1.6642],\n",
            "        [-1.1191, -1.1045, -0.3674,  ..., -0.0161,  0.8641, -0.2183],\n",
            "        [-1.2942,  0.6823,  0.4449,  ..., -1.2667, -0.4361, -0.2832]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0832, -0.5929, -0.7697,  ..., -0.7918,  0.2596,  0.4896],\n",
            "        [-0.6190,  0.1629, -0.3542,  ...,  0.9270, -0.8222,  0.8292],\n",
            "        [-0.2188,  0.0375,  0.6298,  ...,  0.9102, -0.5802,  5.5872],\n",
            "        ...,\n",
            "        [ 1.7402,  2.4271,  0.3032,  ..., -0.4953, -0.1666, -0.7767],\n",
            "        [ 0.1560, -0.3260,  1.3501,  ..., -0.6907, -0.5400, -1.3175],\n",
            "        [-1.5732,  0.5072,  0.3574,  ..., -0.1137,  0.4657,  0.9618]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.4718, -0.1891,  1.4326,  ..., -0.8699, -0.5221,  0.1685],\n",
            "        [-1.1560, -2.0281, -1.4947,  ...,  0.0444,  0.3049, -0.1807],\n",
            "        [ 1.2211, -1.1505,  0.7044,  ..., -1.0302, -0.6152, -0.7441],\n",
            "        ...,\n",
            "        [ 1.3987,  0.6761,  0.5966,  ...,  0.8347, -0.9489,  0.7703],\n",
            "        [ 1.1415,  0.0253, -1.0335,  ...,  0.3965, -1.5094, -0.8251],\n",
            "        [ 0.1496,  2.1873,  6.4477,  ..., -1.9882, -0.6557,  0.8833]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0135, -0.3482, -2.0981,  ...,  2.3710, -0.2945,  0.7450],\n",
            "        [-0.6865,  0.9316, -0.0236,  ...,  0.2331,  0.1431,  0.9936],\n",
            "        [ 1.6637,  0.4315, -1.2901,  ...,  0.8283,  0.6548, -0.3536],\n",
            "        ...,\n",
            "        [-0.0878, -0.2075, -0.8990,  ..., -0.9518, -0.2316, -0.2801],\n",
            "        [ 2.4910,  1.0610, -0.3827,  ..., -0.8797, -0.6868, -0.6512],\n",
            "        [-0.5275, -0.7553, -1.1280,  ..., -0.6968, -1.0616, -0.7929]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9746, -0.9373,  0.1289,  ..., -0.0594, -0.6273, -0.6235],\n",
            "        [-0.4547,  0.0139,  0.2558,  ..., -0.8184,  1.2850, -0.8178],\n",
            "        [-0.7213,  0.6806, -0.3604,  ...,  0.3502,  0.3718,  1.4845],\n",
            "        ...,\n",
            "        [-0.5544,  0.2758, -0.2319,  ...,  0.3814, -0.4194, -0.0123],\n",
            "        [-1.2233, -0.8956, -1.3222,  ..., -0.8542, -0.8822, -0.6673],\n",
            "        [ 0.2565, -0.8200, -1.3023,  ..., -0.9034, -0.6439, -0.7251]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.4893, -0.0405,  1.2689,  ...,  0.0955, -0.0661, -0.9794],\n",
            "        [-0.8857, -0.7161, -0.7616,  ..., -0.5079,  0.9250,  0.3289],\n",
            "        [-0.7828, -0.3433, -0.3188,  ..., -0.6616,  0.9268, -0.0278],\n",
            "        ...,\n",
            "        [-0.1699, -0.0172, -0.3740,  ..., -1.0099, -0.3685, -0.8439],\n",
            "        [-0.8872, -0.2703,  2.9063,  ..., -0.8350, -0.7831, -0.4655],\n",
            "        [ 0.2768,  0.2030, -0.3455,  ...,  0.7498,  0.7540, -0.9938]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8813, -0.1090, -1.5332,  ...,  1.9051,  0.3166,  1.2953],\n",
            "        [-0.3122, -1.4614, -0.2459,  ..., -1.6183, -0.7525, -0.9669],\n",
            "        [-1.2258, -0.9963, -0.0309,  ...,  0.0659, -1.2432, -0.2751],\n",
            "        ...,\n",
            "        [ 2.3519,  1.5283,  1.3737,  ..., -0.4360, -0.4905, -0.8238],\n",
            "        [-1.1237, -0.7970, -0.0359,  ..., -0.8805, -0.2104, -1.4737],\n",
            "        [-0.5546,  0.8510,  0.7891,  ..., -1.2428,  0.4498, -0.4602]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.2937,  0.1507,  1.2244,  ..., -0.6536, -0.4977,  0.5457],\n",
            "        [-0.3343, -0.7587, -1.0931,  ..., -0.3461, -0.7814, -0.7928],\n",
            "        [-1.3529, -1.2785, -0.0170,  ..., -1.0895, -0.3445, -1.0565],\n",
            "        ...,\n",
            "        [-0.4997, -0.6796, -1.0794,  ...,  0.5621, -0.7419,  0.3055],\n",
            "        [-0.0051, -0.2822, -0.4599,  ..., -0.7129, -1.0200, -1.7097],\n",
            "        [ 0.2608, -0.9140, -0.4935,  ..., -0.4215, -0.6524, -1.4166]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3852, -0.1832, -1.3894,  ...,  2.8945,  0.1040,  1.3704],\n",
            "        [ 0.0481, -0.2777, -0.9134,  ..., -0.9774, -0.8993, -0.3128],\n",
            "        [ 1.6037,  0.2692, -1.2680,  ...,  0.9489, -0.1734, -0.6773],\n",
            "        ...,\n",
            "        [-0.8723, -0.7130, -1.0607,  ...,  1.4159,  0.1916,  1.0816],\n",
            "        [ 0.0591, -1.0561, -0.5569,  ..., -0.7333,  0.4552, -0.4005],\n",
            "        [ 0.7008,  0.9188, -0.0071,  ...,  0.2754, -1.4236, -0.2375]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4599, -0.9575, -0.2251,  ..., -0.4948, -0.7556,  0.0702],\n",
            "        [ 0.5030,  7.2490,  1.0643,  ...,  0.2235, -0.0132,  0.0800],\n",
            "        [-0.8647, -1.5025, -1.7388,  ..., -0.1691, -0.0828, -1.2146],\n",
            "        ...,\n",
            "        [ 0.8448,  0.8479,  0.7647,  ...,  0.9496, -0.8164, -0.8555],\n",
            "        [ 1.6767, -0.0305, -1.4845,  ..., -0.1392, -0.5400, -0.7828],\n",
            "        [-0.5999, -0.6972, -1.1958,  ...,  2.1225,  0.0868,  1.5769]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6918,  0.4942, -0.1556,  ..., -0.8973, -0.5243, -0.8494],\n",
            "        [-0.4730, -0.1469, -0.6379,  ...,  1.0024,  1.1655,  1.5962],\n",
            "        [ 2.1413,  2.1064,  1.0243,  ..., -0.1790, -1.6000, -0.2911],\n",
            "        ...,\n",
            "        [-0.6211,  0.0641, -0.5631,  ...,  1.1848, -0.1642,  0.9599],\n",
            "        [ 1.5215, -0.1287, -0.0754,  ...,  0.5409, -1.6029,  0.8252],\n",
            "        [ 0.3513, -0.4301, -1.4876,  ...,  0.5479,  0.0230,  0.3957]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6380, -0.4050, -0.6359,  ...,  1.0588, -1.5559,  1.0218],\n",
            "        [ 0.1384,  0.2879, -0.7847,  ...,  0.9024,  2.1472,  0.3112],\n",
            "        [-1.2276, -0.5795, -0.3982,  ..., -0.6083,  0.6360, -0.2300],\n",
            "        ...,\n",
            "        [-0.3095, -1.5072, -0.1637,  ..., -1.2161, -0.7340, -1.0802],\n",
            "        [-0.3812,  1.1062,  0.3149,  ...,  0.8075,  1.4646,  1.8727],\n",
            "        [-0.4333, -0.8243, -0.8047,  ..., -1.0117, -1.1866, -0.2641]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.3277, -1.3729,  1.0115,  ..., -0.4496, -0.8126, -0.0642],\n",
            "        [ 0.8149, -0.0679, -1.8761,  ...,  1.3270,  0.5047, -0.3118],\n",
            "        [-0.4741, -0.1789, -0.1999,  ..., -0.6521,  0.3980, -0.3112],\n",
            "        ...,\n",
            "        [-0.9840, -0.7706,  1.2325,  ..., -0.9989,  0.2683, -0.7077],\n",
            "        [ 1.8760,  0.1278,  1.3815,  ...,  0.2002, -0.8141,  0.0352],\n",
            "        [-0.2827, -0.1491,  2.2209,  ..., -0.1061, -0.4428,  0.5281]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.3996, -0.5399, -0.1792,  ..., -1.1710, -0.6325, -0.8462],\n",
            "        [-0.0509, -1.1274,  0.4712,  ..., -1.0770, -1.0477, -0.7291],\n",
            "        [-0.4935, -1.1507, -0.0933,  ..., -0.8942, -1.3345, -0.2282],\n",
            "        ...,\n",
            "        [ 2.5438,  1.2921,  0.6227,  ...,  0.3491, -0.9836, -1.2077],\n",
            "        [ 0.7393,  0.2893, -1.9966,  ...,  1.8553,  0.6036, -0.7742],\n",
            "        [-0.9477, -0.6243,  0.5742,  ..., -0.2915,  1.1468,  0.9894]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9445,  0.2853,  0.3718,  ..., -0.4510,  0.2059,  1.0512],\n",
            "        [ 3.5399,  0.7605, -1.5704,  ...,  0.5580, -1.4805, -1.0279],\n",
            "        [-0.8890,  0.7430,  0.9470,  ..., -1.5425, -0.2112, -0.5245],\n",
            "        ...,\n",
            "        [-0.2054, -1.0564,  2.0800,  ..., -1.5831, -1.3741, -0.1451],\n",
            "        [-0.4332, -0.8558, -0.1758,  ..., -0.5009, -0.1656, -0.8665],\n",
            "        [ 0.3834,  0.7141, -0.2348,  ..., -0.9230,  0.0370, -0.2863]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.3041, -1.0670, -0.9655,  ...,  0.6921,  0.2700, -0.0692],\n",
            "        [-0.6617, -0.9396,  0.4108,  ..., -1.2687, -1.3714, -0.4192],\n",
            "        [-0.7085, -0.4949, -1.3345,  ...,  0.2293, -0.8984, -1.0441],\n",
            "        ...,\n",
            "        [ 2.1547,  0.7007,  0.7333,  ...,  1.2253, -1.3112,  0.8190],\n",
            "        [-0.4688, -0.7338,  0.2101,  ..., -0.5190, -1.1703, -0.0675],\n",
            "        [-0.0625, -0.3124, -0.2181,  ..., -0.3229,  0.3147,  0.2017]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 4.0431e-01, -5.7094e-03, -1.0073e+00,  ..., -1.4845e-01,\n",
            "         -3.3860e-01, -6.2840e-01],\n",
            "        [-5.7465e-01, -5.6302e-01,  7.1496e-01,  ..., -5.0461e-01,\n",
            "          1.9111e-01, -9.3697e-01],\n",
            "        [-6.7175e-01, -3.2916e-01, -1.4704e-01,  ..., -3.9420e-01,\n",
            "         -6.5808e-01, -9.0497e-01],\n",
            "        ...,\n",
            "        [ 1.0206e+00, -1.6636e-02, -2.6922e+00,  ...,  6.4756e+00,\n",
            "          7.9243e-01,  4.3144e-01],\n",
            "        [ 1.1923e-01, -9.8430e-01, -1.9513e+00,  ...,  1.2344e-01,\n",
            "         -6.3577e-01, -4.1104e-01],\n",
            "        [ 4.0113e-01, -6.4120e-01,  6.8519e-01,  ..., -1.2994e+00,\n",
            "         -1.0155e+00, -8.0360e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3419, -1.4856, -0.6330,  ..., -0.3652,  2.5459, -0.9155],\n",
            "        [-0.0425,  0.8624, -0.0459,  ..., -0.3943,  0.3060, -0.2417],\n",
            "        [-0.2143,  1.0923,  1.1407,  ..., -0.0599, -0.6288,  1.0557],\n",
            "        ...,\n",
            "        [-0.6059, -0.4946, -0.7090,  ...,  0.1856,  2.6021, -0.8855],\n",
            "        [-0.8240, -1.3669, -0.5957,  ..., -1.1575, -1.2094, -1.2446],\n",
            "        [-0.3645, -0.0065,  0.5393,  ..., -0.9463, -0.4357,  0.3863]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0475,  1.2721,  1.4989,  ..., -1.0151, -0.1497,  0.4107],\n",
            "        [-0.8205,  0.5185,  0.4332,  ...,  0.5118,  3.7668,  0.3344],\n",
            "        [ 0.8436, -1.0267,  1.1273,  ..., -0.7948, -0.8088, -1.0621],\n",
            "        ...,\n",
            "        [ 0.9592, -0.1274, -2.6654,  ...,  6.6432,  0.4851,  1.3752],\n",
            "        [-0.5129,  0.7443,  0.2989,  ...,  0.4408,  2.0532,  0.7993],\n",
            "        [ 1.8070, -0.1231, -1.1308,  ..., -0.4080, -1.5430, -0.8967]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.8711,  0.5972, -1.1167,  ...,  1.5086,  0.3681, -0.2298],\n",
            "        [-0.2720, -0.5378,  0.2601,  ..., -0.4873, -0.9028, -1.3752],\n",
            "        [-0.2370,  0.4236, -0.8562,  ...,  1.4025,  0.2569,  0.5786],\n",
            "        ...,\n",
            "        [ 0.0794,  0.5467,  7.1020,  ..., -1.9616, -0.2459, -0.7683],\n",
            "        [-0.7134, -0.1473, -0.6671,  ...,  0.6939,  0.4958,  0.6702],\n",
            "        [-0.5623,  0.2308,  0.3961,  ...,  0.6421, -0.3692,  2.9198]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.6843,  0.8746,  0.1762,  ...,  0.3668,  0.4636,  0.4715],\n",
            "        [-0.0551, -1.4659,  2.1523,  ..., -1.0282, -1.0087,  0.0202],\n",
            "        [ 0.3839,  0.1153,  0.2464,  ...,  0.6674, -1.4157,  0.9545],\n",
            "        ...,\n",
            "        [-0.1769, -0.5359, -0.5060,  ..., -0.5083, -0.3988, -0.5901],\n",
            "        [ 2.3477,  0.6346, -0.2885,  ...,  0.5432, -1.4189, -1.3747],\n",
            "        [-0.4646, -0.9194, -1.8443,  ..., -0.1845, -1.1008, -0.6817]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5491, -1.5398,  0.8214,  ..., -1.1383, -0.9284, -0.3245],\n",
            "        [ 0.5062,  0.2448, -1.3819,  ...,  1.8750,  0.1831,  0.8346],\n",
            "        [-0.3426,  1.1098, -0.7168,  ...,  0.4219,  0.1636,  1.0916],\n",
            "        ...,\n",
            "        [-0.4757, -0.4889, -0.5931,  ..., -0.0273,  0.4717,  0.5752],\n",
            "        [-0.6303,  0.1727, -0.5817,  ...,  1.0271,  1.3581,  0.5699],\n",
            "        [ 0.4331, -0.7011,  1.5511,  ..., -0.4204, -0.9401, -0.6076]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5224, -0.2956,  6.5801,  ..., -2.5894, -0.6795, -0.3137],\n",
            "        [ 3.0750,  0.4835,  0.4373,  ...,  0.4118, -1.6999, -0.3381],\n",
            "        [-0.5521, -0.3959, -0.5045,  ..., -0.6702, -1.0571, -0.6130],\n",
            "        ...,\n",
            "        [ 0.2454, -0.9315, -0.6683,  ...,  0.7000,  0.4235, -0.2242],\n",
            "        [-0.4047, -0.3603, -0.3013,  ..., -0.5918, -0.1212, -1.3991],\n",
            "        [ 1.0176,  0.0891,  0.5740,  ...,  1.2361, -1.3153,  1.3802]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.0512,  0.8718,  0.7425,  ..., -0.4575, -0.2421, -0.8309],\n",
            "        [-0.6436, -0.1079, -0.5761,  ..., -0.3617, -0.4202, -0.9036],\n",
            "        [ 1.6370,  0.7466, -0.5459,  ..., -0.4431, -0.0800, -1.1121],\n",
            "        ...,\n",
            "        [ 2.7951, -0.1473,  1.0273,  ..., -0.3843, -1.8172, -0.9104],\n",
            "        [-0.4923, -1.0870,  0.1292,  ...,  0.2852,  0.3976, -0.3497],\n",
            "        [-0.7405, -0.4378, -0.4984,  ...,  0.4120,  0.0373,  1.6867]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5614, -0.9873, -1.2464,  ..., -0.9987, -0.9100, -0.6595],\n",
            "        [-0.2321,  0.4495,  0.3370,  ..., -0.9237,  0.4232, -0.2950],\n",
            "        [-0.1534, -0.9899, -0.0514,  ..., -0.0418, -0.8674, -0.9225],\n",
            "        ...,\n",
            "        [ 0.7140, -0.7177,  0.8220,  ..., -0.9591,  0.0270, -0.5208],\n",
            "        [-0.0375, -1.5180, -1.6679,  ...,  0.3931,  0.0747, -0.5353],\n",
            "        [ 2.0848, -0.1712,  0.1089,  ..., -0.3748, -0.8084, -1.6072]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8696, -0.0552, -0.7844,  ...,  0.4632,  6.9631,  0.3762],\n",
            "        [ 6.1264,  0.8525, -0.5395,  ...,  1.0143, -1.1476, -1.4474],\n",
            "        [-0.9939, -0.5887, -1.3497,  ..., -0.5547, -0.8661, -0.9210],\n",
            "        ...,\n",
            "        [-0.8710,  0.3401,  1.6147,  ..., -1.0789, -0.9881,  0.5304],\n",
            "        [ 2.2060,  0.5883, -1.3817,  ...,  2.1619, -0.5975, -1.0269],\n",
            "        [-0.6946, -0.7559,  0.9912,  ..., -0.9596, -1.1094,  2.5065]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2087, -0.6254, -0.0825,  ..., -0.8422, -1.1587, -1.1413],\n",
            "        [ 0.2510, -0.5467,  0.8125,  ..., -0.6203, -0.4162, -0.2153],\n",
            "        [-0.4527,  0.0785,  0.0127,  ..., -0.2022,  0.2518, -0.6338],\n",
            "        ...,\n",
            "        [ 2.8207,  0.2700, -0.6473,  ...,  1.8873, -1.0715, -0.2644],\n",
            "        [ 0.6038, -0.7858, -0.3679,  ..., -0.5696, -0.6832,  0.4037],\n",
            "        [-0.8874,  0.0254, -0.1165,  ..., -1.1357, -0.9203, -1.1686]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.8279,  0.3176,  1.3884,  ..., -0.3944, -1.4315, -0.3700],\n",
            "        [ 0.4812, -0.0612,  0.6252,  ..., -1.2366, -0.3067, -0.9058],\n",
            "        [-0.3162, -1.0719,  0.0466,  ..., -1.1612, -1.4150, -0.9051],\n",
            "        ...,\n",
            "        [ 0.0997, -0.0735, -0.2204,  ..., -1.3947, -0.8435, -0.4412],\n",
            "        [-0.1612, -0.8009, -0.5121,  ...,  0.5462,  2.5105, -0.9009],\n",
            "        [-0.4814, -0.1163,  0.6676,  ..., -0.1040, -0.3279, -1.2891]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,720  of  2,811.    Elapsed: 1:11:32.\n",
            "logits :  tensor([[-0.3897, -0.7924, -0.3064,  ...,  0.4764,  1.3008, -0.8078],\n",
            "        [-1.2016, -1.4728,  1.4597,  ..., -1.5198, -0.5818,  0.3186],\n",
            "        [-1.1640,  0.1934,  0.1227,  ...,  1.2412,  0.7131,  7.5208],\n",
            "        ...,\n",
            "        [-1.1882,  0.0851,  0.3874,  ...,  0.4346,  3.6248, -0.1378],\n",
            "        [ 1.1091,  0.4303, -1.1961,  ...,  1.8425, -0.1725,  0.1703],\n",
            "        [ 0.3883,  0.0471, -0.9829,  ...,  1.7337, -1.1217,  0.5138]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0396e+00,  1.6204e-01, -1.3633e-01,  ..., -9.5228e-01,\n",
            "         -4.4316e-01, -3.6522e-01],\n",
            "        [ 1.0072e-03, -2.0902e-01, -1.1997e+00,  ...,  1.0130e+00,\n",
            "          1.8557e-01, -2.7943e-02],\n",
            "        [-8.0063e-01, -6.1633e-01, -2.0037e-01,  ..., -2.2454e-01,\n",
            "          2.6531e+00, -1.2017e+00],\n",
            "        ...,\n",
            "        [-6.5636e-03,  7.9941e-01,  3.0972e-01,  ..., -1.2125e+00,\n",
            "         -2.0242e-02, -5.0384e-01],\n",
            "        [-6.8659e-02,  1.2758e+00,  7.7311e+00,  ..., -2.4793e+00,\n",
            "         -2.2274e-01,  5.1457e-03],\n",
            "        [-5.8961e-01,  5.4214e-01,  3.2333e-01,  ..., -1.2032e+00,\n",
            "          7.2268e-01, -4.2591e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4227, -0.8205, -0.4682,  ..., -0.3997, -0.2632,  0.1099],\n",
            "        [-0.8073, -0.7208,  0.7295,  ..., -1.2039, -0.7143,  0.8012],\n",
            "        [ 0.1427,  0.0832,  6.0561,  ..., -2.5835, -0.2352, -0.3246],\n",
            "        ...,\n",
            "        [-0.7600, -0.3387,  0.7820,  ..., -0.4454, -0.4058, -0.9801],\n",
            "        [-0.3980, -0.6893, -0.2939,  ..., -0.4275,  0.7478, -0.9404],\n",
            "        [-0.5760, -0.6608, -1.1630,  ..., -0.7848, -1.2591, -1.0193]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9723,  0.1039, -0.0581,  ...,  0.2334, -0.1304, -1.0885],\n",
            "        [-0.7487, -0.7424, -1.6550,  ...,  0.4601,  0.5137,  0.2223],\n",
            "        [ 1.2077,  1.0605, -0.4991,  ...,  0.5787, -0.1393, -1.5317],\n",
            "        ...,\n",
            "        [-0.5932,  0.0509, -0.2844,  ..., -0.8210,  1.0903, -0.2599],\n",
            "        [-0.5520, -0.4021,  0.7292,  ...,  0.0909, -0.0481,  0.0326],\n",
            "        [-0.8813,  0.8304,  0.7914,  ..., -0.4859,  0.5407,  1.0268]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9114,  0.3861, -0.8145,  ..., -0.2421,  0.2703, -0.9745],\n",
            "        [-0.6535, -0.7781, -0.9146,  ..., -0.0830,  0.3187, -0.1329],\n",
            "        [ 1.1515,  0.1969, -1.3188,  ...,  0.3087,  0.5490, -0.9279],\n",
            "        ...,\n",
            "        [-0.6692, -0.5761, -0.6722,  ...,  0.5931,  3.3372, -0.5618],\n",
            "        [ 1.0010, -1.0046, -0.9886,  ...,  0.1072, -1.0975, -0.8129],\n",
            "        [-0.6447, -0.3509,  0.1058,  ..., -0.5950,  0.3142, -0.1079]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.6584,  0.0724, -2.3781,  ...,  7.0403,  0.6125,  1.6254],\n",
            "        [-0.7673,  0.0352,  1.2403,  ..., -0.1742, -0.4065, -1.5218],\n",
            "        [-0.7521, -0.6233,  0.1552,  ..., -0.4773, -0.7149, -0.7175],\n",
            "        ...,\n",
            "        [-0.0250,  7.0736,  1.9480,  ..., -0.4034, -0.1664,  0.8488],\n",
            "        [ 0.8412, -0.8651,  0.3363,  ..., -0.7181, -0.2772, -0.0983],\n",
            "        [-0.5273, -0.8794, -0.7532,  ...,  0.4525,  0.5421,  1.4192]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0472, -1.4104, -0.3123,  ..., -1.4129, -0.6181, -0.7839],\n",
            "        [-0.6933, -0.6439, -0.0206,  ..., -0.4458, -0.3636, -0.5857],\n",
            "        [ 0.7197, -1.5509, -0.9132,  ..., -0.7568, -1.2169, -1.1339],\n",
            "        ...,\n",
            "        [-1.0121, -1.2400, -1.2344,  ..., -0.3271, -0.5916, -1.1537],\n",
            "        [-0.6387,  0.1860, -0.7583,  ...,  0.8502,  1.0147,  0.7939],\n",
            "        [ 1.7383, -0.3388,  1.3297,  ..., -0.0259, -0.6206, -0.9144]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1711, -0.9028,  0.0481,  ..., -1.3922, -1.2481, -0.7619],\n",
            "        [ 0.6218, -0.4786,  0.1091,  ..., -0.9085,  0.2230, -0.2877],\n",
            "        [ 0.0622, -0.4089, -0.5324,  ..., -1.1264, -0.5541, -0.4049],\n",
            "        ...,\n",
            "        [ 6.4199,  1.0886, -0.0713,  ...,  0.9100, -0.9795, -1.5506],\n",
            "        [-0.4986, -1.0502, -0.1042,  ..., -0.0254, -1.1591, -0.1694],\n",
            "        [ 0.4532, -0.3749, -1.0691,  ..., -0.4780, -0.5788, -1.7889]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2124, -0.1954,  0.4250,  ..., -0.0135, -0.1586, -0.4062],\n",
            "        [-0.3202,  0.0816, -0.1447,  ...,  0.3730, -0.5514,  1.7266],\n",
            "        [ 1.8579,  1.7222, -1.0766,  ...,  1.1660,  0.1739, -0.4018],\n",
            "        ...,\n",
            "        [ 0.6101,  0.6689,  0.2011,  ..., -0.2119, -1.1795, -0.3672],\n",
            "        [-0.7643, -0.7513,  0.0274,  ...,  0.2098,  1.1896,  0.7682],\n",
            "        [-0.4678, -1.2213, -0.8704,  ..., -0.0575,  1.2513, -1.0233]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9419, -0.8636, -1.5671,  ..., -0.0146, -1.3946, -1.6554],\n",
            "        [ 1.1504,  0.8747,  0.3600,  ..., -0.6947, -1.2640, -0.7622],\n",
            "        [ 0.2973, -0.4916, -0.3317,  ...,  0.8397,  0.4161, -0.2210],\n",
            "        ...,\n",
            "        [-0.1525,  0.1094, -0.0170,  ...,  0.7829, -0.1369,  1.9980],\n",
            "        [-0.1996, -0.4155, -1.9796,  ...,  2.3431, -0.0387,  1.5346],\n",
            "        [-0.7831, -0.5101,  0.0208,  ..., -1.2692, -1.4837, -1.4740]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.3148,  1.1384,  1.4527,  ..., -0.2600, -0.3710,  0.5170],\n",
            "        [ 3.5941,  0.2611, -0.4849,  ...,  1.3070, -0.6524, -1.5743],\n",
            "        [ 1.2800,  0.1809, -1.7632,  ...,  0.3908, -0.6608, -0.6181],\n",
            "        ...,\n",
            "        [-0.8630,  0.5606,  0.0703,  ...,  0.7741,  2.9910,  0.8161],\n",
            "        [ 2.6372, -0.1278, -0.8935,  ...,  1.4638, -0.8069, -0.0277],\n",
            "        [-0.0260, -0.5786, -0.0176,  ...,  1.0746,  0.2328, -0.0710]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.9242,  1.0900, -1.9217,  ...,  1.0886, -0.9271, -0.4881],\n",
            "        [ 1.5033,  0.4211, -1.1374,  ...,  0.9775,  0.5820, -0.0398],\n",
            "        [ 0.2312,  7.6530,  1.5145,  ..., -0.3841,  0.2650,  0.2169],\n",
            "        ...,\n",
            "        [ 0.5544, -0.1497, -0.4446,  ...,  0.9739,  1.2014,  0.1078],\n",
            "        [ 0.7987,  0.9694,  0.0762,  ...,  1.2789, -0.2407,  1.8176],\n",
            "        [-0.6859, -0.6369, -1.5190,  ...,  2.1996, -0.2060,  1.0326]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2700, -1.0615,  2.0278,  ..., -1.6053, -1.0838, -1.1145],\n",
            "        [-0.2093,  0.1473, -0.8374,  ..., -0.1510,  3.1160, -0.7205],\n",
            "        [-0.5959, -0.4623,  0.0810,  ..., -0.1148, -1.2100,  0.7290],\n",
            "        ...,\n",
            "        [ 0.2601,  0.0498, -1.6189,  ...,  0.9640,  0.3134,  0.0546],\n",
            "        [ 0.5255,  0.6952,  1.4389,  ..., -0.5728, -0.9458,  0.1399],\n",
            "        [-0.4982, -0.3788, -0.4868,  ...,  0.0302, -0.2623,  1.8584]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8687,  0.6209,  1.3164,  ...,  0.8718, -0.1430,  1.8379],\n",
            "        [ 2.2418,  0.7914, -0.9741,  ...,  1.5413,  0.0278, -0.3731],\n",
            "        [-0.4969, -0.1435, -0.8742,  ..., -0.1671,  0.3612,  0.9521],\n",
            "        ...,\n",
            "        [-0.7747,  0.6095, -0.5218,  ...,  0.9523, -0.6602,  4.6325],\n",
            "        [ 0.1989, -0.5590, -0.1419,  ...,  0.4783,  0.4948, -0.4821],\n",
            "        [ 0.1738,  1.2095,  0.4887,  ..., -0.3787,  0.8299, -0.1040]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6243,  0.1759, -0.6401,  ...,  0.5441,  6.8156,  0.5787],\n",
            "        [-0.2512, -1.0128, -0.0323,  ..., -1.0518, -1.3655, -1.4639],\n",
            "        [-2.0289, -0.7977, -0.5288,  ..., -1.1443, -0.6458, -0.9048],\n",
            "        ...,\n",
            "        [-0.2117, -1.1900,  0.1865,  ..., -0.9905, -0.9475, -0.6245],\n",
            "        [ 0.9501, -1.3966,  0.9281,  ..., -1.6822, -1.0414, -0.1985],\n",
            "        [-0.2583, -0.6709, -0.7214,  ..., -0.7011,  0.9180, -0.0316]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 4.3082,  0.5918, -0.7595,  ...,  1.6951, -1.3144, -0.9175],\n",
            "        [-0.5731, -0.2839, -0.7117,  ..., -0.9130, -0.1473, -1.4599],\n",
            "        [ 1.6382,  0.6729,  0.0677,  ...,  0.1698, -0.5720, -1.6504],\n",
            "        ...,\n",
            "        [-0.7459, -1.4908, -0.2380,  ...,  0.7556,  0.2153, -0.9308],\n",
            "        [-0.9952, -0.1812, -0.2523,  ..., -1.2309, -1.3370, -1.1065],\n",
            "        [ 0.7615,  5.4932,  2.3680,  ..., -0.6792,  0.3807, -0.3001]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1849,  0.9747, -0.4473,  ..., -0.0192, -0.8094, -0.1387],\n",
            "        [-0.5364, -0.9112, -0.9346,  ..., -0.9548, -1.5731, -0.1805],\n",
            "        [-0.8735,  0.3970,  0.5465,  ..., -1.6488,  0.9041, -0.6827],\n",
            "        ...,\n",
            "        [ 0.0786,  1.6002,  7.2790,  ..., -2.2668, -0.4154, -0.0527],\n",
            "        [-1.2460, -1.4879,  1.6944,  ..., -1.3638, -0.8480,  0.8865],\n",
            "        [-0.4562,  1.0877, -0.1651,  ..., -0.7335,  0.2802, -0.3467]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.6333,  0.2089,  1.0829,  ..., -0.0707,  0.0576, -0.9250],\n",
            "        [-0.4781, -0.3871,  0.0511,  ..., -1.0365,  0.4112, -0.4215],\n",
            "        [-0.4831, -1.6892, -0.1652,  ..., -1.4255, -1.2119, -0.8811],\n",
            "        ...,\n",
            "        [-0.7551,  0.3804,  1.2444,  ..., -0.2233, -0.5119,  0.6290],\n",
            "        [-0.5957, -1.3879, -0.7499,  ..., -0.0713,  0.0099, -0.1471],\n",
            "        [-0.3003, -1.4031, -0.4008,  ..., -0.8185, -1.3414,  0.0155]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5159,  0.9853,  0.2398,  ..., -0.8730,  0.3764, -0.4340],\n",
            "        [-0.9748, -1.4882,  1.2592,  ..., -1.4137, -0.7559,  0.5833],\n",
            "        [-1.1370,  0.3262,  0.2930,  ..., -0.3114,  0.3834,  1.2274],\n",
            "        ...,\n",
            "        [ 0.7697, -0.0335,  1.2222,  ...,  0.2076, -1.1619,  1.4358],\n",
            "        [ 1.6713, -0.6634,  0.5541,  ...,  0.1509, -0.7076, -0.6081],\n",
            "        [ 0.2904, -0.5236,  1.6491,  ..., -1.0361, -0.3804,  0.4003]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0619e+00, -1.4997e+00,  6.2388e-01,  ..., -3.4455e-01,\n",
            "          7.0947e-01, -5.5550e-01],\n",
            "        [-4.4416e-01, -1.4606e-01, -1.2283e+00,  ...,  1.2185e+00,\n",
            "          2.1572e+00, -8.0158e-01],\n",
            "        [ 4.7293e-01,  3.9506e-02,  9.5352e-01,  ...,  4.7536e-01,\n",
            "         -9.2884e-01,  1.2406e+00],\n",
            "        ...,\n",
            "        [ 1.3981e+00,  4.5141e-01, -1.8029e+00,  ..., -3.2979e-01,\n",
            "          3.8501e-01, -9.5109e-01],\n",
            "        [-7.3864e-01, -7.2638e-01, -8.0243e-01,  ...,  5.8980e-01,\n",
            "          1.6654e+00, -1.0228e+00],\n",
            "        [-7.9819e-02,  3.6009e-01,  1.1266e-03,  ...,  4.3435e-01,\n",
            "          1.2094e+00,  1.6292e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8128,  0.4239, -1.0020,  ...,  0.7648, -0.7149, -0.4827],\n",
            "        [ 2.0620,  0.4048,  0.5976,  ...,  0.9720,  0.0750, -0.5010],\n",
            "        [-0.1982, -0.6999,  0.2462,  ..., -1.3753, -0.2708, -0.4231],\n",
            "        ...,\n",
            "        [ 4.8018, -0.0512, -0.6202,  ...,  0.4894, -1.8393, -1.8324],\n",
            "        [-1.1242, -1.2868,  0.2964,  ...,  0.1214,  0.9386, -0.1196],\n",
            "        [-0.3286, -0.4771,  0.4041,  ..., -0.7813,  0.2250, -0.9323]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4770, -0.0535,  0.2577,  ..., -0.2181, -0.6945, -0.0168],\n",
            "        [ 0.1719,  0.4984, -0.1104,  ..., -0.9276,  0.4391, -0.3727],\n",
            "        [-0.1266, -0.8811,  1.3095,  ..., -1.3636, -0.4296, -1.6064],\n",
            "        ...,\n",
            "        [-0.6297,  0.4136, -0.2552,  ...,  0.4760,  0.6803,  0.6466],\n",
            "        [-0.8721,  0.3364,  0.3664,  ..., -0.9329, -1.1436, -1.1475],\n",
            "        [ 0.4288,  0.0398, -1.1501,  ..., -0.1027, -0.1677, -0.9531]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-7.3776e-01,  5.4687e-03, -1.7487e-01,  ...,  4.9208e-01,\n",
            "          7.0932e+00,  3.0589e-01],\n",
            "        [-4.6477e-01,  5.8561e-01,  5.0096e-01,  ..., -1.1870e+00,\n",
            "         -6.9835e-01,  1.1631e-01],\n",
            "        [-5.5652e-01, -3.2050e-01, -3.1861e-01,  ..., -1.4260e-01,\n",
            "          1.9294e-01, -8.9201e-01],\n",
            "        ...,\n",
            "        [-9.5128e-01, -1.2650e+00, -1.0771e+00,  ...,  6.4923e-01,\n",
            "          1.3002e+00,  7.3462e-01],\n",
            "        [-9.8999e-01, -1.6334e+00, -1.8354e+00,  ...,  2.3415e-01,\n",
            "          1.0788e-02, -1.2304e-01],\n",
            "        [-2.2215e-01, -8.4573e-01, -6.0375e-01,  ..., -2.6034e-01,\n",
            "         -3.1853e-01, -8.0622e-03]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 3.2872,  1.4225, -0.4261,  ...,  1.2452, -0.5824, -0.2014],\n",
            "        [ 1.0855,  0.2553, -0.4459,  ..., -0.3033, -0.2830, -1.5222],\n",
            "        [-0.1931, -0.4374, -0.1499,  ...,  0.1518, -0.8262,  0.6892],\n",
            "        ...,\n",
            "        [-0.9873, -1.3246,  0.0988,  ..., -0.0120,  2.8903,  0.7555],\n",
            "        [ 1.0039,  0.8886, -2.2036,  ..., -0.1292,  0.2139, -1.3519],\n",
            "        [-0.2023,  0.8007,  0.7886,  ..., -0.7168,  0.6937,  0.3468]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0731, -0.1604,  0.6430,  ..., -0.4042, -1.0788,  1.6521],\n",
            "        [-0.0120, -0.2848, -0.8617,  ..., -1.0082, -0.3476, -0.4269],\n",
            "        [ 0.8922,  0.6302, -1.1599,  ...,  0.9828, -1.0626, -0.6899],\n",
            "        ...,\n",
            "        [-1.1548, -1.1598, -0.8286,  ..., -0.9085, -0.4761, -1.5613],\n",
            "        [-0.3724,  0.4556,  1.3869,  ..., -0.5827, -0.5617,  0.1297],\n",
            "        [-0.3354, -0.8248, -1.0520,  ...,  2.3792,  0.5545,  1.1016]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9200, -0.6454, -0.8091,  ..., -0.1590,  1.0546,  0.3135],\n",
            "        [ 4.4698,  0.6497, -0.7677,  ...,  0.9304, -0.6331, -1.6236],\n",
            "        [ 0.3811, -0.3411, -1.3376,  ..., -0.3916, -0.7610, -0.3706],\n",
            "        ...,\n",
            "        [-0.3365, -0.6682, -0.5323,  ..., -0.3261,  0.9735,  0.0823],\n",
            "        [ 2.0851,  0.4858, -0.8325,  ...,  1.4866, -0.1956,  0.3903],\n",
            "        [-0.8331, -1.1236, -0.7278,  ..., -0.2385,  0.9003,  0.0552]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0046,  0.2492,  0.0479,  ..., -1.0448, -0.2966, -1.6363],\n",
            "        [ 0.0258,  0.4979,  0.1760,  ..., -0.8393, -0.3249,  0.2819],\n",
            "        [-0.0571, -0.2913, -0.1254,  ..., -0.6150, -0.7390,  0.1318],\n",
            "        ...,\n",
            "        [ 0.0367, -0.3838, -0.6004,  ...,  0.6205, -1.3215,  0.4698],\n",
            "        [-0.9041, -0.7035, -0.3828,  ..., -0.6170,  0.8472,  0.0974],\n",
            "        [-0.8757,  0.1859, -0.0836,  ..., -1.0638, -0.3307, -0.9490]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5652, -0.1443, -0.9579,  ...,  1.8933, -0.6671, -0.0657],\n",
            "        [-0.7518, -0.0314, -0.4306,  ...,  0.3882,  7.0095,  0.4887],\n",
            "        [ 0.0170,  0.1604, -0.2515,  ...,  1.1665,  2.3103,  0.4887],\n",
            "        ...,\n",
            "        [-0.8188, -0.0977,  0.1321,  ...,  0.6405,  2.7630, -0.1648],\n",
            "        [-0.2164,  0.1496, -0.4310,  ...,  0.8115,  0.0638, -0.2137],\n",
            "        [-0.5861, -0.4631, -1.1771,  ...,  1.8951, -0.1481,  0.8467]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.5480,  0.4727, -0.5835,  ...,  0.7823,  0.5924, -0.3606],\n",
            "        [-0.2885,  0.8089,  0.4826,  ..., -0.7496,  0.0649, -1.1469],\n",
            "        [ 0.1891,  1.1886,  0.3522,  ...,  0.5142,  1.1536,  0.4074],\n",
            "        ...,\n",
            "        [-1.3535,  0.1459, -0.2049,  ..., -1.0870, -0.5012, -1.6783],\n",
            "        [ 1.2008, -0.7466,  1.6479,  ..., -1.1810, -1.0087, -0.9730],\n",
            "        [ 1.0460, -0.5313, -0.1695,  ...,  0.7747,  0.1953,  0.0224]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2721, -0.5690,  0.3435,  ...,  0.0964, -0.6856, -0.0115],\n",
            "        [-0.8654, -0.6458, -1.4216,  ...,  1.6267,  1.0255,  1.1432],\n",
            "        [-0.8226, -0.9824, -0.7918,  ..., -0.7980, -1.6290, -0.9956],\n",
            "        ...,\n",
            "        [ 0.6704,  1.6418,  0.5145,  ...,  0.1832, -0.3047, -0.0047],\n",
            "        [ 2.7931,  0.8647,  1.2938,  ...,  0.0712, -1.9679, -0.5435],\n",
            "        [ 0.3672,  0.8542, -0.4880,  ...,  0.5154,  0.3588,  1.1075]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.0128e+00,  4.1842e-01, -2.1765e+00,  ...,  2.1722e+00,\n",
            "          1.2756e-01, -9.1711e-01],\n",
            "        [-1.9213e-01, -9.0474e-01,  2.4394e+00,  ..., -1.6167e+00,\n",
            "         -1.4801e+00, -1.6777e-01],\n",
            "        [ 7.6591e-01, -1.3110e+00, -1.7414e+00,  ...,  2.2871e+00,\n",
            "         -9.5995e-01, -4.6064e-01],\n",
            "        ...,\n",
            "        [ 3.9528e+00,  9.5523e-01, -3.7498e-01,  ...,  5.9687e-03,\n",
            "         -9.0115e-01, -1.3122e+00],\n",
            "        [ 2.6610e-01, -4.2552e-01, -3.2849e-01,  ..., -7.7214e-01,\n",
            "         -1.2410e+00, -1.0743e+00],\n",
            "        [ 2.5051e-01,  7.4113e+00,  1.8291e+00,  ..., -1.5022e-01,\n",
            "          4.5573e-01, -1.8245e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4307, -0.7622, -1.5280,  ...,  2.4254,  0.7909,  1.2367],\n",
            "        [-0.4421, -0.6378, -0.4176,  ..., -0.6900,  0.2678, -1.8882],\n",
            "        [ 1.9799,  3.2090, -0.1626,  ...,  0.5977, -0.1321, -0.2866],\n",
            "        ...,\n",
            "        [ 0.9384, -0.7926, -0.4760,  ...,  0.3759, -1.1388, -0.1082],\n",
            "        [-0.3724,  0.0360, -0.3592,  ..., -0.3852, -0.2996,  0.6665],\n",
            "        [-1.1066,  0.1038,  1.3790,  ..., -0.1560, -0.3353,  1.0051]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5894, -0.3853,  0.4635,  ..., -0.3990, -0.0594, -0.5927],\n",
            "        [ 0.1551,  0.9902,  1.4567,  ...,  0.0895, -0.5737,  0.8062],\n",
            "        [-1.0625, -1.7361, -0.1653,  ..., -0.1057,  0.5811, -0.7265],\n",
            "        ...,\n",
            "        [-0.3398, -0.7672, -0.4450,  ...,  0.2252, -0.1191,  0.9108],\n",
            "        [ 3.2151,  1.2710,  1.1146,  ...,  0.7100, -1.3355, -0.2722],\n",
            "        [-0.4839, -0.3825, -0.2934,  ..., -0.5175, -0.9169,  0.0797]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.5312, -0.3538, -0.6614,  ..., -0.5287, -1.2102, -0.3994],\n",
            "        [ 2.1679,  0.6570, -1.8122,  ...,  2.3958,  0.4741, -0.9308],\n",
            "        [-1.0809,  0.9826,  0.2825,  ..., -0.2753,  0.4240,  1.0061],\n",
            "        ...,\n",
            "        [ 0.4372, -0.7862,  2.6705,  ..., -1.4545, -0.6161, -0.1385],\n",
            "        [ 0.4625,  0.8955, -0.3321,  ...,  0.5059,  0.5361,  0.7737],\n",
            "        [ 1.3799, -0.2922, -1.1302,  ...,  0.0553, -1.8110, -0.4783]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.5917,  1.3012, -0.1430,  ...,  2.1955, -1.1760,  1.5812],\n",
            "        [-1.0948, -0.7505,  0.0927,  ...,  0.2588,  2.1627,  1.7396],\n",
            "        [-0.0208, -1.4310, -1.2688,  ..., -0.3095,  1.0078, -0.7687],\n",
            "        ...,\n",
            "        [ 0.6701,  0.1507, -0.8210,  ..., -1.4990, -0.9985, -0.1895],\n",
            "        [-0.4640, -0.2899, -0.4665,  ..., -1.3209, -0.0646, -0.8345],\n",
            "        [ 0.3598,  0.9576, -0.3222,  ...,  0.3482, -0.5016, -0.5789]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.4249,  0.1732,  0.5672,  ...,  0.8699, -0.9766,  0.6104],\n",
            "        [ 1.2821, -0.0374,  0.5209,  ..., -0.2594, -1.0388, -0.1952],\n",
            "        [-0.2076, -0.6165,  0.5063,  ...,  0.2411, -0.8260, -1.0471],\n",
            "        ...,\n",
            "        [ 0.1974,  0.7608, -0.3095,  ...,  0.1052,  0.3887,  1.7181],\n",
            "        [ 0.2149,  0.7091,  0.2945,  ...,  0.7775,  1.4892,  0.6908],\n",
            "        [-0.7439, -0.6786,  0.5492,  ...,  0.0352, -0.6929,  1.1266]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 4.7199,  1.2811, -0.2478,  ...,  0.3719, -0.8974, -1.9098],\n",
            "        [ 0.1550,  1.9373,  2.2798,  ..., -0.6846, -0.3700,  0.6379],\n",
            "        [ 0.3341, -0.5176, -0.7844,  ...,  0.9612,  0.4115, -0.3720],\n",
            "        ...,\n",
            "        [-0.6394, -0.2561, -0.7037,  ..., -0.1492,  1.1804,  0.4378],\n",
            "        [-0.5386, -0.1257,  0.0452,  ..., -0.2626,  1.3562, -0.2634],\n",
            "        [ 3.5362,  0.6498,  1.7590,  ...,  0.3103, -1.7160, -0.3373]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 2.6084, -0.1076,  0.3372,  ...,  0.2155, -0.8325, -1.0216],\n",
            "        [-0.5911, -0.7142,  0.4207,  ..., -0.3872, -0.6320,  1.0155],\n",
            "        [ 0.1325,  0.2683, -0.5584,  ..., -1.0610, -0.6212, -0.3694],\n",
            "        ...,\n",
            "        [ 0.0112,  0.4666,  1.2547,  ..., -0.3788, -0.9590,  0.4121],\n",
            "        [ 0.8113,  7.3814,  2.4414,  ...,  0.1494,  0.6783,  0.6418],\n",
            "        [-0.5331, -0.3842, -0.4861,  ...,  1.7153, -0.4983,  1.0627]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7734, -1.4723, -1.8771,  ..., -0.1233, -0.1025, -0.0453],\n",
            "        [-0.7116, -1.0236,  1.3491,  ..., -1.2083, -0.7041, -0.0567],\n",
            "        [ 1.8391, -0.4691, -1.5096,  ...,  0.2363, -1.5951, -1.1158],\n",
            "        ...,\n",
            "        [ 3.5021,  0.3303,  0.4744,  ...,  0.1403, -1.7362, -1.3217],\n",
            "        [-1.0058, -1.1785, -0.9098,  ..., -0.1208,  0.8555,  0.7764],\n",
            "        [-0.2285,  0.4435,  1.7575,  ..., -0.9439, -1.0067,  0.2370]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0377, -1.2206, -0.5674,  ..., -0.9946,  0.4584, -0.4685],\n",
            "        [-0.8250, -0.1767, -0.0936,  ..., -0.5850,  0.8346, -0.8891],\n",
            "        [ 1.0458, -0.6605, -1.5415,  ...,  0.8479, -0.9500, -1.1170],\n",
            "        ...,\n",
            "        [-1.0227, -0.1961,  0.1418,  ..., -0.8029,  1.0771, -0.7324],\n",
            "        [-0.6438,  0.4440, -0.4641,  ...,  0.9435,  0.9232,  1.9220],\n",
            "        [ 0.7938,  0.1656,  0.8983,  ...,  0.7270, -0.1115, -1.1955]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,760  of  2,811.    Elapsed: 1:12:35.\n",
            "logits :  tensor([[-0.6328, -1.0376, -0.8996,  ..., -1.0847, -1.1956, -0.8703],\n",
            "        [-0.5257, -0.2521,  0.2380,  ...,  0.6058, -0.3872,  1.2257],\n",
            "        [-0.4352,  1.1496,  0.0093,  ...,  0.5585,  0.8072,  0.8799],\n",
            "        ...,\n",
            "        [ 2.1801,  0.7135, -1.0078,  ...,  0.3573,  0.7753, -0.7537],\n",
            "        [-0.8158, -1.6914, -0.9827,  ...,  0.2638,  1.4986,  0.7774],\n",
            "        [ 2.2950,  1.2277, -1.1500,  ...,  1.8799, -0.3055, -0.6618]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0991, -0.5557, -0.4593,  ..., -1.0124, -1.1319, -1.4125],\n",
            "        [-0.7630, -0.7747, -0.5839,  ...,  0.7398,  2.8054,  0.1443],\n",
            "        [ 0.9071, -0.1308,  1.5239,  ..., -1.4033, -1.0041,  0.3038],\n",
            "        ...,\n",
            "        [-0.6040, -1.6096, -0.0988,  ...,  0.4802,  0.2179, -0.4129],\n",
            "        [-1.0088, -1.4261, -0.2152,  ...,  0.2817,  2.6330,  1.7350],\n",
            "        [-0.2757,  0.0818,  3.6646,  ..., -1.5366,  0.0764, -0.6877]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8712, -0.3863, -0.5551,  ..., -0.5313,  3.4261, -0.1464],\n",
            "        [ 0.3741, -0.2146,  0.0289,  ..., -0.9365, -0.3749, -0.6185],\n",
            "        [ 1.1152, -0.2370, -1.2567,  ...,  1.9625, -1.2571, -0.0814],\n",
            "        ...,\n",
            "        [-0.7133,  0.6478,  0.7501,  ..., -1.1983,  1.1834, -0.1679],\n",
            "        [-0.9251, -0.7779, -0.7388,  ..., -0.3982,  0.6977,  0.3008],\n",
            "        [-0.9363,  0.2324,  0.5949,  ..., -1.7219, -0.7580, -1.3893]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4739,  0.1643,  1.0617,  ...,  0.0385,  1.6695,  1.1772],\n",
            "        [ 0.4257,  0.5257, -0.1694,  ..., -0.4979,  1.9384, -0.2711],\n",
            "        [-1.0590, -0.1078, -0.1452,  ..., -0.8348, -0.0487, -1.4045],\n",
            "        ...,\n",
            "        [-0.5121, -0.6210,  0.7367,  ..., -0.8199,  0.3497, -0.5288],\n",
            "        [-1.1297,  0.2031, -0.0309,  ..., -1.0979, -1.0604, -1.2372],\n",
            "        [ 1.4507,  0.3457, -1.7372,  ...,  1.2204,  0.2117, -0.6605]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.1438,  0.2153,  0.2789,  ..., -1.2358, -0.2712, -0.1013],\n",
            "        [-0.1955,  3.1531,  1.0121,  ..., -0.8487,  0.5261, -0.4769],\n",
            "        [-0.1968, -0.3721, -1.6866,  ...,  2.8625, -0.6495,  1.6441],\n",
            "        ...,\n",
            "        [-0.5684, -0.3183, -0.2256,  ..., -0.3829, -0.2337, -0.4480],\n",
            "        [-1.1598, -1.4496,  1.4659,  ..., -1.4963, -0.6424,  0.4439],\n",
            "        [-0.2154,  0.6814,  0.4659,  ...,  1.0351, -0.7037,  5.8262]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1647, -0.6301, -0.8534,  ..., -0.5204, -0.7796, -0.7582],\n",
            "        [ 0.4547, -1.2339,  0.5944,  ..., -1.1871, -0.6810,  0.2732],\n",
            "        [-1.0091, -1.3249, -0.6505,  ..., -0.1005,  1.1736, -0.8048],\n",
            "        ...,\n",
            "        [-1.0755, -0.3393,  0.2366,  ..., -0.0097,  0.0726, -0.9786],\n",
            "        [-0.4646, -0.5175, -0.7408,  ...,  0.6885,  3.2604, -1.0090],\n",
            "        [-0.7658, -0.0639,  1.4957,  ..., -0.2621, -0.5911,  0.8986]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9497,  0.1475, -0.2379,  ..., -1.1263, -0.5302, -1.2649],\n",
            "        [ 1.2725,  0.2019,  0.4676,  ...,  0.4831, -0.6796,  0.6261],\n",
            "        [-0.1207, -1.1177,  1.7030,  ..., -1.0749, -1.5099,  0.1696],\n",
            "        ...,\n",
            "        [ 2.2072,  0.6377, -1.3514,  ...,  1.0257,  0.4599, -0.9097],\n",
            "        [-0.7379, -0.8017, -1.2917,  ..., -1.1704, -1.0592, -1.1391],\n",
            "        [ 1.8422,  0.3401,  1.4241,  ..., -0.4844, -1.2801, -0.7573]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5432,  1.0703, -0.2937,  ..., -0.3503,  0.1712, -0.1834],\n",
            "        [-0.4630, -0.3613, -1.1477,  ...,  1.8567,  0.1058,  1.1329],\n",
            "        [-1.2037, -1.4836,  1.1365,  ..., -1.1210, -0.3500,  0.9006],\n",
            "        ...,\n",
            "        [ 1.6235,  1.6426,  0.4954,  ..., -0.0061,  0.3545, -1.2665],\n",
            "        [-0.4166,  0.0770, -0.0219,  ...,  0.0349,  0.1169, -0.0784],\n",
            "        [-0.1495, -0.1653, -0.8395,  ...,  0.9891, -0.5381, -0.2391]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.0264,  0.2306,  0.7891,  ..., -0.9508, -0.6936, -0.1564],\n",
            "        [-0.8201, -0.6485, -0.6843,  ...,  0.9664, -0.7529, -0.4367],\n",
            "        [ 0.7662, -0.2962, -1.9289,  ...,  6.3676, -0.8219,  1.0763],\n",
            "        ...,\n",
            "        [-0.4215, -0.3161,  0.0833,  ..., -0.8482, -0.8834, -1.8780],\n",
            "        [-0.9094, -1.1866, -0.5313,  ..., -0.4115, -1.0325,  0.8491],\n",
            "        [-0.3845, -1.1357, -0.1365,  ..., -1.0757, -1.3016, -1.5075]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6648, -1.0228, -0.3661,  ..., -0.5227, -0.5932, -0.2113],\n",
            "        [-0.4529,  0.0268,  0.0761,  ...,  0.3161,  5.6185,  0.2960],\n",
            "        [ 3.6700,  0.7349,  1.7231,  ...,  0.0421, -0.6336, -1.5408],\n",
            "        ...,\n",
            "        [-0.3927, -1.4313, -0.1422,  ..., -0.1355,  0.4892, -1.0980],\n",
            "        [-0.3679, -0.6463,  0.4290,  ..., -0.5687, -0.3364, -1.1512],\n",
            "        [ 0.7880, -0.5600,  2.0992,  ..., -0.0233, -0.7401, -0.9477]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0978, -0.1899, -0.6297,  ..., -0.3358, -0.3329, -0.3133],\n",
            "        [ 1.6267,  0.7493, -0.9227,  ...,  0.6888, -0.3102, -1.4714],\n",
            "        [ 1.5810,  0.0794, -0.5986,  ...,  1.2528,  1.1193, -0.6785],\n",
            "        ...,\n",
            "        [-0.3450, -0.4924, -0.4035,  ..., -0.6944,  0.2981,  0.0327],\n",
            "        [ 0.8882, -0.8692,  1.6420,  ...,  0.0395, -0.8639, -0.5038],\n",
            "        [-0.2218,  0.0192, -0.4334,  ..., -0.2728, -0.1258,  0.9774]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 4.5282e+00,  4.3902e-01, -7.0265e-01,  ...,  1.8422e+00,\n",
            "         -3.3171e-01, -1.2541e+00],\n",
            "        [-1.8810e-01, -5.3018e-01,  2.5766e-01,  ..., -8.4299e-01,\n",
            "         -4.2879e-01, -6.6390e-01],\n",
            "        [ 2.8270e-01, -1.6680e-01, -6.8688e-01,  ..., -7.2523e-01,\n",
            "         -7.0872e-01, -8.4476e-01],\n",
            "        ...,\n",
            "        [ 3.1923e-01,  4.2685e-01,  2.5403e-01,  ..., -9.5355e-01,\n",
            "         -6.0107e-02, -3.1672e-01],\n",
            "        [-7.8353e-01, -3.3347e-01, -7.3388e-02,  ..., -6.3058e-01,\n",
            "          8.8755e-01, -7.8087e-01],\n",
            "        [ 2.1365e-01, -1.5863e-03,  1.4403e-02,  ...,  8.0055e-01,\n",
            "         -1.4356e-01,  1.8092e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2063, -0.0604, -0.5604,  ...,  1.3940, -0.6110,  0.4996],\n",
            "        [ 0.3660,  7.2386,  1.8269,  ..., -0.1849,  0.2309,  0.3305],\n",
            "        [ 2.1378, -0.7977,  0.3407,  ..., -0.3436, -0.9024, -1.1182],\n",
            "        ...,\n",
            "        [-0.4757,  0.1428, -0.2933,  ...,  0.4499,  1.2283,  0.1209],\n",
            "        [ 0.2956,  7.9599,  1.7764,  ...,  0.0983,  0.3015,  0.6018],\n",
            "        [-0.3454, -0.9185, -0.2474,  ..., -0.7733,  2.0909, -0.0131]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.4121, -0.0328,  0.4995,  ..., -1.3656, -0.0623, -0.4433],\n",
            "        [ 0.4027, -0.1027, -2.2843,  ...,  1.9992,  1.6668, -0.3321],\n",
            "        [ 1.1959, -0.3324, -0.4513,  ...,  0.7857, -0.1598,  0.5048],\n",
            "        ...,\n",
            "        [-0.7533, -0.3617, -0.3231,  ..., -0.5633, -0.1082,  0.5234],\n",
            "        [ 1.3726, -0.1306, -1.2239,  ..., -0.2586, -1.3166,  0.1321],\n",
            "        [-0.1973, -1.5004,  0.5199,  ..., -1.2010, -1.3249, -0.8508]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8559, -0.5977,  0.2016,  ..., -0.8197,  1.4419, -0.1539],\n",
            "        [ 0.7340,  1.8861,  1.1880,  ...,  0.0399, -0.3812,  0.5430],\n",
            "        [-0.5581, -0.9502,  0.3952,  ...,  0.3825,  1.7720,  1.3010],\n",
            "        ...,\n",
            "        [-0.9558, -0.2959,  1.1171,  ...,  0.4095, -0.4660,  0.5035],\n",
            "        [-0.3608, -0.2757,  0.0168,  ..., -0.8588, -0.2504, -0.3029],\n",
            "        [ 0.0068, -0.8026,  0.6433,  ..., -0.5733, -0.2150,  0.2071]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.2780,  0.9043,  0.2858,  ...,  0.9984, -0.7853, -0.9007],\n",
            "        [-0.4929,  0.5121, -0.4163,  ...,  0.4461, -0.3575,  0.1610],\n",
            "        [-0.2158,  0.8830,  0.1699,  ..., -0.5802,  1.7862,  0.5535],\n",
            "        ...,\n",
            "        [-1.2291,  1.0109,  1.1102,  ...,  1.1598, -0.4474,  2.1900],\n",
            "        [ 0.0783, -1.8142,  0.0328,  ..., -1.1033, -1.1123, -0.5534],\n",
            "        [-0.6457, -0.6393, -1.6285,  ...,  3.6069,  0.9458,  3.2587]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2802, -0.2443, -1.2905,  ...,  3.6820, -0.8054,  0.3196],\n",
            "        [-0.4709,  3.3846, -0.1556,  ..., -0.1094,  0.1990, -0.3134],\n",
            "        [-1.3068, -0.3432, -0.1286,  ..., -1.2670, -0.9545, -1.5343],\n",
            "        ...,\n",
            "        [ 2.3350,  0.6194, -0.0956,  ..., -0.0461, -1.3934, -0.8974],\n",
            "        [ 1.3953,  0.8037, -1.1680,  ...,  0.7859,  0.6579, -0.7705],\n",
            "        [ 0.9463, -1.0024, -1.3170,  ..., -0.7856, -1.5744, -1.0576]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3765,  1.3239,  7.3357,  ..., -2.0260, -0.5325, -0.1091],\n",
            "        [ 0.4718,  0.0255, -0.1992,  ..., -0.7423,  0.0771, -0.1970],\n",
            "        [ 2.2179,  0.3197, -2.1543,  ...,  2.0167,  0.4455, -1.3949],\n",
            "        ...,\n",
            "        [ 0.1886, -0.7327, -1.0753,  ..., -0.1239, -1.3236, -1.0443],\n",
            "        [-0.2572, -1.4966, -0.0207,  ..., -1.4655, -0.6780, -0.6059],\n",
            "        [ 2.2736,  0.2734,  0.6288,  ...,  0.4516, -1.4953, -0.3345]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.0682,  0.1508,  1.8908,  ..., -1.3365, -0.6607,  0.0628],\n",
            "        [-1.4243, -0.9243, -0.1623,  ..., -1.1374,  0.2222, -0.9522],\n",
            "        [ 0.1135,  0.2191,  0.1677,  ..., -1.6401, -0.6806, -0.4973],\n",
            "        ...,\n",
            "        [-1.3676, -1.0909, -0.9964,  ..., -0.3798,  1.1542,  0.8142],\n",
            "        [ 0.3505, -0.8215, -0.5649,  ..., -1.1956, -0.6662, -0.0265],\n",
            "        [-0.3983, -0.3725,  0.2918,  ..., -0.7797, -0.8607,  0.0984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-8.9887e-01, -6.0508e-01, -1.1386e+00,  ..., -1.2667e-01,\n",
            "          7.7999e-01,  1.9691e-02],\n",
            "        [-3.8641e-01, -5.1236e-01, -8.1620e-01,  ..., -3.2711e-01,\n",
            "          9.7633e-01, -7.2661e-01],\n",
            "        [-6.1740e-01, -3.0621e-01, -1.3148e-01,  ..., -1.1510e+00,\n",
            "          1.1756e-03, -7.3933e-01],\n",
            "        ...,\n",
            "        [ 4.2722e-01, -1.4830e+00,  5.7470e-02,  ..., -1.9343e+00,\n",
            "         -1.9666e+00, -1.2980e+00],\n",
            "        [-7.0098e-01, -6.7972e-01,  1.5740e+00,  ..., -1.1570e+00,\n",
            "         -6.1987e-01, -8.1279e-02],\n",
            "        [-1.0101e+00,  3.3251e-01,  1.3396e-01,  ...,  7.5394e-02,\n",
            "          6.9885e-01,  9.8766e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.9965, -0.3669, -0.0523,  ...,  0.2786, -0.4461, -0.1659],\n",
            "        [-0.9833, -0.3194, -0.4977,  ..., -0.6878,  1.5136, -0.6821],\n",
            "        [-0.9489, -1.8631, -1.9749,  ..., -0.0689,  0.0155, -0.4840],\n",
            "        ...,\n",
            "        [ 0.1851, -0.4641, -0.7819,  ..., -0.4623, -0.7569, -0.3549],\n",
            "        [-0.6779, -0.1260, -0.8521,  ..., -0.0185, -0.0404,  0.8842],\n",
            "        [-0.3182, -0.9096, -0.2310,  ..., -0.3600, -0.1716, -0.4132]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 5.7521e+00,  5.3627e-01, -1.0677e+00,  ...,  7.7637e-01,\n",
            "         -1.4291e+00, -1.9644e+00],\n",
            "        [ 7.2245e-02,  3.4404e-01, -5.0758e-03,  ..., -8.8712e-01,\n",
            "          3.0394e-01, -1.0365e-01],\n",
            "        [-2.9625e-02, -3.9594e-01, -2.3267e+00,  ...,  2.8228e+00,\n",
            "         -5.2189e-01,  1.5502e-01],\n",
            "        ...,\n",
            "        [-1.7917e-01, -2.0313e-01,  8.3695e-01,  ..., -4.8054e-01,\n",
            "         -4.2772e-01, -3.5388e-01],\n",
            "        [ 2.8936e-01, -2.7913e-02, -6.7716e-01,  ..., -7.4507e-01,\n",
            "          2.7262e-01, -3.1047e-01],\n",
            "        [-8.2947e-01, -1.4077e+00, -2.1499e+00,  ..., -6.0610e-01,\n",
            "         -7.2654e-01, -1.6199e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.7241, -0.9650, -0.4323,  ..., -0.3602, -0.3738, -1.4512],\n",
            "        [-0.2979, -0.3600, -0.2417,  ..., -0.5627, -1.1904, -1.6371],\n",
            "        [ 1.4523,  0.1093,  2.0338,  ..., -0.8295, -0.4317, -0.4391],\n",
            "        ...,\n",
            "        [-0.5713, -0.4080, -1.2837,  ...,  1.9018, -0.0803,  1.8185],\n",
            "        [-0.3796, -0.1630, -0.0738,  ..., -0.1609,  0.3656, -0.4801],\n",
            "        [-0.2414,  0.9517, -0.4676,  ..., -0.5584,  0.6164, -0.4175]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.0259, -1.1856,  0.1171,  ..., -0.1842,  0.0699, -0.6956],\n",
            "        [-0.4697, -0.2965, -0.5800,  ...,  0.4408, -0.9269,  2.6720],\n",
            "        [ 1.2537, -0.3910, -0.6279,  ..., -0.0864, -1.7486, -0.3991],\n",
            "        ...,\n",
            "        [-0.9660, -0.7515, -0.4244,  ...,  0.9233,  3.0039,  4.0853],\n",
            "        [-0.5142, -0.8200,  0.2117,  ...,  0.7385,  1.6181,  0.7254],\n",
            "        [-0.5134, -0.1857, -0.0409,  ...,  0.0200, -0.5819, -0.6000]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1878,  0.3109,  0.1897,  ..., -0.9237,  0.2775, -0.0951],\n",
            "        [-0.0378,  0.7202,  5.3210,  ..., -1.9133, -0.0410, -0.4452],\n",
            "        [-0.6353,  0.1424,  0.1457,  ...,  0.1067, -0.2372, -0.3882],\n",
            "        ...,\n",
            "        [-0.1953, -0.8355, -0.4810,  ..., -0.6221,  0.9434, -0.0449],\n",
            "        [-0.6264,  0.6557,  0.8741,  ..., -1.1911,  0.4626, -0.3945],\n",
            "        [-0.6317, -0.7683, -0.7896,  ..., -0.5014,  0.1037,  0.8022]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3777,  0.6235,  0.5475,  ..., -1.1670, -0.1255,  0.0479],\n",
            "        [-1.0204, -1.5003, -1.8711,  ...,  0.1940, -0.0209,  0.0304],\n",
            "        [-0.4862,  0.0074, -0.5625,  ..., -0.2315, -0.1622,  1.0849],\n",
            "        ...,\n",
            "        [-0.4451,  0.5736,  0.6237,  ..., -0.3388,  1.0233,  0.5254],\n",
            "        [-0.3181,  0.7462, -0.1226,  ...,  0.6205,  1.8528,  0.7247],\n",
            "        [ 2.8574,  1.1272, -1.0775,  ...,  1.7212, -0.4657, -0.9873]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8629, -0.4616, -1.3294,  ...,  2.1326,  0.2973,  1.5310],\n",
            "        [-0.8755, -0.1235, -0.0316,  ...,  0.3879,  1.0529,  0.9794],\n",
            "        [-0.0734, -1.0414, -1.3956,  ..., -0.4640, -1.1251, -0.2541],\n",
            "        ...,\n",
            "        [-0.8380,  0.6473,  0.0199,  ...,  0.0919,  0.9942,  1.5300],\n",
            "        [-0.2616, -0.6971, -1.2677,  ...,  0.1632,  0.9227, -0.5485],\n",
            "        [-1.2807, -0.8873,  0.3992,  ..., -0.7802,  0.7260, -0.8639]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.2558, -1.8021, -1.6159,  ...,  0.1179, -0.0107, -0.3284],\n",
            "        [-0.4376, -0.9512, -1.3447,  ...,  0.4023, -0.9777, -0.4359],\n",
            "        [-0.0862,  0.5940,  0.1427,  ...,  0.2644,  0.7148,  0.1734],\n",
            "        ...,\n",
            "        [ 2.2084,  0.9110,  0.0335,  ..., -0.5338, -0.6836, -1.8158],\n",
            "        [-1.1378,  0.4380,  0.4550,  ...,  1.0426,  2.6023,  5.3139],\n",
            "        [-0.3940,  0.1108, -0.5311,  ..., -0.1625, -0.2865,  1.1525]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.5512, -0.4884,  1.0533,  ...,  0.2514, -0.8665, -0.7112],\n",
            "        [-0.5228, -0.3378,  0.3729,  ..., -0.7312, -0.0955, -0.5632],\n",
            "        [ 1.5539, -0.1277, -0.1962,  ...,  1.0382, -0.8408,  0.4097],\n",
            "        ...,\n",
            "        [-0.1508,  1.2482,  0.1733,  ...,  0.0639, -0.8773,  0.4713],\n",
            "        [-0.8880, -0.3015, -0.0966,  ..., -0.1047,  1.7586, -0.1407],\n",
            "        [ 0.8379, -0.5131,  1.5291,  ...,  0.0665, -0.7017, -0.8355]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-1.1833, -0.8417, -0.2910,  ..., -0.1536,  0.8912,  0.4566],\n",
            "        [ 1.8471,  0.0273, -0.8752,  ...,  0.3169, -0.3955, -0.8296],\n",
            "        [-1.0585, -0.0660,  0.0777,  ..., -0.3443,  0.9038, -0.6672],\n",
            "        ...,\n",
            "        [ 0.5461,  0.2799, -2.3073,  ...,  1.6495,  0.0921,  0.1840],\n",
            "        [-0.1289, -0.2461, -0.3633,  ...,  1.0452, -0.1071, -0.1930],\n",
            "        [-0.3386,  1.1163, -0.2216,  ..., -0.1234, -0.3924,  0.8519]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.9742,  0.3895,  0.9878,  ..., -1.4462,  0.4025, -0.4510],\n",
            "        [-0.7424, -0.0737,  0.2873,  ..., -0.3450,  1.8290, -0.5503],\n",
            "        [-0.3634,  1.1924,  0.1444,  ..., -1.2760,  1.4716,  0.1414],\n",
            "        ...,\n",
            "        [-0.6701, -0.9000,  0.0605,  ..., -0.5292, -0.7481,  0.3262],\n",
            "        [ 0.0641, -0.4536, -0.8755,  ..., -0.7206, -0.7447, -0.7064],\n",
            "        [-0.4745,  0.5305,  0.4607,  ..., -1.2039,  0.4933, -0.3872]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.1268e+00,  5.3623e-01,  5.8750e-04,  ...,  1.2569e+00,\n",
            "         -8.0505e-01,  1.2887e+00],\n",
            "        [ 1.4070e+00, -5.0208e-01, -1.0375e+00,  ..., -4.7765e-01,\n",
            "         -8.0174e-01, -1.2584e+00],\n",
            "        [ 3.4683e-01,  1.0395e+00, -2.2723e-01,  ...,  5.6989e-01,\n",
            "          8.6304e-01,  9.9423e-01],\n",
            "        ...,\n",
            "        [-3.3598e-01, -9.7226e-01,  9.1933e-01,  ..., -6.9164e-01,\n",
            "          2.1997e+00, -6.0392e-01],\n",
            "        [-2.5549e-01, -6.4844e-01, -5.5973e-01,  ..., -3.7496e-01,\n",
            "          2.2815e-01, -2.1238e-01],\n",
            "        [-9.6796e-01, -1.7619e-01, -1.5535e-01,  ..., -1.1269e+00,\n",
            "         -8.0372e-01, -1.5906e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6598,  0.1599,  0.7197,  ..., -0.0393, -0.4518, -1.1751],\n",
            "        [ 0.0781,  0.0887, -0.0153,  ..., -0.6831, -1.6508, -0.9730],\n",
            "        [ 4.4403,  0.7151, -0.4060,  ...,  0.6802, -0.6468, -1.1892],\n",
            "        ...,\n",
            "        [-0.5157, -0.7832, -1.2650,  ...,  1.3440, -0.6311,  0.9963],\n",
            "        [ 1.4444, -0.6818,  0.6453,  ...,  0.2071, -0.5754, -0.6188],\n",
            "        [-0.3700, -0.0137, -0.4968,  ...,  0.2849,  0.2341, -0.1062]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 1.5827,  0.9141,  0.1717,  ...,  1.3485, -0.6562,  0.6674],\n",
            "        [ 0.1507,  1.4081,  6.6448,  ..., -2.2820,  0.3983, -0.0902],\n",
            "        [ 1.1375,  1.1385,  0.0138,  ...,  2.1772, -0.5446,  0.3969],\n",
            "        ...,\n",
            "        [ 1.2704,  0.2776, -1.4832,  ...,  1.9225, -0.1588, -0.8079],\n",
            "        [-1.2715,  0.1412,  0.0371,  ..., -1.5161, -0.4913, -1.7129],\n",
            "        [-1.1337, -0.2979,  0.7824,  ...,  0.6692, -0.1474, -0.1580]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.2075, -0.7263, -0.6188,  ..., -0.9227,  0.3196, -0.0958],\n",
            "        [-0.5918, -1.2180, -0.2317,  ..., -0.3039,  0.4554, -0.6738],\n",
            "        [ 0.0261, -0.7550,  0.5437,  ..., -0.7384, -1.0891,  0.3939],\n",
            "        ...,\n",
            "        [ 0.0270, -0.0837, -1.3058,  ...,  0.3902,  0.1283, -1.5012],\n",
            "        [-0.3736, -0.2570, -0.3561,  ...,  0.0077,  0.0219, -0.2501],\n",
            "        [-0.0882,  0.0214, -0.7585,  ..., -0.6959, -0.3282,  0.3074]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.3358,  2.1557,  0.6789,  ..., -0.0188, -0.1170,  0.5874],\n",
            "        [-1.1695, -0.2270, -0.0999,  ..., -0.1058,  0.1209, -1.0474],\n",
            "        [-0.2798, -0.4534, -0.0391,  ..., -0.4515,  0.2257, -0.6947],\n",
            "        ...,\n",
            "        [-0.4837, -0.7488, -0.1010,  ..., -0.3667, -0.5048, -0.1858],\n",
            "        [-1.0299, -0.8481, -0.1321,  ..., -0.9408, -1.2837, -0.8287],\n",
            "        [-0.7089,  0.4701, -0.1095,  ...,  1.6963,  2.6387,  1.3053]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.1584, -0.1468, -1.3683,  ...,  1.8760, -0.2710,  0.3471],\n",
            "        [-0.3510,  0.1188, -0.1094,  ..., -0.1142, -0.3230, -0.1683],\n",
            "        [-0.7337, -0.2398, -1.5329,  ...,  2.6726, -0.0298,  1.3140],\n",
            "        ...,\n",
            "        [-0.3506, -0.1101, -1.6189,  ..., -0.5677, -1.2687, -0.8443],\n",
            "        [-0.6712,  0.1289,  0.5089,  ...,  1.0632,  2.6516,  0.1655],\n",
            "        [-0.2848,  0.0657,  1.6969,  ..., -0.5075, -0.6564, -0.2141]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.4295, -0.5655, -0.2830,  ..., -0.5528,  0.1317, -0.8602],\n",
            "        [-1.0587,  0.2523,  3.2025,  ..., -1.6242, -1.0244,  0.2772],\n",
            "        [-0.9883, -0.4003, -0.1454,  ..., -0.6381, -0.2142, -0.5326],\n",
            "        ...,\n",
            "        [-0.8631, -0.4984, -0.3592,  ..., -0.2237,  1.0462,  0.8951],\n",
            "        [ 0.2999, -0.6142,  3.6102,  ..., -1.2242, -1.6867,  0.0270],\n",
            "        [-1.5377,  0.6361,  0.0520,  ...,  0.8486,  0.2496,  6.0356]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-3.3853e-02, -1.0207e+00,  1.7193e+00,  ..., -9.3184e-01,\n",
            "         -1.5350e+00, -1.6898e-01],\n",
            "        [ 2.0142e+00, -4.0896e-01,  2.3820e+00,  ..., -1.7357e+00,\n",
            "         -1.2802e+00, -1.7221e-01],\n",
            "        [ 1.8715e-01,  4.9367e-01,  6.6642e+00,  ..., -2.5324e+00,\n",
            "         -5.7148e-01, -2.6890e-01],\n",
            "        ...,\n",
            "        [-1.0147e+00, -1.8826e+00, -1.6481e+00,  ..., -1.6942e-01,\n",
            "         -1.5926e-01, -3.7895e-01],\n",
            "        [-1.1184e+00,  6.1691e-01,  1.2066e-03,  ...,  1.2195e+00,\n",
            "          3.4390e-01,  7.1107e+00],\n",
            "        [ 1.7927e+00,  1.0372e+00,  7.7974e-02,  ..., -2.3833e-01,\n",
            "         -7.1848e-01, -1.1843e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3475,  0.6085, -0.2956,  ..., -0.4838,  1.8977,  0.1552],\n",
            "        [-1.1678, -0.6162,  0.1438,  ..., -0.5236, -0.4342, -0.4855],\n",
            "        [ 1.6091,  0.3877,  0.5701,  ...,  0.6076, -1.3286, -0.8638],\n",
            "        ...,\n",
            "        [-1.0169, -0.4388,  0.4453,  ..., -0.3091,  2.7641, -0.5891],\n",
            "        [ 0.2918, -0.3173, -0.3633,  ...,  1.3360,  0.6210,  0.0921],\n",
            "        [-0.6392, -1.1205, -1.5337,  ..., -0.4007, -0.1882, -0.5031]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "  Batch 2,800  of  2,811.    Elapsed: 1:13:38.\n",
            "logits :  tensor([[-0.0888,  0.7065, -0.1598,  ..., -1.0182,  0.0572, -0.2351],\n",
            "        [ 1.7437,  0.7913, -1.1739,  ...,  1.1063, -0.1801, -0.2805],\n",
            "        [ 0.7382, -0.9335, -0.0183,  ..., -0.2774, -0.3124, -0.1292],\n",
            "        ...,\n",
            "        [-0.0713,  1.5165,  7.3881,  ..., -2.2058, -0.2809,  0.0601],\n",
            "        [ 0.3980,  0.1058, -2.0473,  ...,  6.9544,  0.6044,  1.2459],\n",
            "        [-0.1042, -0.3365,  0.0140,  ..., -0.5541, -0.6512, -0.2746]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-4.7425e-01,  2.7063e-01,  1.6725e+00,  ..., -2.0312e-01,\n",
            "         -2.2900e-01,  6.7292e-01],\n",
            "        [ 4.2059e-01,  1.8932e-01, -2.5632e-01,  ..., -9.4279e-01,\n",
            "         -7.8392e-01, -1.7645e+00],\n",
            "        [-1.1257e+00, -9.1176e-01, -1.7121e-03,  ..., -5.8726e-01,\n",
            "          1.9648e+00, -4.6322e-01],\n",
            "        ...,\n",
            "        [ 4.5604e-01, -1.4061e-01, -1.0924e+00,  ...,  7.7890e-01,\n",
            "         -2.2149e-02, -6.2818e-02],\n",
            "        [ 2.2851e-01, -7.3124e-01, -1.8179e-01,  ..., -1.2868e+00,\n",
            "         -2.5573e-01, -3.6891e-01],\n",
            "        [ 8.4810e-01, -6.7605e-01, -1.1669e+00,  ...,  9.8377e-01,\n",
            "         -1.5777e+00,  4.5140e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-4.8466e-01, -5.2008e-01, -1.0704e+00,  ...,  1.4149e+00,\n",
            "          1.3760e-01,  7.1465e-01],\n",
            "        [-7.5262e-01, -2.4534e-01, -4.7958e-01,  ...,  6.1385e-01,\n",
            "          4.7835e+00, -2.9151e-01],\n",
            "        [-1.0183e+00, -1.1290e+00, -4.4951e-01,  ..., -1.2251e+00,\n",
            "         -1.9589e-03, -8.1684e-01],\n",
            "        ...,\n",
            "        [ 1.2533e+00,  2.6423e+00,  1.2682e+00,  ...,  1.0774e-01,\n",
            "         -5.6210e-01, -1.1470e-01],\n",
            "        [ 8.3471e-01, -2.8590e-01, -5.5810e-01,  ..., -5.0194e-03,\n",
            "         -2.8522e-01,  8.2202e-03],\n",
            "        [ 2.4076e+00, -1.3709e-01, -3.5589e-01,  ...,  5.1805e-01,\n",
            "         -3.9109e-01, -2.4951e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.0170, -0.6218, -1.0046,  ...,  0.3509,  2.7170, -0.6097],\n",
            "        [-0.0945, -0.7901, -0.5006,  ..., -0.5379, -0.4676, -0.6203],\n",
            "        [-0.2702, -0.1497,  0.2948,  ...,  0.3901,  0.6793,  0.5938],\n",
            "        ...,\n",
            "        [-0.4890, -0.1881,  0.3830,  ..., -0.5429, -0.2501,  0.1435],\n",
            "        [-0.9611,  0.1141,  0.5495,  ..., -0.2084, -0.0744, -0.8296],\n",
            "        [-0.7075,  0.5402, -0.6584,  ...,  0.7152, -0.8745,  1.1532]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.8104, -0.1420,  0.2886,  ..., -0.4770,  1.5734, -0.6868],\n",
            "        [-0.8368, -0.1314, -0.0714,  ..., -0.1471, -0.0814, -0.3716],\n",
            "        [-0.0096,  0.5288,  7.0563,  ..., -2.3359, -0.2892, -0.1290],\n",
            "        ...,\n",
            "        [ 0.3367,  0.1982,  1.0703,  ..., -0.4518, -0.0301, -0.7684],\n",
            "        [ 0.1586,  0.6758,  0.0282,  ...,  0.5395,  0.0233,  1.2426],\n",
            "        [-0.8517,  0.2711,  0.6966,  ..., -1.0291,  0.9843, -0.0782]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6518, -0.5411, -1.3162,  ...,  2.0772, -0.2032,  0.6026],\n",
            "        [ 0.0308, -0.6485, -1.2620,  ...,  0.9520, -0.4647,  1.8237],\n",
            "        [-0.7771, -0.6445, -0.6882,  ..., -0.8712, -0.1187, -0.1551],\n",
            "        ...,\n",
            "        [ 0.3485, -0.6373, -1.6233,  ..., -0.6913, -1.1603, -1.0635],\n",
            "        [-0.2912,  0.2366,  0.6437,  ...,  0.1159,  1.0351, -0.1451],\n",
            "        [-0.5331,  0.1104,  0.8114,  ..., -0.0234, -0.5285,  1.0536]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.5019, -0.6796,  2.5072,  ..., -1.8326, -0.3596, -0.6593],\n",
            "        [ 3.2610,  0.3251,  0.2551,  ...,  0.1413, -0.9077, -0.9287],\n",
            "        [ 0.7630,  0.6716,  0.8143,  ...,  0.8227, -0.6856, -0.1975],\n",
            "        ...,\n",
            "        [-0.6701,  0.6184,  1.0726,  ..., -0.4290, -0.4798,  0.0473],\n",
            "        [ 2.0302,  0.7787, -0.4518,  ..., -0.1833, -0.3434, -0.9841],\n",
            "        [-0.1410,  0.4114,  0.5785,  ..., -1.3673, -0.4495,  0.0811]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[ 0.8708,  0.9165, -1.1444,  ..., -0.4042,  0.1642, -0.6677],\n",
            "        [ 0.7532, -0.5500, -0.7947,  ...,  0.9290, -0.5049,  1.8662],\n",
            "        [-0.0421,  1.0574,  7.3530,  ..., -2.3487, -0.2225,  0.2713],\n",
            "        ...,\n",
            "        [ 2.1223,  1.2791, -0.2290,  ...,  0.4370,  0.1237,  0.2658],\n",
            "        [ 1.5650,  0.6554, -1.0535,  ...,  0.7329,  0.4246, -0.4273],\n",
            "        [-0.2939, -1.1612,  0.1821,  ..., -0.5513, -1.4133, -0.9785]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.6051,  0.0365, -0.6543,  ..., -0.3346,  0.1439,  0.9673],\n",
            "        [ 0.0205,  0.2851, -0.6540,  ...,  0.2533, -0.6048,  1.1063],\n",
            "        [-1.5461,  0.0232, -0.1990,  ...,  0.2959,  0.3941,  2.3131],\n",
            "        ...,\n",
            "        [-1.3313, -0.4826, -0.8566,  ..., -1.2356, -0.5384, -1.3066],\n",
            "        [-0.4133, -1.1947,  0.1340,  ..., -0.8318,  0.2457, -1.1050],\n",
            "        [-0.4860, -1.2527, -0.9707,  ..., -1.0885, -0.7026, -1.1567]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-0.3199,  0.2739,  0.6353,  ...,  0.1864, -0.7864,  0.7271],\n",
            "        [-0.2503, -0.2975,  0.0599,  ..., -0.1746, -0.4685, -0.0740],\n",
            "        [-0.8560, -0.9276, -1.3167,  ...,  0.0701,  1.5238,  0.1698],\n",
            "        ...,\n",
            "        [-0.6078, -0.6945, -1.4234,  ...,  2.7703,  0.0655,  1.0367],\n",
            "        [-0.6220, -0.6250, -0.2574,  ..., -0.0453, -1.2251, -1.5197],\n",
            "        [ 0.8275,  4.1333,  0.4289,  ..., -0.6229, -0.7278, -0.6585]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "16\n",
            "logits :  tensor([[-6.4123e-01,  2.3201e-01, -1.4837e-01,  6.6808e-01,  2.1649e-01,\n",
            "          2.8157e-01, -6.6955e-01, -9.0734e-01, -1.0618e+00, -7.9420e-01,\n",
            "         -1.2920e+00, -7.1936e-01, -5.2302e-01,  3.4142e-01, -3.4406e-01,\n",
            "         -5.5912e-01, -3.2907e-01, -1.3873e-01, -1.6904e-01, -4.2939e-01,\n",
            "          7.5972e-01, -3.6951e-01, -3.2433e-01,  6.4236e-02, -6.6142e-02,\n",
            "         -1.7748e+00,  1.4048e+00,  1.4942e-01, -5.9673e-01, -1.0522e-01,\n",
            "          7.3243e-01,  1.7975e-01,  2.0272e+00, -8.6789e-01, -9.1846e-01,\n",
            "         -7.2519e-01,  1.9684e+00, -9.0223e-01,  7.1798e-01,  6.4366e-01,\n",
            "         -2.9316e-01, -5.6049e-01,  1.0746e+00, -1.3983e+00,  3.5673e-01,\n",
            "          2.9822e-01, -6.4901e-01,  9.6763e-02,  8.7995e-01,  4.0292e-01,\n",
            "          7.3941e-01,  5.1790e-01,  1.0158e+00, -3.4668e-01, -9.4140e-01,\n",
            "          7.3744e+00,  2.3177e-01,  1.2438e-01, -9.3384e-01, -6.9688e-01,\n",
            "         -3.8774e-02, -5.2073e-01, -1.8189e-01, -1.1576e-01, -1.2420e-02,\n",
            "          4.7538e-01,  7.9740e-01, -1.8671e-01, -5.9909e-01,  1.4284e-02,\n",
            "         -3.6704e-01, -4.0894e-01, -4.8942e-01,  2.2807e-01, -1.1263e+00,\n",
            "          1.4490e-01, -3.3453e-01, -9.3118e-01,  4.7043e-01, -1.6998e-01,\n",
            "         -6.3896e-01, -4.4288e-01,  3.0484e-01, -3.5927e-01,  4.2348e-01,\n",
            "         -7.4387e-02, -1.9356e-01, -1.0169e+00, -7.6893e-01,  1.6235e+00,\n",
            "          6.8976e-01, -1.2786e+00,  1.2125e-01, -3.7794e-01,  1.7314e-01,\n",
            "         -1.0815e+00, -2.7864e-03,  1.3105e+00,  2.6476e+00,  4.2972e-01],\n",
            "        [-2.6086e-03, -4.0061e-01,  9.7026e-01,  3.3461e-01,  9.5203e-01,\n",
            "         -6.6798e-01,  3.5460e-01,  5.8811e-01,  5.2991e-01,  5.3861e-01,\n",
            "         -1.1102e+00,  1.7721e-01, -1.2082e+00,  1.2389e-01,  1.4372e+00,\n",
            "         -1.1220e+00, -1.1731e-01,  1.6730e-01, -1.0856e-01,  2.1162e+00,\n",
            "          1.3299e+00, -6.5480e-01, -1.9550e-02,  2.0912e-01, -9.3032e-01,\n",
            "         -1.1952e+00, -5.2215e-01, -1.7406e-01, -7.1711e-01,  9.9597e-01,\n",
            "          1.1299e+00,  1.7841e+00, -1.2097e+00,  9.9855e-01, -7.5614e-01,\n",
            "         -7.2205e-01, -1.7550e+00, -1.0955e+00, -7.1440e-02,  7.5615e-01,\n",
            "          9.5703e-01, -6.2802e-01,  1.3402e+00, -1.2312e+00,  2.6094e+00,\n",
            "         -1.5451e+00, -1.4803e+00, -1.0800e+00, -1.4313e+00, -5.9195e-01,\n",
            "         -1.2672e+00,  7.7669e-01, -6.7324e-01, -3.5248e-01,  5.5467e-01,\n",
            "         -4.1233e-01, -4.0164e-01,  1.9412e+00, -1.3865e+00, -3.1841e-01,\n",
            "          1.7893e+00,  2.5916e-01, -2.9924e-02, -8.9746e-01,  4.3436e+00,\n",
            "          7.8050e-01, -8.1042e-01,  1.2691e+00, -4.9222e-01,  4.3637e-01,\n",
            "          1.5296e+00, -1.0700e+00,  3.4284e-01, -1.2450e+00,  6.4571e-01,\n",
            "         -7.0905e-01, -1.7109e+00, -6.0095e-01, -4.2713e-01, -3.5288e-01,\n",
            "         -4.5850e-01, -2.2365e+00, -4.1579e-02, -1.2549e+00, -8.1934e-01,\n",
            "          9.4413e-01,  1.7519e+00,  1.9519e+00,  4.1267e-01, -6.2008e-01,\n",
            "         -1.1390e+00, -9.7724e-01, -1.5069e+00, -1.1923e+00,  9.7518e-01,\n",
            "         -8.7089e-01, -6.3517e-01, -8.8535e-01, -1.3961e+00,  8.0744e-01],\n",
            "        [-1.6030e+00,  3.2566e-01, -2.5124e-02,  2.0793e-01,  9.0750e-01,\n",
            "         -7.3250e-01, -3.2133e-01,  7.8468e-02, -1.1018e+00, -5.3579e-01,\n",
            "         -3.1798e-01, -1.4137e+00,  6.0170e-01, -7.9717e-01, -9.1100e-01,\n",
            "         -4.0064e-01, -2.1299e-02, -6.8202e-01, -1.3760e+00,  2.6400e-01,\n",
            "         -1.3403e-01, -6.3396e-01, -7.8563e-01, -9.1946e-01, -1.0422e+00,\n",
            "          3.1320e-01, -1.1662e+00, -1.6913e-01,  1.2837e-01, -6.6787e-01,\n",
            "         -8.6296e-02,  5.4684e-01,  4.2833e-01, -5.6333e-01, -1.7673e+00,\n",
            "         -3.6132e-01,  1.0109e+00, -8.0448e-02, -1.2251e+00, -3.5186e-01,\n",
            "         -1.9904e-01, -2.9117e-01,  1.0065e-01, -5.4239e-01, -4.5685e-01,\n",
            "          1.4400e+00, -8.0410e-01,  1.4518e+00, -7.3865e-01,  1.6231e+00,\n",
            "          1.8491e+00, -3.2686e-01, -6.7649e-01, -1.6457e+00, -1.0829e+00,\n",
            "         -1.0364e-01, -7.8029e-02, -3.7416e-01, -7.1032e-02,  6.0389e-02,\n",
            "          3.5785e-01, -2.6878e-01, -8.5253e-02, -7.7630e-01,  4.5405e-01,\n",
            "         -5.0730e-01,  1.1315e-01,  5.0319e-02,  7.6209e-01, -7.4255e-01,\n",
            "          2.2883e-01,  7.0921e-01,  1.7800e+00, -1.0671e+00,  6.5555e-03,\n",
            "          2.9098e-01,  2.1771e-03,  1.8826e+00, -3.6007e-01,  1.9354e+00,\n",
            "         -4.1346e-01,  4.8855e-01,  6.1680e-01,  3.8966e-02,  5.7586e-01,\n",
            "          3.5082e-01, -7.1186e-01,  5.7776e-02, -2.3247e-01,  1.0609e+00,\n",
            "         -1.4737e+00,  1.1337e-01,  1.2538e-01, -9.1882e-01,  1.8248e+00,\n",
            "         -2.5368e-01,  4.3564e-01,  6.9221e-01,  3.7177e-01,  7.2471e+00],\n",
            "        [-2.3373e-01, -8.7624e-02, -2.4621e-01,  2.0106e+00,  7.0356e-01,\n",
            "          6.4742e-01, -6.4977e-01,  3.4583e-01,  9.8336e-01,  1.6695e+00,\n",
            "         -7.3818e-01,  1.5900e+00, -1.2484e+00,  7.1691e-01,  1.7739e+00,\n",
            "         -1.2885e-01,  1.0745e+00, -1.3599e-01,  4.0199e-01,  5.6328e-01,\n",
            "          1.2322e+00, -1.3375e+00,  6.8184e-01,  8.2114e-01, -5.6222e-01,\n",
            "         -1.1748e+00,  2.9939e-01,  3.7146e-01,  3.9483e-01,  1.9024e+00,\n",
            "          9.7318e-01, -3.2210e-01, -7.7390e-01,  9.2670e-01,  5.0348e-01,\n",
            "         -3.1424e-01, -3.0137e-01, -6.5303e-01,  8.1961e-01,  1.0109e-01,\n",
            "          5.1881e-01, -1.0407e+00,  2.0807e-01, -6.9335e-01,  3.0159e+00,\n",
            "         -1.3581e+00, -6.5813e-02, -9.7385e-01, -1.1789e+00,  5.7373e-01,\n",
            "         -1.8655e-01,  6.8080e-01,  4.2315e-01, -6.7014e-01,  2.1281e-01,\n",
            "         -5.9992e-01, -1.7918e+00,  7.0375e+00, -6.9252e-01, -1.3547e+00,\n",
            "         -7.3504e-01, -1.0490e+00,  6.4410e-01, -1.2359e+00,  1.2757e+00,\n",
            "         -2.6252e-02, -1.2357e-01, -1.3916e+00, -1.4620e+00,  4.7787e-01,\n",
            "          4.0808e-01, -8.9338e-01, -8.5423e-01, -8.9931e-01,  2.0537e+00,\n",
            "          2.6757e-01, -1.2143e+00, -1.2825e+00, -1.2777e+00,  2.1746e-01,\n",
            "         -1.9591e-01, -1.2632e+00, -6.7252e-01, -8.1402e-01,  4.6626e-01,\n",
            "         -5.9801e-02, -1.0922e-01,  1.1361e+00, -1.6101e-01,  3.6821e-01,\n",
            "         -1.0630e+00, -5.7291e-01, -1.3253e-01, -6.6009e-01, -2.7344e-01,\n",
            "         -9.0795e-01, -1.2899e+00, -1.2956e+00, -3.2567e-01,  8.7983e-03],\n",
            "        [-6.8057e-01,  2.3086e-02, -2.8144e-01, -7.9440e-02, -1.1030e+00,\n",
            "         -3.9087e-01, -8.4125e-01, -4.6053e-01,  6.0584e-01, -1.0308e+00,\n",
            "          2.5391e-01, -9.6068e-02, -8.8256e-02, -9.3218e-01, -5.9667e-01,\n",
            "          6.2468e-02, -1.0750e-01, -1.0484e+00, -5.1587e-01,  6.5514e-01,\n",
            "         -6.8858e-01, -5.0484e-01,  5.9300e-01, -6.4169e-01, -4.9047e-02,\n",
            "          3.0165e-01,  4.3956e-01,  1.0344e+00, -4.2721e-01, -8.1321e-01,\n",
            "          1.6959e-01,  5.1457e-01,  1.8483e+00, -1.3509e+00, -4.1361e-01,\n",
            "          5.2989e-01, -8.4463e-01,  9.8587e-01, -4.4995e-02, -3.6959e-01,\n",
            "         -7.9744e-01,  7.1504e-01, -8.6426e-01,  6.7746e-01, -9.6120e-01,\n",
            "          7.9031e-01,  1.1777e+00, -1.1600e+00,  6.6958e+00, -4.7133e-02,\n",
            "         -7.8860e-01, -1.0660e+00, -2.6197e-01,  1.3804e-01, -2.9290e-01,\n",
            "          8.2911e-01,  1.3190e-01, -1.1566e+00,  9.5157e-01, -4.4559e-01,\n",
            "          5.6597e-01, -1.1132e+00, -5.6457e-01, -3.0205e-02, -3.2096e-01,\n",
            "         -5.9748e-01, -1.3069e-01,  5.7828e-01, -5.3598e-01, -1.5431e+00,\n",
            "         -2.3892e-01,  2.7560e-01, -2.7770e-01,  1.3618e+00, -7.1482e-01,\n",
            "         -4.2565e-01,  3.8491e-01,  8.0703e-01, -6.5069e-01, -6.4039e-01,\n",
            "          4.1971e-01,  1.0792e+00, -2.2537e-01,  1.9319e+00,  4.1337e-02,\n",
            "          6.2289e-02, -7.6633e-02, -1.3595e+00, -1.3026e+00, -4.0707e-03,\n",
            "          2.2205e+00, -4.0109e-01, -2.1421e-01,  1.3447e+00, -1.1986e+00,\n",
            "          2.2025e-01, -9.9100e-02, -3.5288e-01,  1.0319e+00, -1.4497e-01],\n",
            "        [-4.0095e-01, -8.9704e-01, -1.4515e+00,  6.3459e-01,  2.4461e+00,\n",
            "          1.1776e+00, -6.9468e-01, -1.5408e+00,  2.8298e-01, -4.0009e-01,\n",
            "         -6.6044e-01, -1.2165e+00, -1.5163e-01,  2.2865e+00, -1.3863e+00,\n",
            "          3.2906e-01,  3.3411e-01, -1.3052e+00, -1.6129e+00, -1.8024e-01,\n",
            "         -1.7672e+00, -3.2934e-01,  6.4379e-01, -1.2990e+00,  5.8127e-01,\n",
            "         -6.4210e-01,  1.3187e+00,  1.2022e+00,  5.7503e-01, -1.9309e-01,\n",
            "         -5.9993e-01, -4.4779e-01, -2.2377e-01,  9.3272e-01, -5.0261e-01,\n",
            "          1.3154e+00, -2.5462e-01,  2.9482e-01,  1.3695e+00,  1.7838e+00,\n",
            "         -1.6460e+00, -2.1268e-01, -3.7100e-01,  1.6428e+00, -5.4076e-01,\n",
            "         -2.2398e-01,  3.4538e-01,  9.8895e-01,  7.0805e-01,  6.4722e-01,\n",
            "          9.9216e-01, -1.7033e+00,  5.8410e-02, -1.0449e+00, -2.0709e-01,\n",
            "         -3.8192e-01,  1.2487e+00, -9.0997e-01, -2.0939e-01,  1.4112e+00,\n",
            "         -6.4192e-01, -5.2833e-01, -3.7121e-01, -9.3808e-02, -8.3877e-01,\n",
            "         -1.2979e+00,  3.8162e-01, -9.7825e-01,  5.5043e-02,  2.5958e-01,\n",
            "          8.1321e-02, -7.6148e-01,  1.0882e+00, -9.3866e-01, -9.1754e-01,\n",
            "          7.8099e-01,  7.1590e-01,  1.2294e-01, -6.2262e-01, -5.0066e-01,\n",
            "          7.7745e-01,  6.3346e+00, -9.3616e-01,  1.5806e-02,  4.4587e-01,\n",
            "          5.2032e-01,  1.8217e+00,  2.3265e-01, -7.8418e-01, -3.0769e-01,\n",
            "          5.8000e-01,  1.1302e+00, -4.0565e-01, -3.9411e-02,  3.8506e-01,\n",
            "          6.9119e-01, -4.9664e-01,  2.7815e-01, -1.9048e-01, -4.5043e-01],\n",
            "        [-1.9269e-01, -1.0007e+00, -7.3960e-01,  1.9284e+00, -6.6122e-01,\n",
            "         -7.9144e-01, -1.3015e+00,  1.4307e+00, -4.8686e-01,  9.5992e-01,\n",
            "         -8.7697e-01, -9.3625e-01, -4.6216e-01,  1.5464e-01, -5.4682e-02,\n",
            "          1.5148e+00,  4.3065e-01,  4.9707e-03, -1.0204e+00, -4.4463e-01,\n",
            "          3.5236e-01,  2.0400e-01,  5.0084e-01, -2.7623e-01,  1.4441e+00,\n",
            "         -1.9789e-01, -8.2962e-03, -1.0969e+00, -1.3174e+00,  4.3301e-01,\n",
            "         -1.5079e-01, -4.1591e-01, -2.7810e-01, -3.3171e-01, -7.8278e-01,\n",
            "          2.9832e-01, -8.5038e-01,  6.8765e-02, -4.9435e-01,  1.0990e+00,\n",
            "          4.3483e-02, -2.2645e-02, -2.2956e-01, -8.0131e-01,  2.2791e+00,\n",
            "         -6.2119e-01, -7.9113e-01, -1.2808e+00, -6.9914e-01,  2.1811e-01,\n",
            "         -3.0482e-01,  5.6680e+00,  3.3160e+00, -4.6358e-01, -3.4703e-01,\n",
            "          4.7997e-01,  2.8062e+00,  6.9827e-01, -9.4526e-01, -9.1030e-01,\n",
            "         -3.8902e-01,  4.8304e-01, -1.6035e+00, -3.3508e-01, -5.2556e-01,\n",
            "          6.9376e-01, -2.8025e-01,  4.7731e-01, -1.3030e+00,  5.7163e-02,\n",
            "          1.5885e-01, -7.9381e-01, -2.8611e-01,  3.0745e+00, -2.7068e-01,\n",
            "         -9.9247e-01, -1.5573e+00, -6.7856e-01, -9.9637e-01, -6.6876e-01,\n",
            "          8.8994e-01, -1.8110e+00, -1.4395e+00, -5.1680e-01,  1.5279e-01,\n",
            "         -1.2893e+00,  4.7376e-02,  9.9882e-01, -8.7664e-01, -1.0589e+00,\n",
            "         -3.0467e-01, -2.2050e-01, -8.6949e-01, -5.1581e-01,  1.2858e+00,\n",
            "          1.2223e-01, -1.0209e+00,  2.8026e-01,  2.5678e+00, -5.4797e-01],\n",
            "        [ 6.0790e-01,  2.9395e-01, -6.7186e-02, -8.1502e-01,  1.2647e-01,\n",
            "         -3.2914e-01,  5.5085e-01, -9.0475e-01, -8.2646e-01, -1.5254e+00,\n",
            "          1.1818e-01, -6.8166e-01,  8.7229e-01, -8.2554e-01, -9.8648e-01,\n",
            "         -6.7726e-01, -2.8475e-01,  3.1201e-01,  7.6810e-01, -8.1486e-01,\n",
            "          1.8078e-01,  1.1088e-01, -1.3882e+00, -4.3885e-01, -6.0103e-01,\n",
            "          2.8099e-02, -7.0984e-01, -1.2595e+00,  1.5949e+00,  6.5009e-02,\n",
            "         -5.7630e-01, -1.3621e-01, -5.1170e-02, -4.5144e-01,  1.0185e+00,\n",
            "         -5.5904e-01,  1.1614e+00,  6.8240e-01, -8.3366e-01, -6.9065e-01,\n",
            "         -5.5276e-01,  1.3321e+00,  2.2965e-01, -6.1027e-01, -1.0521e+00,\n",
            "         -3.9725e-03,  4.8309e-02,  6.0337e-01, -8.0510e-01,  1.0598e-01,\n",
            "          5.4233e-01, -1.0670e+00,  1.0532e-01,  4.7999e-01,  5.1368e-01,\n",
            "          3.4216e-01, -1.0130e+00, -8.4419e-01,  8.8424e-01, -1.6512e-01,\n",
            "          6.4769e-01,  5.2864e-01,  6.9538e-01,  1.2924e+00, -2.7976e-01,\n",
            "          9.8293e-01,  2.2092e-01,  1.4137e+00, -4.8615e-01, -7.8387e-01,\n",
            "         -3.1358e-01,  2.1859e+00, -3.5403e-01, -6.2574e-01,  1.8479e-01,\n",
            "          1.2594e-01,  1.2665e-01, -7.7155e-01,  1.0494e+00,  1.8900e-01,\n",
            "         -5.6451e-01, -9.8687e-01,  6.8214e+00, -2.8260e-01,  3.4461e-01,\n",
            "         -5.4618e-01, -2.9522e-01, -1.5929e+00, -2.6100e-01,  2.7024e-02,\n",
            "          9.9668e-01, -8.2398e-01, -8.7465e-01, -5.7741e-01, -3.6484e-01,\n",
            "          1.8808e-01,  1.2482e+00,  1.5509e+00, -9.1076e-01,  1.1690e-01],\n",
            "        [-8.7711e-01, -1.8867e-01, -6.3890e-01, -1.8032e+00, -4.3599e-01,\n",
            "         -3.7197e-01, -3.8158e-01, -2.4074e-01, -3.7448e-01, -6.5575e-01,\n",
            "          2.4007e-01,  1.9080e-01,  6.3969e-01, -1.7574e-01, -9.6480e-01,\n",
            "         -4.9200e-01, -5.4040e-01, -3.6565e-01,  8.8620e-02,  2.9110e-01,\n",
            "          1.8962e-01, -4.1071e-01,  2.2567e-01, -3.5353e-01, -8.5676e-01,\n",
            "          1.3060e+00, -1.7095e+00, -7.9973e-01,  5.3870e-01, -2.0741e-01,\n",
            "          2.4542e-01, -3.6489e-01,  1.1345e-01, -5.9596e-01,  4.0171e-01,\n",
            "          7.2102e-01,  3.8013e-01,  7.9316e+00, -8.9392e-01, -1.6918e+00,\n",
            "         -2.6770e-01,  4.7401e-01, -1.2208e+00,  1.8323e+00, -7.0264e-01,\n",
            "          1.6338e+00,  8.3990e-02,  1.2691e+00,  5.8831e-03,  5.7308e-01,\n",
            "          2.8782e+00, -1.4562e-01,  1.5420e-01, -4.6032e-01, -4.0416e-01,\n",
            "         -8.7181e-01, -8.0977e-01, -2.8060e-01,  1.6608e-01, -6.8908e-02,\n",
            "          8.5040e-01, -1.0933e+00,  4.4623e-01, -4.2945e-01, -1.1899e-01,\n",
            "         -3.1771e-01, -1.2197e+00, -1.6879e-01, -4.0167e-01, -1.4733e+00,\n",
            "         -5.1122e-01,  3.4112e-01,  5.4974e-02,  6.8589e-01,  2.6836e-01,\n",
            "          2.5708e+00, -4.6848e-01,  8.0234e-01, -8.3302e-01, -8.7319e-02,\n",
            "         -3.1329e-01,  1.2707e-01,  6.2143e-01,  7.7904e-01,  1.5737e+00,\n",
            "         -6.6651e-01, -4.7653e-01, -5.2257e-01, -1.0873e-01,  4.1892e-01,\n",
            "          7.8213e-01,  2.3567e-01,  7.0908e-01,  8.1926e-02, -7.9809e-01,\n",
            "          7.1890e-01,  9.6937e-02,  5.7363e-01, -4.5405e-01,  3.7674e-01],\n",
            "        [-1.3843e-01, -2.8270e-01,  1.8586e-01, -2.2870e-01, -2.3311e-01,\n",
            "         -5.7555e-01, -1.3398e+00, -5.6142e-01,  1.5572e+00,  2.4721e+00,\n",
            "         -1.1650e+00,  9.9168e-01,  5.5284e-01,  5.4582e-01,  9.1084e-01,\n",
            "         -8.9390e-01, -1.8704e-01,  8.3913e-01,  1.0502e+00,  1.3106e+00,\n",
            "         -1.9059e-02, -1.7399e+00,  9.6716e-01,  1.2885e+00,  1.8484e-01,\n",
            "         -8.8785e-01,  5.2734e-01,  6.6006e-02, -3.5407e-01, -1.7246e-01,\n",
            "          7.1106e+00,  6.8707e-01, -4.5678e-01,  8.2824e-01, -1.1200e+00,\n",
            "         -4.2747e-01, -6.6771e-01,  1.2212e-01, -7.6467e-01, -1.0147e+00,\n",
            "         -1.0306e+00, -4.7291e-01, -5.0789e-02, -1.2579e+00,  1.5808e+00,\n",
            "         -3.2282e-01,  6.1162e-01, -1.9228e-01,  1.1211e-01,  3.6362e-01,\n",
            "          5.4171e-01, -5.3476e-01, -3.0831e-01,  1.3940e+00, -8.7426e-02,\n",
            "         -4.0358e-02, -1.7320e+00,  9.7673e-01, -2.1330e-01, -6.1558e-01,\n",
            "         -2.4027e-01, -1.2255e+00, -5.7789e-01, -1.4791e+00,  7.0911e-01,\n",
            "         -1.0604e+00, -7.0353e-01, -7.2391e-01, -9.2395e-01, -4.5433e-01,\n",
            "          1.4230e+00,  1.0275e-01, -1.9399e+00, -1.6636e+00, -1.2141e+00,\n",
            "          2.5591e-01,  1.1643e-01, -1.0497e-01, -7.0531e-01, -3.5606e-01,\n",
            "          3.9118e-01, -2.6024e-02, -1.1489e+00,  4.2954e-01, -4.0174e-02,\n",
            "         -6.3145e-01, -4.0567e-01,  9.2723e-01,  1.3369e+00, -7.5196e-02,\n",
            "         -6.3369e-01, -1.0739e+00, -4.9650e-01, -7.8967e-01, -5.1999e-01,\n",
            "         -4.7723e-01, -5.3190e-01,  1.0730e-01, -1.3454e-01, -2.3563e-01]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "10\n",
            "\n",
            "  Average training loss: 1.63\n",
            "  Training epcoh took: 1:13:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.61\n",
            "  Validation took: 0:02:57\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:16:52 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/ASU/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFET0qIiPdk7",
        "outputId": "f20f1a02-35f6-4d51-8f0f-d0ac08d58fa6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/ASU/model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ASU/model_save/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/vocab.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/merges.txt',\n",
              " '/content/drive/MyDrive/ASU/model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Tv4UlVXfHU5h",
        "outputId": "4cba9687-cf69-4ae3-de2f-ba6b2d8f6c5c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               1.63         0.61           0.87       1:13:55         0:02:57"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de5e2f6d-13a8-4a96-a689-9cb3e1341e0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.63</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.87</td>\n",
              "      <td>1:13:55</td>\n",
              "      <td>0:02:57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de5e2f6d-13a8-4a96-a689-9cb3e1341e0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de5e2f6d-13a8-4a96-a689-9cb3e1341e0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de5e2f6d-13a8-4a96-a689-9cb3e1341e0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "iweBagNKHVLU",
        "outputId": "b1dafd7a-733b-429d-c250-d985960ffea1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import regex as re\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ASU/ood_test_data_small.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nUAlH28vHYuN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['flag']=df.loc[:,['real_label','review']].apply(lambda x: re.match(\"UPDATE*\",x['review']),axis=1 )\n",
        "#removing updated records\n",
        "\n",
        "df=df.loc[:,['real_label','review','flag']].loc[df['flag'].isin([None])]\n",
        "df.drop('flag',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "rAII-BpSKeSC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "JjfsmaGSL38f",
        "outputId": "5be35c80-4c05-42ab-ab4e-dcd3efa20b7e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   real_label                                             review\n",
              "0          44  I bought this battery charger a year ago, when...\n",
              "1          44  I bought this because with four geriatric vehi...\n",
              "2          44  I was a tad skeptical of the outcome after see...\n",
              "3          44  I insist on every one of my vehicles to have a...\n",
              "4          44  This is a very well-made top grain cow leather...\n",
              "5          44  At first I was pleased to get this roller shad...\n",
              "6          44  This strap appears well-made, with inch-thick ...\n",
              "7          44  For a quick, overall shine on chrome and plast...\n",
              "8          44  This balaclava comes in a small, bubble-wrap p...\n",
              "9          44  This is an impressive car jump battery pack wi..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-775f156e-a977-45c6-ba43-054d59ed5a98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>I bought this battery charger a year ago, when...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>I bought this because with four geriatric vehi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>I was a tad skeptical of the outcome after see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>I insist on every one of my vehicles to have a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>This is a very well-made top grain cow leather...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>44</td>\n",
              "      <td>At first I was pleased to get this roller shad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>44</td>\n",
              "      <td>This strap appears well-made, with inch-thick ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>44</td>\n",
              "      <td>For a quick, overall shine on chrome and plast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>44</td>\n",
              "      <td>This balaclava comes in a small, bubble-wrap p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>44</td>\n",
              "      <td>This is an impressive car jump battery pack wi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-775f156e-a977-45c6-ba43-054d59ed5a98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-775f156e-a977-45c6-ba43-054d59ed5a98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-775f156e-a977-45c6-ba43-054d59ed5a98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.loc[df.real_label.values<100]"
      ],
      "metadata": {
        "id": "mApZpnbpMN10"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(by='real_label').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "XikERaqQLOiG",
        "outputId": "457f63ab-75d9-48f8-f1d0-5953307b3408"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            review\n",
              "real_label        \n",
              "0               99\n",
              "1              100\n",
              "2              100\n",
              "3              100\n",
              "4              100\n",
              "...            ...\n",
              "95             100\n",
              "96             100\n",
              "97             100\n",
              "98             100\n",
              "99             100\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ede093d-1b4c-4184-a000-1c44121c059e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ede093d-1b4c-4184-a000-1c44121c059e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ede093d-1b4c-4184-a000-1c44121c059e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ede093d-1b4c-4184-a000-1c44121c059e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create sentence and label lists\n",
        "#\n",
        "#labels = df.real_label.values\n",
        "#sentence1 = df.review.values\n",
        "sentence1=sentences\n",
        "labels = dataset_filtered.real_label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent1 in zip(sentence1):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent1,# Sentence to encode.\n",
        "                        truncation=True,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "r9dPsWLsKHFH"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  pred_labels = np.argmax(logits, axis=1)\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(pred_labels.tolist())\n",
        "  true_labels.extend(label_ids.tolist())\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJTEXHAzM3pK",
        "outputId": "08c1e8c4-c91e-4e32-9c7a-e45d5a2761e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 49,967 test sentences...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(predictions)"
      ],
      "metadata": {
        "id": "6Uo5Q2CMsC2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(true_labels)"
      ],
      "metadata": {
        "id": "04Gb-rS0sFPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "qoRci6B5SW_e"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_metrics=sklearn.metrics.classification_report(true_labels, predictions, digits=100, output_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3oDS63sSYnr",
        "outputId": "b5525015-db57-4c9d-f358-7f2fab22a992"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "result_report= classification_report(true_labels, predictions, digits=100)\n",
        "print(result_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYNPK2cnM9FX",
        "outputId": "9c479e6d-0ecf-49e3-f6fd-7417fbb40b54"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                      precision    recall  f1-score   support\n",
            "\n",
            "                                                                                                   0  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000        99\n",
            "                                                                                                   1  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                   2  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                   3  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                   4  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                   5  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000        99\n",
            "                                                                                                   6  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                   7  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                   8  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                   9  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  10  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  11  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  12  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  13  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  14  0.0100130169219985985795684513277592486701905727386474609375000000000000000000000000000000000000000000 1.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0198275007435312795867066171240367111749947071075439453125000000000000000000000000000000000000000000       100\n",
            "                                                                                                  15  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  16  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  17  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  18  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  19  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  20  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  21  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  22  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  23  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  24  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  25  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000        99\n",
            "                                                                                                  26  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  27  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  28  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  29  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000        98\n",
            "                                                                                                  30  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  31  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  32  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  33  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  34  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  35  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  36  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  37  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  38  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000        99\n",
            "                                                                                                  39  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  40  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  41  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  42  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  43  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  44  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000        96\n",
            "                                                                                                  45  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  46  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  47  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  48  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  49  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  50  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  51  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  52  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  53  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  54  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  55  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  56  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  57  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  58  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  59  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  60  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  61  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  62  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  63  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  64  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  65  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  66  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  67  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  68  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  69  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000        98\n",
            "                                                                                                  70  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  71  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  72  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  73  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  74  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  75  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  76  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  77  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  78  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  79  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  80  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  81  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  82  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  83  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  84  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  85  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  86  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  87  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  88  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  89  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  90  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000        99\n",
            "                                                                                                  91  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  92  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  93  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  94  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  95  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  96  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  97  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  98  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "                                                                                                  99  0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000       100\n",
            "\n",
            "                                                                                            accuracy                      0.0100130169219985985795684513277592486701905727386474609375000000000000000000000000000000000000000000      9987\n",
            "                                                                                           macro avg  0.0001001301692199859836272801683065836186870001256465911865234375000000000000000000000000000000000000 0.0100000000000000002081668171172168513294309377670288085937500000000000000000000000000000000000000000 0.0001982750074353127904460553088128449417126830667257308959960937500000000000000000000000000000000000      9987\n",
            "                                                                                        weighted avg  0.0001002605078802302817969280268606269146403064951300621032714843750000000000000000000000000000000000 0.0100130169219985985795684513277592486701905727386474609375000000000000000000000000000000000000000000 0.0001985331004659184940021321441605550717213191092014312744140625000000000000000000000000000000000000      9987\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brek"
      ],
      "metadata": {
        "id": "0wU62prNyraY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/ASU/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "metadata": {
        "id": "55TGwUWdM92G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "metadata": {
        "id": "Wup4eBSGNAnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "metadata": {
        "id": "AwSPmLacNFlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = RobertaForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = RobertaForSequenceClassification.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "nvMN56oGNtjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA8r4uk9PPkj",
        "outputId": "428dbb8c-2e92-4680-8710-f49c17a8a60b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Trz1nxZCPQjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e49f574fc784dee829f63e7b57c1e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff5537f8d4de4ad79b242a039e7f21fd",
              "IPY_MODEL_cb3620b504f347599aa9e97d681cf0cb",
              "IPY_MODEL_9fe22194db0e4d4c91ca395f274804fd"
            ],
            "layout": "IPY_MODEL_b714a50f338b4d388549231b53d8ce04"
          }
        },
        "ff5537f8d4de4ad79b242a039e7f21fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f86491a6654bc79426b56082f15407",
            "placeholder": "​",
            "style": "IPY_MODEL_64b9af0dd2b8486195bd87913e02d681",
            "value": "Downloading: 100%"
          }
        },
        "cb3620b504f347599aa9e97d681cf0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f7bb02e6444e4b9934c2125fabb1c9",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e063a91f3dc842bfaf9ca14207b1be82",
            "value": 898823
          }
        },
        "9fe22194db0e4d4c91ca395f274804fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e23826b83504bab95154b60c93310d9",
            "placeholder": "​",
            "style": "IPY_MODEL_653f34951fe24f87bf5ac7addb9615ec",
            "value": " 899k/899k [00:01&lt;00:00, 587kB/s]"
          }
        },
        "b714a50f338b4d388549231b53d8ce04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36f86491a6654bc79426b56082f15407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b9af0dd2b8486195bd87913e02d681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f7bb02e6444e4b9934c2125fabb1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e063a91f3dc842bfaf9ca14207b1be82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e23826b83504bab95154b60c93310d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653f34951fe24f87bf5ac7addb9615ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab09c9910bc84cf1af02838c418ef83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7c4166a7a8747978717ba7aae195ae7",
              "IPY_MODEL_7b3be117f6dd4b9faa3a21af007bf4ff",
              "IPY_MODEL_f73492744a404c67aa23413e77969171"
            ],
            "layout": "IPY_MODEL_e3c311d2fb224d079b13399064908893"
          }
        },
        "e7c4166a7a8747978717ba7aae195ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec390a539a0c4b408e46b1b1abd56329",
            "placeholder": "​",
            "style": "IPY_MODEL_b2a7f88ab772488fb26bb0320a5bff7e",
            "value": "Downloading: 100%"
          }
        },
        "7b3be117f6dd4b9faa3a21af007bf4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2b5e3a280c437ebd17cac71f441a21",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47900b36aea54bc29e1fe5d6e54333af",
            "value": 456318
          }
        },
        "f73492744a404c67aa23413e77969171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18dbf81a0007438d837e9a89fcc275fa",
            "placeholder": "​",
            "style": "IPY_MODEL_dcb28abbc57c48069d6909747376dcfe",
            "value": " 456k/456k [00:01&lt;00:00, 471kB/s]"
          }
        },
        "e3c311d2fb224d079b13399064908893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec390a539a0c4b408e46b1b1abd56329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a7f88ab772488fb26bb0320a5bff7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf2b5e3a280c437ebd17cac71f441a21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47900b36aea54bc29e1fe5d6e54333af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18dbf81a0007438d837e9a89fcc275fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb28abbc57c48069d6909747376dcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bcaa69d6e3d43e19f0c56f05844d760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9550883bc39949d1972d1683452b4266",
              "IPY_MODEL_45960c910c934728a4d143553e896ab8",
              "IPY_MODEL_bbe83bd48ac344ae9a58dc8b92e93061"
            ],
            "layout": "IPY_MODEL_ef63a720b5934de8b3c405b78f41ee70"
          }
        },
        "9550883bc39949d1972d1683452b4266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_300ee276fbb34414a4e0522ce8b74b06",
            "placeholder": "​",
            "style": "IPY_MODEL_bcea42c3ba474faead0a1ebb7eb0e426",
            "value": "Downloading: 100%"
          }
        },
        "45960c910c934728a4d143553e896ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71562a7413054110a40d6e619d3ef894",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c479a7273974e7b9977c205ecbf4700",
            "value": 481
          }
        },
        "bbe83bd48ac344ae9a58dc8b92e93061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30d6a792f21842a2b3607a7107465f51",
            "placeholder": "​",
            "style": "IPY_MODEL_587906a4b6ec4895ab873ecbae50aed8",
            "value": " 481/481 [00:00&lt;00:00, 3.32kB/s]"
          }
        },
        "ef63a720b5934de8b3c405b78f41ee70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300ee276fbb34414a4e0522ce8b74b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcea42c3ba474faead0a1ebb7eb0e426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71562a7413054110a40d6e619d3ef894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c479a7273974e7b9977c205ecbf4700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30d6a792f21842a2b3607a7107465f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "587906a4b6ec4895ab873ecbae50aed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f813b126a8d49708c6b57cdd7ea083e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d578b958e744234960b086ef7382c14",
              "IPY_MODEL_d357520ec4aa40e590501bf3692baa34",
              "IPY_MODEL_d4b30545da0e449cbbd8ecd54011436f"
            ],
            "layout": "IPY_MODEL_9ddbd777132b42fc8c9018bc8b97e993"
          }
        },
        "5d578b958e744234960b086ef7382c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66200ad9979e464b960cdce71c7dd1af",
            "placeholder": "​",
            "style": "IPY_MODEL_e532244c360347e0bfb95d048542fa3c",
            "value": "Downloading: 100%"
          }
        },
        "d357520ec4aa40e590501bf3692baa34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d805bfdf75454c9632f80a4f89989c",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cc9e0538484445d959e31d448ade76d",
            "value": 501200538
          }
        },
        "d4b30545da0e449cbbd8ecd54011436f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86083ab57c845648deba87a7b7c39a5",
            "placeholder": "​",
            "style": "IPY_MODEL_19f810c703684ad9835a12253a0d48b8",
            "value": " 501M/501M [00:08&lt;00:00, 58.9MB/s]"
          }
        },
        "9ddbd777132b42fc8c9018bc8b97e993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66200ad9979e464b960cdce71c7dd1af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e532244c360347e0bfb95d048542fa3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04d805bfdf75454c9632f80a4f89989c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc9e0538484445d959e31d448ade76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a86083ab57c845648deba87a7b7c39a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f810c703684ad9835a12253a0d48b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}