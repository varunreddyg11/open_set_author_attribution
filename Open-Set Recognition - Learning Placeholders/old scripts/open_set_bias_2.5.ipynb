{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hiCdiTWzgKeG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#pd.set_option('display.max_rows', 50000)/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oq68oD37gl7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce8b875-db29-4236-b003-89a34768ff91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IWe3lgvZgZTb",
        "outputId": "c2e27329-fe5e-49d1-d3cb-a498c069a63e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           author  real_label  label  \\\n",
              "0  A11OTLEDSW8ZXD          44     44   \n",
              "1  A11OTLEDSW8ZXD          44     44   \n",
              "2  A11OTLEDSW8ZXD          44     44   \n",
              "3  A11OTLEDSW8ZXD          44     44   \n",
              "4  A11OTLEDSW8ZXD          44     44   \n",
              "5  A11OTLEDSW8ZXD          44     44   \n",
              "6  A11OTLEDSW8ZXD          44     44   \n",
              "7  A11OTLEDSW8ZXD          44     44   \n",
              "8  A11OTLEDSW8ZXD          44     44   \n",
              "9  A11OTLEDSW8ZXD          44     44   \n",
              "\n",
              "                                              review  \\\n",
              "0  I have always been a fan of the Lewis and Clar...   \n",
              "1  I started reading this book during a three-wee...   \n",
              "2  This cable is well-made and feels sturdier tha...   \n",
              "3  This kibble is expensive, but the cats like it...   \n",
              "4  This device is exactly what we needed for our ...   \n",
              "5  These beef hides are quite the treat.  I like ...   \n",
              "6  Reading this memoir was quite a surprise.  It ...   \n",
              "7  Being a born Hoosier and having graduated from...   \n",
              "8  This is a surprisingly good first novel.  Whil...   \n",
              "9  My first impression of this lens was its weigh...   \n",
              "\n",
              "                        product_domain  overall  #words  \n",
              "0                        books.json.gz      5.0     529  \n",
              "1                        books.json.gz      4.0     193  \n",
              "2  cell_phones_and_accessories.json.gz      4.0     109  \n",
              "3                 pet_supplies.json.gz      5.0     100  \n",
              "4                  electronics.json.gz      4.0     197  \n",
              "5                 pet_supplies.json.gz      5.0     130  \n",
              "6                        books.json.gz      4.0     393  \n",
              "7                        books.json.gz      4.0     382  \n",
              "8                        books.json.gz      5.0     140  \n",
              "9                  electronics.json.gz      3.0     348  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73b124ee-b5d7-429d-8471-2fed6880e1bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>real_label</th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "      <th>product_domain</th>\n",
              "      <th>overall</th>\n",
              "      <th>#words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>I have always been a fan of the Lewis and Clar...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>5.0</td>\n",
              "      <td>529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>I started reading this book during a three-wee...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>This cable is well-made and feels sturdier tha...</td>\n",
              "      <td>cell_phones_and_accessories.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>This kibble is expensive, but the cats like it...</td>\n",
              "      <td>pet_supplies.json.gz</td>\n",
              "      <td>5.0</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>This device is exactly what we needed for our ...</td>\n",
              "      <td>electronics.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>These beef hides are quite the treat.  I like ...</td>\n",
              "      <td>pet_supplies.json.gz</td>\n",
              "      <td>5.0</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>Reading this memoir was quite a surprise.  It ...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>Being a born Hoosier and having graduated from...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>4.0</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>This is a surprisingly good first novel.  Whil...</td>\n",
              "      <td>books.json.gz</td>\n",
              "      <td>5.0</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A11OTLEDSW8ZXD</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>My first impression of this lens was its weigh...</td>\n",
              "      <td>electronics.json.gz</td>\n",
              "      <td>3.0</td>\n",
              "      <td>348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73b124ee-b5d7-429d-8471-2fed6880e1bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73b124ee-b5d7-429d-8471-2fed6880e1bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73b124ee-b5d7-429d-8471-2fed6880e1bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset=pd.read_csv(\"/content/drive/MyDrive/ASU/train.csv\")\n",
        "dataset.head(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9pq-A70gfgG",
        "outputId": "5c5416ce-3214-4564-8cbc-a1175b460619"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(dataset.real_label.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "F4xsb7Ingh-k",
        "outputId": "a11c9b1a-236f-4e24-aaaf-8415b676e319"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            author  label  review  product_domain  overall  #words\n",
              "real_label                                                        \n",
              "0              500    500     500             500      500     500\n",
              "1              500    500     500             500      500     500\n",
              "2              500    500     500             500      500     500\n",
              "3              500    500     500             500      500     500\n",
              "4              500    500     500             500      500     500\n",
              "...            ...    ...     ...             ...      ...     ...\n",
              "95             500    500     500             500      500     500\n",
              "96             500    500     500             500      500     500\n",
              "97             500    500     500             500      500     500\n",
              "98             500    500     500             500      500     500\n",
              "99             500    500     500             500      500     500\n",
              "\n",
              "[100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ce71a17-377f-4da7-972e-89001cdebcf7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>label</th>\n",
              "      <th>review</th>\n",
              "      <th>product_domain</th>\n",
              "      <th>overall</th>\n",
              "      <th>#words</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ce71a17-377f-4da7-972e-89001cdebcf7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ce71a17-377f-4da7-972e-89001cdebcf7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ce71a17-377f-4da7-972e-89001cdebcf7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset.groupby(by='real_label').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "59Iv1OIhgkPS",
        "outputId": "c1164d73-d5c1-4714-eed9-7e2ef8331fea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       real_label                                             review\n",
              "0              44  I have always been a fan of the Lewis and Clar...\n",
              "1              44  I started reading this book during a three-wee...\n",
              "2              44  This cable is well-made and feels sturdier tha...\n",
              "3              44  This kibble is expensive, but the cats like it...\n",
              "4              44  This device is exactly what we needed for our ...\n",
              "...           ...                                                ...\n",
              "49995          46  Dumbo is one of disney's most beloved and clas...\n",
              "49996          46  I haven't played anygood sport games yet and i...\n",
              "49997          46  This game is loads of fun, i really liked this...\n",
              "49998          46  Gabriel is one of the funniest comedians i've ...\n",
              "49999          46  red tails is about the tuskegee airforce men w...\n",
              "\n",
              "[50000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6395b6a9-fd8d-481d-9bcc-3c1d1a0dd0cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>I have always been a fan of the Lewis and Clar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>I started reading this book during a three-wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>This cable is well-made and feels sturdier tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>This kibble is expensive, but the cats like it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>This device is exactly what we needed for our ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>46</td>\n",
              "      <td>Dumbo is one of disney's most beloved and clas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>46</td>\n",
              "      <td>I haven't played anygood sport games yet and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>46</td>\n",
              "      <td>This game is loads of fun, i really liked this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>46</td>\n",
              "      <td>Gabriel is one of the funniest comedians i've ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>46</td>\n",
              "      <td>red tails is about the tuskegee airforce men w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6395b6a9-fd8d-481d-9bcc-3c1d1a0dd0cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6395b6a9-fd8d-481d-9bcc-3c1d1a0dd0cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6395b6a9-fd8d-481d-9bcc-3c1d1a0dd0cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset.loc[:,['real_label','review']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WSv4YScMgmb_"
      },
      "outputs": [],
      "source": [
        "import regex as re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "i9PWLkmpgoLo"
      },
      "outputs": [],
      "source": [
        "dataset['flag']=dataset.loc[:,['real_label','review']].apply(lambda x: re.match(\"UPDATE*\",x['review']),axis=1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-AEvb1-ogpxk"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ocljhqeCgrKx"
      },
      "outputs": [],
      "source": [
        "#removing updated records\n",
        "\n",
        "dataset_filtered=dataset.loc[:,['real_label','review','flag']].loc[dataset['flag'].isin([None])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yGEU0z_wgs_h"
      },
      "outputs": [],
      "source": [
        "dataset_filtered.drop('flag',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0hcdDVPvgujd",
        "outputId": "03220554-2e79-4ce1-c2f8-f33d146a7b6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       real_label                                             review  \\\n",
              "450            44  <div id=\"video-block-R2SQB0OUB1NBH5\" class=\"a-...   \n",
              "2809            0  <div id=\"video-block-R1VMY3B2ETH5QP\" class=\"a-...   \n",
              "2821            0  <div id=\"video-block-R3NJKKD6S2WID6\" class=\"a-...   \n",
              "2952            0  <div id=\"video-block-R33S0CYT44UQX1\" class=\"a-...   \n",
              "2970            0  <div id=\"video-block-R5L2E0WNGPMI7\" class=\"a-s...   \n",
              "...           ...                                                ...   \n",
              "44995          40  <div id=\"video-block-R1R0HO8E534KBL\" class=\"a-...   \n",
              "44996          40  <div id=\"video-block-R1ZAATOSO22JSK\" class=\"a-...   \n",
              "44999          40  <div id=\"video-block-R306912UZ65A6Y\" class=\"a-...   \n",
              "45555          69  <div id=\"video-block-R2NVHO9ID4JNHG\" class=\"a-...   \n",
              "45636          69  <div id=\"video-block-R13GXJJWLY7JN2\" class=\"a-...   \n",
              "\n",
              "                                                  flag  \n",
              "450    <regex.Match object; span=(0, 4), match='<div'>  \n",
              "2809   <regex.Match object; span=(0, 4), match='<div'>  \n",
              "2821   <regex.Match object; span=(0, 4), match='<div'>  \n",
              "2952   <regex.Match object; span=(0, 4), match='<div'>  \n",
              "2970   <regex.Match object; span=(0, 4), match='<div'>  \n",
              "...                                                ...  \n",
              "44995  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "44996  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "44999  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "45555  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "45636  <regex.Match object; span=(0, 4), match='<div'>  \n",
              "\n",
              "[719 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ee742ea-e3e4-416c-99c3-e25945916629\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>44</td>\n",
              "      <td>&lt;div id=\"video-block-R2SQB0OUB1NBH5\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2809</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;div id=\"video-block-R1VMY3B2ETH5QP\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2821</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;div id=\"video-block-R3NJKKD6S2WID6\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2952</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;div id=\"video-block-R33S0CYT44UQX1\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2970</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;div id=\"video-block-R5L2E0WNGPMI7\" class=\"a-s...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44995</th>\n",
              "      <td>40</td>\n",
              "      <td>&lt;div id=\"video-block-R1R0HO8E534KBL\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44996</th>\n",
              "      <td>40</td>\n",
              "      <td>&lt;div id=\"video-block-R1ZAATOSO22JSK\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44999</th>\n",
              "      <td>40</td>\n",
              "      <td>&lt;div id=\"video-block-R306912UZ65A6Y\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45555</th>\n",
              "      <td>69</td>\n",
              "      <td>&lt;div id=\"video-block-R2NVHO9ID4JNHG\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45636</th>\n",
              "      <td>69</td>\n",
              "      <td>&lt;div id=\"video-block-R13GXJJWLY7JN2\" class=\"a-...</td>\n",
              "      <td>&lt;regex.Match object; span=(0, 4), match='&lt;div'&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>719 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ee742ea-e3e4-416c-99c3-e25945916629')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ee742ea-e3e4-416c-99c3-e25945916629 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ee742ea-e3e4-416c-99c3-e25945916629');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset_filtered['flag']=dataset_filtered.loc[:,['real_label','review']].apply(lambda x: re.match(\"<div*\",x['review']),axis=1 )\n",
        "dataset_filtered.loc[:,['real_label','review','flag']].loc[~dataset_filtered['flag'].isin([None])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "dzYeq9Pcgv-Y",
        "outputId": "f01f026b-1593-4bd8-8eef-eaefe5a5420d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            review  flag\n",
              "real_label              \n",
              "0                4     4\n",
              "1                1     1\n",
              "5                1     1\n",
              "7              178   178\n",
              "8                1     1\n",
              "9               35    35\n",
              "10              22    22\n",
              "14               3     3\n",
              "16             170   170\n",
              "17               1     1\n",
              "32               1     1\n",
              "34              58    58\n",
              "39              10    10\n",
              "40             139   139\n",
              "44               1     1\n",
              "45               1     1\n",
              "51              72    72\n",
              "53               9     9\n",
              "61               9     9\n",
              "69               2     2\n",
              "96               1     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b838f0d2-67dc-4d8c-8711-0123a9a2a725\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real_label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>178</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>139</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b838f0d2-67dc-4d8c-8711-0123a9a2a725')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b838f0d2-67dc-4d8c-8711-0123a9a2a725 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b838f0d2-67dc-4d8c-8711-0123a9a2a725');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dataset_filtered.loc[:,['real_label','review','flag']].loc[~dataset_filtered['flag'].isin([None])].groupby('real_label').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4WcMNZCDgx7c"
      },
      "outputs": [],
      "source": [
        "dataset_filtered.drop('flag',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_GWJsLH5hE4a",
        "outputId": "246711ab-1254-48cb-b491-4037566c2c0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   real_label                                             review\n",
              "0          44  I have always been a fan of the Lewis and Clar...\n",
              "1          44  I started reading this book during a three-wee...\n",
              "2          44  This cable is well-made and feels sturdier tha...\n",
              "3          44  This kibble is expensive, but the cats like it...\n",
              "4          44  This device is exactly what we needed for our ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d306124c-cc2d-4dbc-8965-26a0a0aca362\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>I have always been a fan of the Lewis and Clar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>I started reading this book during a three-wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>This cable is well-made and feels sturdier tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>This kibble is expensive, but the cats like it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>This device is exactly what we needed for our ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d306124c-cc2d-4dbc-8965-26a0a0aca362')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d306124c-cc2d-4dbc-8965-26a0a0aca362 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d306124c-cc2d-4dbc-8965-26a0a0aca362');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "dataset_filtered.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "tWeBPDesiKXr",
        "outputId": "3ce7c189-3ee8-4fb2-98f6-19332fde2d80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            review\n",
              "real_label        \n",
              "0              497\n",
              "1              500\n",
              "2              500\n",
              "3              500\n",
              "4              500\n",
              "...            ...\n",
              "95             500\n",
              "96             500\n",
              "97             500\n",
              "98             500\n",
              "99             500\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbac31fc-6245-48f7-ae81-2a46e4311184\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbac31fc-6245-48f7-ae81-2a46e4311184')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbac31fc-6245-48f7-ae81-2a46e4311184 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbac31fc-6245-48f7-ae81-2a46e4311184');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "dataset_filtered.groupby('real_label').count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Input dataset\n",
        "dataset_filtered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jYLP4SFw4JoF",
        "outputId": "5acb79d2-f040-44ec-be50-81f6c279cb5c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       real_label                                             review\n",
              "0              44  I have always been a fan of the Lewis and Clar...\n",
              "1              44  I started reading this book during a three-wee...\n",
              "2              44  This cable is well-made and feels sturdier tha...\n",
              "3              44  This kibble is expensive, but the cats like it...\n",
              "4              44  This device is exactly what we needed for our ...\n",
              "...           ...                                                ...\n",
              "49995          46  Dumbo is one of disney's most beloved and clas...\n",
              "49996          46  I haven't played anygood sport games yet and i...\n",
              "49997          46  This game is loads of fun, i really liked this...\n",
              "49998          46  Gabriel is one of the funniest comedians i've ...\n",
              "49999          46  red tails is about the tuskegee airforce men w...\n",
              "\n",
              "[49967 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82f19c08-0b79-4d35-9710-3a292b44855f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>I have always been a fan of the Lewis and Clar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>I started reading this book during a three-wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>This cable is well-made and feels sturdier tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>This kibble is expensive, but the cats like it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>This device is exactly what we needed for our ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>46</td>\n",
              "      <td>Dumbo is one of disney's most beloved and clas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>46</td>\n",
              "      <td>I haven't played anygood sport games yet and i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>46</td>\n",
              "      <td>This game is loads of fun, i really liked this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>46</td>\n",
              "      <td>Gabriel is one of the funniest comedians i've ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>46</td>\n",
              "      <td>red tails is about the tuskegee airforce men w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49967 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82f19c08-0b79-4d35-9710-3a292b44855f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82f19c08-0b79-4d35-9710-3a292b44855f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82f19c08-0b79-4d35-9710-3a292b44855f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "918jkbVoh_Y1",
        "outputId": "60e33c33-39f1-494f-d761-e86968549455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    n_gpu=torch.cuda.device_count()\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy-HBiXjiE1g",
        "outputId": "518fbee2-7bac-4c90-e373-1a513cda9cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 25.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer,BertTokenizer, AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\"\"\"\n",
        "# Load the tokenizer.\n",
        "print('Loading Roberta tokenizer...')\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\"\"\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "config = AutoConfig.from_pretrained('bert-base-uncased',\n",
        "                                            num_labels=101,\n",
        "                                            hidden_dropout_prob=0.15)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "d8fbab10f1994b229063ab13728a4eab",
            "c913df38dfa349788aef3210a050e76f",
            "1a637a97a2ef433f90c61569666f974d",
            "bf9ed46215d64729ae3e1e4c89936018",
            "3c94452b1e9f49e2a6ef8e2204e75f17",
            "b6477d9145ec4642a15306c42fb0e5b8",
            "12298742368944748ec6235c30aa6de9",
            "ff12dd166db44dd9b3e1fc0e69d2caca",
            "fc90d23c6cfb459d9052bcca9c6181cb",
            "6adc7d4defd84636bcbcee7e18f26e6d",
            "cb59bddd00e8413d9b1895c691e11a10",
            "61703f7d98514dd4a98bbcf20a6b1490",
            "0c5b0405910242ea9e2702988ed24610",
            "16a77a29059d4b3aafaef293fac589c4",
            "b35e1f19aa6946ab84f5a8beba21701f",
            "6148c5c2aa134daebccf557542087c7e",
            "57ba7b537afb4b0da88186e83d48537d",
            "061add92a441496486919713329df6bb",
            "ca41315e98974e09b87f37a2178d078e",
            "c3ba42d3e272456fa076eda69178d850",
            "a616558029b34f9dabf2d4cdfa112304",
            "c17b1349d1ce46f0955877d601ba29f2",
            "c10843fd97e946049c331463734769a3",
            "22fc2296b6a445cab503133e93f39937",
            "f4df45341a9d49498ed222a60c530f5a",
            "3502771957a947a9b9c1e1d574133b88",
            "3efc247cea7341d09ef54d284bd6f7a4",
            "ae6806c486344f49b970fea14d38b9f0",
            "2f7daa84a85e48cea2d4f01f12cc1c5b",
            "1a187bad5424481685e850cde19b256e",
            "299c2db1a7af431fa4f964af5c0a28ac",
            "f20c4aeef26f43b7bd00467225031cc7",
            "b06d2f8668964ab6b88fc7bb2f72d8d5",
            "94f5ad04cdaa47e49dcda39850daf905",
            "ae42439fdd244ce4b55442874171930b",
            "24f1eaab6af64b33bd7b849ed24a7920",
            "74711b55307b4a3c91d45ec876999c93",
            "97223a35fd7241caab91a16046f146bb",
            "6ffb82895ce3495cbc087c446ee12ce3",
            "e6edb509beda4729bafdcc0b4c4ace7b",
            "58b94c1de4ee4e758675e80c4406a7bc",
            "f2a54883c72a4d75bf52dd252c59180d",
            "d04877f1877246ffabc5754bb3934928",
            "e76e1ad512764a1292a07a70e58e95cf"
          ]
        },
        "id": "6BZYtNIG-YG9",
        "outputId": "0f774b1d-4288-473b-9c80-82c88cb5713b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8fbab10f1994b229063ab13728a4eab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61703f7d98514dd4a98bbcf20a6b1490"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c10843fd97e946049c331463734769a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94f5ad04cdaa47e49dcda39850daf905"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import BertTokenizer, AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/ASU/model_save/'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir+'tokenizer/')\n",
        "model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
        "\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-71E7Ju8Kfdr",
        "outputId": "bc7f948f-5961-46a5-eab5-6449ae0166aa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.15, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.15, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=101, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1qImgeyib35",
        "outputId": "e123b546-fde2-4aa9-e8d7-72997ca10b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length in training data:  7283\n"
          ]
        }
      ],
      "source": [
        "#Max length\n",
        "\n",
        "max_len = 0\n",
        "len_list=[]\n",
        "# For every sentence...\n",
        "for r in dataset_filtered.values:\n",
        "    #print(r)\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(r[1], add_special_tokens=True)\n",
        "    len_list.append([r[0],len(input_ids)])\n",
        "    \n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length in training data: ', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YjNFmPYLisgM"
      },
      "outputs": [],
      "source": [
        "len_df=pd.DataFrame(len_list)\n",
        "len_df.columns=['Lable','str_len']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_df.loc[len_df['str_len'].values>2000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VxoSNUV48EeU",
        "outputId": "47628de7-e1ea-4142-dff7-63045cc83440"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Lable  str_len\n",
              "1021      55     2262\n",
              "1092      55     2288\n",
              "1143      55     2458\n",
              "1155      55     2412\n",
              "1168      55     2003\n",
              "...      ...      ...\n",
              "47926     75     3025\n",
              "47932     75     2318\n",
              "47960     75     2108\n",
              "47961     75     2543\n",
              "47964     75     2057\n",
              "\n",
              "[206 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11db5e34-5e27-4faf-a3f8-85952e1ecbb3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lable</th>\n",
              "      <th>str_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>55</td>\n",
              "      <td>2262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>55</td>\n",
              "      <td>2288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1143</th>\n",
              "      <td>55</td>\n",
              "      <td>2458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1155</th>\n",
              "      <td>55</td>\n",
              "      <td>2412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1168</th>\n",
              "      <td>55</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47926</th>\n",
              "      <td>75</td>\n",
              "      <td>3025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47932</th>\n",
              "      <td>75</td>\n",
              "      <td>2318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47960</th>\n",
              "      <td>75</td>\n",
              "      <td>2108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47961</th>\n",
              "      <td>75</td>\n",
              "      <td>2543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47964</th>\n",
              "      <td>75</td>\n",
              "      <td>2057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>206 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11db5e34-5e27-4faf-a3f8-85952e1ecbb3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11db5e34-5e27-4faf-a3f8-85952e1ecbb3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11db5e34-5e27-4faf-a3f8-85952e1ecbb3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "XvMsVBbAlo85",
        "outputId": "4d7d1659-c886-4975-9c9b-e900e25d8321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49967\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       str_len\n",
              "Lable         \n",
              "0          497\n",
              "1          500\n",
              "2          500\n",
              "3          500\n",
              "4          500\n",
              "...        ...\n",
              "95         500\n",
              "96         500\n",
              "97         500\n",
              "98         500\n",
              "99         500\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-137d36e1-e582-4291-9b2d-5d549c1affa9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>str_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lable</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-137d36e1-e582-4291-9b2d-5d549c1affa9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-137d36e1-e582-4291-9b2d-5d549c1affa9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-137d36e1-e582-4291-9b2d-5d549c1affa9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "print(len(len_df))\n",
        "len_df.groupby('Lable').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "obu05H4dmKtC",
        "outputId": "5dac75e8-f988-41ec-90c2-af51387e3b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39473\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       str_len\n",
              "Lable         \n",
              "0          476\n",
              "1          496\n",
              "2          487\n",
              "3          242\n",
              "4          472\n",
              "...        ...\n",
              "95         494\n",
              "96         500\n",
              "97         322\n",
              "98         159\n",
              "99         364\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-395b7ca9-f432-495c-9c20-6510ad93441b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>str_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lable</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-395b7ca9-f432-495c-9c20-6510ad93441b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-395b7ca9-f432-495c-9c20-6510ad93441b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-395b7ca9-f432-495c-9c20-6510ad93441b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len_df_filtered=len_df.loc[len_df['str_len'].values<=512]\n",
        "print(len(len_df_filtered))\n",
        "len_df_filtered.groupby('Lable').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "B19CR8NUnkOA"
      },
      "outputs": [],
      "source": [
        "dataset_filtered['num_sentences']=dataset_filtered.apply(lambda x:len(x.values[1].split('\\n')),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKUsJTzQ1MHm",
        "outputId": "04348109-15e1-4b38-dda8-12506521b0f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "np.percentile(dataset_filtered.num_sentences.values,95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "caLOP-mt10ru",
        "outputId": "6c823ced-5659-4e2d-93db-d59e3904350d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       real_label                                             review  \\\n",
              "3021           43  With HOLLYWOOD CLASSICS 100 MOVIE PACK, MILL C...   \n",
              "3023           43  Based on current polling numbers at a film res...   \n",
              "3062           43  The majority of films in the ACTION CLASSICS 5...   \n",
              "3183           43  WESTERN CLASSICS 100 MOVIE PACK is a set of 24...   \n",
              "3361           43  The CRIME CLASSICS 50 MOVIE PACK has one film ...   \n",
              "4789           68  Book #5 in the action-adventure series first p...   \n",
              "10224           7  <div id=\"video-block-R2SS5UEOOTKZG1\" class=\"a-...   \n",
              "11119          91  With many books, translations are negligible, ...   \n",
              "14002          74  Obama's Wars by Bob Woodward\\nSimon and Schust...   \n",
              "14025          74  The Baby Boomer Generation will be the new\\n\"T...   \n",
              "14063          74  Turbo Charged- Accelerate Your Fat Burning Met...   \n",
              "14124          74  Visions of the Multiverse\\nIs Our Universe One...   \n",
              "14146          74  The author's main point is that vaccines can\\n...   \n",
              "14388          74  The author's main thesis is that the seas have...   \n",
              "14441          74  Biofuels Engineering Process Technology by Dra...   \n",
              "14497          74  Super Body Super Brain- The Workout That Does ...   \n",
              "19033          16  I purchased Samsun Galaxy 7.7 with Prepaid mon...   \n",
              "19094          16  I am an experienced knitter who has made dozen...   \n",
              "19128          16  \"Life's little emergencies\" is a reference wri...   \n",
              "19299          16  All recipes in this book have a few things in ...   \n",
              "19383          16  <div id=\"video-block-RJZQTRRL40LXO\" class=\"a-s...   \n",
              "19583          15  Jean Vigo...the man who influenced the French ...   \n",
              "19599          15  Whit Stillman, the director who brought us \"Me...   \n",
              "19603          15  When it comes to the \"Star Trek\" films, some r...   \n",
              "19635          15  With Walt Disney's \"Zorro\" popular television ...   \n",
              "19712          15  For six years, \"Daria\" was a popular animated ...   \n",
              "19756          15  Back in 1961, one of the popular comedy shows ...   \n",
              "19800          15  With the announcement that \"90210', based on t...   \n",
              "19802          15  Back in 1982, the sci-fi Disney film \"Tron\" ca...   \n",
              "19808          15  Filmmaker Jacques Tati has inspired many peopl...   \n",
              "19832          15  One of the most fascinating and also important...   \n",
              "19894          15  Based on the popular manga and anime series th...   \n",
              "19958          15  Throughout the life of young pervert Tomoki Sa...   \n",
              "19980          15  Whenever there is an art heist, there is one w...   \n",
              "20151          26  This review will have a two-part format. In th...   \n",
              "20165          26  This review will have a two-part format. In th...   \n",
              "20170          26  Please note: This review is going to be quite ...   \n",
              "20407          26  This review will have a two-part format. In th...   \n",
              "25687          12  When I was young, I watched \"The Wizard of Oz\"...   \n",
              "42079          51  Anyone can file for Social Security Disability...   \n",
              "42154          51  Things have come a long way since we simply ad...   \n",
              "42186          51  <div id=\"video-block-R2HOIF5I4Y5VQN\" class=\"a-...   \n",
              "42286          51  Most iPad users I know are self-taught.  I kno...   \n",
              "42296          51  I have questions, lots of questions about Soci...   \n",
              "42367          51  One of the more interesting facets of supply c...   \n",
              "42393          51  The Kocaso has a gesture-based lock screen. If...   \n",
              "46638          90  I loved DS9. I didn't realize how much I'd lov...   \n",
              "49760          46  Angel is a awesome show and here are the best ...   \n",
              "49778          46  This is a awesome show probably one of the bes...   \n",
              "49853          46  Great seasons here is the best episodes for ea...   \n",
              "\n",
              "       num_sentences  \n",
              "3021             207  \n",
              "3023             105  \n",
              "3062             105  \n",
              "3183             106  \n",
              "3361             109  \n",
              "4789             102  \n",
              "10224            114  \n",
              "11119            169  \n",
              "14002            147  \n",
              "14025            113  \n",
              "14063            110  \n",
              "14124            104  \n",
              "14146            186  \n",
              "14388            109  \n",
              "14441            146  \n",
              "14497            164  \n",
              "19033            105  \n",
              "19094            122  \n",
              "19128            228  \n",
              "19299            119  \n",
              "19383            126  \n",
              "19583            117  \n",
              "19599            103  \n",
              "19603            155  \n",
              "19635            104  \n",
              "19712            133  \n",
              "19756            103  \n",
              "19800            156  \n",
              "19802            113  \n",
              "19808            104  \n",
              "19832            110  \n",
              "19894            119  \n",
              "19958            101  \n",
              "19980            107  \n",
              "20151            135  \n",
              "20165            131  \n",
              "20170            145  \n",
              "20407            115  \n",
              "25687            108  \n",
              "42079            220  \n",
              "42154            184  \n",
              "42186            157  \n",
              "42286            335  \n",
              "42296            144  \n",
              "42367            267  \n",
              "42393            105  \n",
              "46638            215  \n",
              "49760            124  \n",
              "49778            106  \n",
              "49853            104  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d59fe042-a1c8-4a9c-8c39-f2722e7ca162\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "      <th>num_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3021</th>\n",
              "      <td>43</td>\n",
              "      <td>With HOLLYWOOD CLASSICS 100 MOVIE PACK, MILL C...</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3023</th>\n",
              "      <td>43</td>\n",
              "      <td>Based on current polling numbers at a film res...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3062</th>\n",
              "      <td>43</td>\n",
              "      <td>The majority of films in the ACTION CLASSICS 5...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3183</th>\n",
              "      <td>43</td>\n",
              "      <td>WESTERN CLASSICS 100 MOVIE PACK is a set of 24...</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3361</th>\n",
              "      <td>43</td>\n",
              "      <td>The CRIME CLASSICS 50 MOVIE PACK has one film ...</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4789</th>\n",
              "      <td>68</td>\n",
              "      <td>Book #5 in the action-adventure series first p...</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10224</th>\n",
              "      <td>7</td>\n",
              "      <td>&lt;div id=\"video-block-R2SS5UEOOTKZG1\" class=\"a-...</td>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11119</th>\n",
              "      <td>91</td>\n",
              "      <td>With many books, translations are negligible, ...</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14002</th>\n",
              "      <td>74</td>\n",
              "      <td>Obama's Wars by Bob Woodward\\nSimon and Schust...</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14025</th>\n",
              "      <td>74</td>\n",
              "      <td>The Baby Boomer Generation will be the new\\n\"T...</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14063</th>\n",
              "      <td>74</td>\n",
              "      <td>Turbo Charged- Accelerate Your Fat Burning Met...</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14124</th>\n",
              "      <td>74</td>\n",
              "      <td>Visions of the Multiverse\\nIs Our Universe One...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14146</th>\n",
              "      <td>74</td>\n",
              "      <td>The author's main point is that vaccines can\\n...</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14388</th>\n",
              "      <td>74</td>\n",
              "      <td>The author's main thesis is that the seas have...</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14441</th>\n",
              "      <td>74</td>\n",
              "      <td>Biofuels Engineering Process Technology by Dra...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14497</th>\n",
              "      <td>74</td>\n",
              "      <td>Super Body Super Brain- The Workout That Does ...</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19033</th>\n",
              "      <td>16</td>\n",
              "      <td>I purchased Samsun Galaxy 7.7 with Prepaid mon...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19094</th>\n",
              "      <td>16</td>\n",
              "      <td>I am an experienced knitter who has made dozen...</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19128</th>\n",
              "      <td>16</td>\n",
              "      <td>\"Life's little emergencies\" is a reference wri...</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19299</th>\n",
              "      <td>16</td>\n",
              "      <td>All recipes in this book have a few things in ...</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19383</th>\n",
              "      <td>16</td>\n",
              "      <td>&lt;div id=\"video-block-RJZQTRRL40LXO\" class=\"a-s...</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19583</th>\n",
              "      <td>15</td>\n",
              "      <td>Jean Vigo...the man who influenced the French ...</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19599</th>\n",
              "      <td>15</td>\n",
              "      <td>Whit Stillman, the director who brought us \"Me...</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19603</th>\n",
              "      <td>15</td>\n",
              "      <td>When it comes to the \"Star Trek\" films, some r...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19635</th>\n",
              "      <td>15</td>\n",
              "      <td>With Walt Disney's \"Zorro\" popular television ...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19712</th>\n",
              "      <td>15</td>\n",
              "      <td>For six years, \"Daria\" was a popular animated ...</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19756</th>\n",
              "      <td>15</td>\n",
              "      <td>Back in 1961, one of the popular comedy shows ...</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19800</th>\n",
              "      <td>15</td>\n",
              "      <td>With the announcement that \"90210', based on t...</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19802</th>\n",
              "      <td>15</td>\n",
              "      <td>Back in 1982, the sci-fi Disney film \"Tron\" ca...</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19808</th>\n",
              "      <td>15</td>\n",
              "      <td>Filmmaker Jacques Tati has inspired many peopl...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19832</th>\n",
              "      <td>15</td>\n",
              "      <td>One of the most fascinating and also important...</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19894</th>\n",
              "      <td>15</td>\n",
              "      <td>Based on the popular manga and anime series th...</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19958</th>\n",
              "      <td>15</td>\n",
              "      <td>Throughout the life of young pervert Tomoki Sa...</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19980</th>\n",
              "      <td>15</td>\n",
              "      <td>Whenever there is an art heist, there is one w...</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20151</th>\n",
              "      <td>26</td>\n",
              "      <td>This review will have a two-part format. In th...</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20165</th>\n",
              "      <td>26</td>\n",
              "      <td>This review will have a two-part format. In th...</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20170</th>\n",
              "      <td>26</td>\n",
              "      <td>Please note: This review is going to be quite ...</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20407</th>\n",
              "      <td>26</td>\n",
              "      <td>This review will have a two-part format. In th...</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25687</th>\n",
              "      <td>12</td>\n",
              "      <td>When I was young, I watched \"The Wizard of Oz\"...</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42079</th>\n",
              "      <td>51</td>\n",
              "      <td>Anyone can file for Social Security Disability...</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42154</th>\n",
              "      <td>51</td>\n",
              "      <td>Things have come a long way since we simply ad...</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42186</th>\n",
              "      <td>51</td>\n",
              "      <td>&lt;div id=\"video-block-R2HOIF5I4Y5VQN\" class=\"a-...</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42286</th>\n",
              "      <td>51</td>\n",
              "      <td>Most iPad users I know are self-taught.  I kno...</td>\n",
              "      <td>335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42296</th>\n",
              "      <td>51</td>\n",
              "      <td>I have questions, lots of questions about Soci...</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42367</th>\n",
              "      <td>51</td>\n",
              "      <td>One of the more interesting facets of supply c...</td>\n",
              "      <td>267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42393</th>\n",
              "      <td>51</td>\n",
              "      <td>The Kocaso has a gesture-based lock screen. If...</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46638</th>\n",
              "      <td>90</td>\n",
              "      <td>I loved DS9. I didn't realize how much I'd lov...</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49760</th>\n",
              "      <td>46</td>\n",
              "      <td>Angel is a awesome show and here are the best ...</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49778</th>\n",
              "      <td>46</td>\n",
              "      <td>This is a awesome show probably one of the bes...</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49853</th>\n",
              "      <td>46</td>\n",
              "      <td>Great seasons here is the best episodes for ea...</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d59fe042-a1c8-4a9c-8c39-f2722e7ca162')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d59fe042-a1c8-4a9c-8c39-f2722e7ca162 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d59fe042-a1c8-4a9c-8c39-f2722e7ca162');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "dataset_filtered.loc[dataset_filtered['num_sentences']>100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzg99yNARt7Q",
        "outputId": "92644d32-f380-4aa9-de53-1da6c7c5ecdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['real_label', 'review', 'num_sentences'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "dataset_filtered.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TJH5YBtl2TOY"
      },
      "outputs": [],
      "source": [
        "labels = dataset_filtered.real_label.values\n",
        "sentences=dataset_filtered.review.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(dataset_filtered.real_label.values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI8AQwQo9hYz",
        "outputId": "a211779d-0751-4404-e273-515f2ed215f1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "pvL9x0Nz9IA7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labels = torch.nn.functional.one_hot(labels, num_classes = 100).to(torch.float)\n",
        "#print(labels)"
      ],
      "metadata": {
        "id": "oNK487VO9Ms9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8csXCK7-eXp",
        "outputId": "22808099-e32c-4060-fab4-607791b0b49a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  I have always been a fan of the Lewis and Clark (L&C) expedition and have read numerous books on that era.  I even road tripped along the Missouri River to the river's source in Montana (bypassing North Dakota and eastern Montana due to repeated tornadoes that summer), stopping along all the historical signs.  I'm a fan because I understand the courage it took to explore unknown lands with potential violent inhabitants, but I also understand the significance of American expansion to the Pacific via the Northwest passage.  Opening up these lands is one of Jefferson's biggest legacies as president.\n",
            "\n",
            "What Julie Fenster does here is not just summarize the L&C expedition, though.  She describes the young America at the turn of the 19th century.  Pioneers were moving westward, but Spain controlled the western lands. She gives short biographies of the players, the governors, kings and explorers of the era.  It was a time of great hostilities.  Fenster portrays Jefferson as a man fighting off the John Adams supporters; all was not going so well for Jefferson when he first became president.\n",
            "\n",
            "What readers get out of this very readable account is that the L&C expedition was not the only expedition going on at the time.  It's interesting to note that there were other courageous explorers willing to report back to Jefferson what the Spanish-held lands were like, and Fenster describes these in relation to the L&C expedition  The Hunter & Dunbar expedition was as valuable to Jefferson as the L&C one was, or the oft-plagued expedition of Zebulon Pike, or the courage of Thomas Freeman or Peter Custis.  All these men deserve their fifteen minutes of fame, and Fenster delivers a fast-paced narrative to tell the more complete story of a young America restless to explore and dominate its western boundaries.  If it hadn't been for the expense of the Napoleonic wars in western Europe, France and Spain may have had different visions of their mission in the New World.\n",
            "\n",
            "For those who are well-versed in the L&C expedition, it's well-known among those scholars that Lewis and Clark were not the first white men to traverse\n",
            "the Missouri River.  There were many French trappers and a few lone Spaniards who had made contact with the native tribes, and who unknowingly spread communicable diseases to these vulnerable people and decimated entire villages.  Fenster tries to bring this into perspective here, as L&C did not meet any hostile natives until they came among the Mandan.  Entire villages south of them were abandoned due to diseases the white settlers had brought to the region.\n",
            "\n",
            "This is a very readable narrative of Jefferson's goal to get the western lands explored.  There are a lot of names dropped early on to give the curious reader a perspective.  Spain and the young United States almost went to war over the status of New Orleans and the Louisiana territory, but the Napoleonic wars sidetracked the kings in Europe.  Many of the explorers in this book fall along the wayside in American history, but Fenster gives credit to all these men and help the history buff see that L&C were not the only expedition exploring unchartered waters.\n",
            "Tokenized:  ['i', 'have', 'always', 'been', 'a', 'fan', 'of', 'the', 'lewis', 'and', 'clark', '(', 'l', '&', 'c', ')', 'expedition', 'and', 'have', 'read', 'numerous', 'books', 'on', 'that', 'era', '.', 'i', 'even', 'road', 'tripped', 'along', 'the', 'missouri', 'river', 'to', 'the', 'river', \"'\", 's', 'source', 'in', 'montana', '(', 'bypass', '##ing', 'north', 'dakota', 'and', 'eastern', 'montana', 'due', 'to', 'repeated', 'tornadoes', 'that', 'summer', ')', ',', 'stopping', 'along', 'all', 'the', 'historical', 'signs', '.', 'i', \"'\", 'm', 'a', 'fan', 'because', 'i', 'understand', 'the', 'courage', 'it', 'took', 'to', 'explore', 'unknown', 'lands', 'with', 'potential', 'violent', 'inhabitants', ',', 'but', 'i', 'also', 'understand', 'the', 'significance', 'of', 'american', 'expansion', 'to', 'the', 'pacific', 'via', 'the', 'northwest', 'passage', '.', 'opening', 'up', 'these', 'lands', 'is', 'one', 'of', 'jefferson', \"'\", 's', 'biggest', 'leg', '##acies', 'as', 'president', '.', 'what', 'julie', 'fen', '##ster', 'does', 'here', 'is', 'not', 'just', 'sum', '##mar', '##ize', 'the', 'l', '&', 'c', 'expedition', ',', 'though', '.', 'she', 'describes', 'the', 'young', 'america', 'at', 'the', 'turn', 'of', 'the', '19th', 'century', '.', 'pioneers', 'were', 'moving', 'westward', ',', 'but', 'spain', 'controlled', 'the', 'western', 'lands', '.', 'she', 'gives', 'short', 'biographies', 'of', 'the', 'players', ',', 'the', 'governors', ',', 'kings', 'and', 'explorers', 'of', 'the', 'era', '.', 'it', 'was', 'a', 'time', 'of', 'great', 'hostilities', '.', 'fen', '##ster', 'portrays', 'jefferson', 'as', 'a', 'man', 'fighting', 'off', 'the', 'john', 'adams', 'supporters', ';', 'all', 'was', 'not', 'going', 'so', 'well', 'for', 'jefferson', 'when', 'he', 'first', 'became', 'president', '.', 'what', 'readers', 'get', 'out', 'of', 'this', 'very', 'read', '##able', 'account', 'is', 'that', 'the', 'l', '&', 'c', 'expedition', 'was', 'not', 'the', 'only', 'expedition', 'going', 'on', 'at', 'the', 'time', '.', 'it', \"'\", 's', 'interesting', 'to', 'note', 'that', 'there', 'were', 'other', 'courageous', 'explorers', 'willing', 'to', 'report', 'back', 'to', 'jefferson', 'what', 'the', 'spanish', '-', 'held', 'lands', 'were', 'like', ',', 'and', 'fen', '##ster', 'describes', 'these', 'in', 'relation', 'to', 'the', 'l', '&', 'c', 'expedition', 'the', 'hunter', '&', 'dunbar', 'expedition', 'was', 'as', 'valuable', 'to', 'jefferson', 'as', 'the', 'l', '&', 'c', 'one', 'was', ',', 'or', 'the', 'of', '##t', '-', 'plagued', 'expedition', 'of', 'ze', '##bu', '##lon', 'pike', ',', 'or', 'the', 'courage', 'of', 'thomas', 'freeman', 'or', 'peter', 'cu', '##stis', '.', 'all', 'these', 'men', 'deserve', 'their', 'fifteen', 'minutes', 'of', 'fame', ',', 'and', 'fen', '##ster', 'delivers', 'a', 'fast', '-', 'paced', 'narrative', 'to', 'tell', 'the', 'more', 'complete', 'story', 'of', 'a', 'young', 'america', 'restless', 'to', 'explore', 'and', 'dominate', 'its', 'western', 'boundaries', '.', 'if', 'it', 'hadn', \"'\", 't', 'been', 'for', 'the', 'expense', 'of', 'the', 'napoleonic', 'wars', 'in', 'western', 'europe', ',', 'france', 'and', 'spain', 'may', 'have', 'had', 'different', 'visions', 'of', 'their', 'mission', 'in', 'the', 'new', 'world', '.', 'for', 'those', 'who', 'are', 'well', '-', 'verse', '##d', 'in', 'the', 'l', '&', 'c', 'expedition', ',', 'it', \"'\", 's', 'well', '-', 'known', 'among', 'those', 'scholars', 'that', 'lewis', 'and', 'clark', 'were', 'not', 'the', 'first', 'white', 'men', 'to', 'traverse', 'the', 'missouri', 'river', '.', 'there', 'were', 'many', 'french', 'trap', '##pers', 'and', 'a', 'few', 'lone', 'spaniards', 'who', 'had', 'made', 'contact', 'with', 'the', 'native', 'tribes', ',', 'and', 'who', 'un', '##k', '##now', '##ingly', 'spread', 'com', '##mun', '##ica', '##ble', 'diseases', 'to', 'these', 'vulnerable', 'people', 'and', 'dec', '##imated', 'entire', 'villages', '.', 'fen', '##ster', 'tries', 'to', 'bring', 'this', 'into', 'perspective', 'here', ',', 'as', 'l', '&', 'c', 'did', 'not', 'meet', 'any', 'hostile', 'natives', 'until', 'they', 'came', 'among', 'the', 'man', '##dan', '.', 'entire', 'villages', 'south', 'of', 'them', 'were', 'abandoned', 'due', 'to', 'diseases', 'the', 'white', 'settlers', 'had', 'brought', 'to', 'the', 'region', '.', 'this', 'is', 'a', 'very', 'read', '##able', 'narrative', 'of', 'jefferson', \"'\", 's', 'goal', 'to', 'get', 'the', 'western', 'lands', 'explored', '.', 'there', 'are', 'a', 'lot', 'of', 'names', 'dropped', 'early', 'on', 'to', 'give', 'the', 'curious', 'reader', 'a', 'perspective', '.', 'spain', 'and', 'the', 'young', 'united', 'states', 'almost', 'went', 'to', 'war', 'over', 'the', 'status', 'of', 'new', 'orleans', 'and', 'the', 'louisiana', 'territory', ',', 'but', 'the', 'napoleonic', 'wars', 'side', '##tra', '##cked', 'the', 'kings', 'in', 'europe', '.', 'many', 'of', 'the', 'explorers', 'in', 'this', 'book', 'fall', 'along', 'the', 'ways', '##ide', 'in', 'american', 'history', ',', 'but', 'fen', '##ster', 'gives', 'credit', 'to', 'all', 'these', 'men', 'and', 'help', 'the', 'history', 'buff', 'see', 'that', 'l', '&', 'c', 'were', 'not', 'the', 'only', 'expedition', 'exploring', 'un', '##cha', '##rter', '##ed', 'waters', '.']\n",
            "Token IDs:  [1045, 2031, 2467, 2042, 1037, 5470, 1997, 1996, 4572, 1998, 5215, 1006, 1048, 1004, 1039, 1007, 5590, 1998, 2031, 3191, 3365, 2808, 2006, 2008, 3690, 1012, 1045, 2130, 2346, 21129, 2247, 1996, 5284, 2314, 2000, 1996, 2314, 1005, 1055, 3120, 1999, 8124, 1006, 11826, 2075, 2167, 7734, 1998, 2789, 8124, 2349, 2000, 5567, 22668, 2008, 2621, 1007, 1010, 7458, 2247, 2035, 1996, 3439, 5751, 1012, 1045, 1005, 1049, 1037, 5470, 2138, 1045, 3305, 1996, 8424, 2009, 2165, 2000, 8849, 4242, 4915, 2007, 4022, 6355, 4864, 1010, 2021, 1045, 2036, 3305, 1996, 7784, 1997, 2137, 4935, 2000, 1996, 3534, 3081, 1996, 4514, 6019, 1012, 3098, 2039, 2122, 4915, 2003, 2028, 1997, 7625, 1005, 1055, 5221, 4190, 20499, 2004, 2343, 1012, 2054, 7628, 21713, 6238, 2515, 2182, 2003, 2025, 2074, 7680, 7849, 4697, 1996, 1048, 1004, 1039, 5590, 1010, 2295, 1012, 2016, 5577, 1996, 2402, 2637, 2012, 1996, 2735, 1997, 1996, 3708, 2301, 1012, 13200, 2020, 3048, 15165, 1010, 2021, 3577, 4758, 1996, 2530, 4915, 1012, 2016, 3957, 2460, 22056, 1997, 1996, 2867, 1010, 1996, 11141, 1010, 5465, 1998, 19264, 1997, 1996, 3690, 1012, 2009, 2001, 1037, 2051, 1997, 2307, 17601, 1012, 21713, 6238, 17509, 7625, 2004, 1037, 2158, 3554, 2125, 1996, 2198, 5922, 6793, 1025, 2035, 2001, 2025, 2183, 2061, 2092, 2005, 7625, 2043, 2002, 2034, 2150, 2343, 1012, 2054, 8141, 2131, 2041, 1997, 2023, 2200, 3191, 3085, 4070, 2003, 2008, 1996, 1048, 1004, 1039, 5590, 2001, 2025, 1996, 2069, 5590, 2183, 2006, 2012, 1996, 2051, 1012, 2009, 1005, 1055, 5875, 2000, 3602, 2008, 2045, 2020, 2060, 26103, 19264, 5627, 2000, 3189, 2067, 2000, 7625, 2054, 1996, 3009, 1011, 2218, 4915, 2020, 2066, 1010, 1998, 21713, 6238, 5577, 2122, 1999, 7189, 2000, 1996, 1048, 1004, 1039, 5590, 1996, 4477, 1004, 23034, 5590, 2001, 2004, 7070, 2000, 7625, 2004, 1996, 1048, 1004, 1039, 2028, 2001, 1010, 2030, 1996, 1997, 2102, 1011, 17808, 5590, 1997, 27838, 8569, 7811, 12694, 1010, 2030, 1996, 8424, 1997, 2726, 11462, 2030, 2848, 12731, 29472, 1012, 2035, 2122, 2273, 10107, 2037, 5417, 2781, 1997, 4476, 1010, 1998, 21713, 6238, 18058, 1037, 3435, 1011, 13823, 7984, 2000, 2425, 1996, 2062, 3143, 2466, 1997, 1037, 2402, 2637, 15035, 2000, 8849, 1998, 16083, 2049, 2530, 7372, 1012, 2065, 2009, 2910, 1005, 1056, 2042, 2005, 1996, 10961, 1997, 1996, 18813, 5233, 1999, 2530, 2885, 1010, 2605, 1998, 3577, 2089, 2031, 2018, 2367, 12018, 1997, 2037, 3260, 1999, 1996, 2047, 2088, 1012, 2005, 2216, 2040, 2024, 2092, 1011, 7893, 2094, 1999, 1996, 1048, 1004, 1039, 5590, 1010, 2009, 1005, 1055, 2092, 1011, 2124, 2426, 2216, 5784, 2008, 4572, 1998, 5215, 2020, 2025, 1996, 2034, 2317, 2273, 2000, 20811, 1996, 5284, 2314, 1012, 2045, 2020, 2116, 2413, 8132, 7347, 1998, 1037, 2261, 10459, 20999, 2040, 2018, 2081, 3967, 2007, 1996, 3128, 6946, 1010, 1998, 2040, 4895, 2243, 19779, 15787, 3659, 4012, 23041, 5555, 3468, 7870, 2000, 2122, 8211, 2111, 1998, 11703, 20592, 2972, 4731, 1012, 21713, 6238, 5363, 2000, 3288, 2023, 2046, 7339, 2182, 1010, 2004, 1048, 1004, 1039, 2106, 2025, 3113, 2151, 10420, 12493, 2127, 2027, 2234, 2426, 1996, 2158, 7847, 1012, 2972, 4731, 2148, 1997, 2068, 2020, 4704, 2349, 2000, 7870, 1996, 2317, 7322, 2018, 2716, 2000, 1996, 2555, 1012, 2023, 2003, 1037, 2200, 3191, 3085, 7984, 1997, 7625, 1005, 1055, 3125, 2000, 2131, 1996, 2530, 4915, 10641, 1012, 2045, 2024, 1037, 2843, 1997, 3415, 3333, 2220, 2006, 2000, 2507, 1996, 8025, 8068, 1037, 7339, 1012, 3577, 1998, 1996, 2402, 2142, 2163, 2471, 2253, 2000, 2162, 2058, 1996, 3570, 1997, 2047, 5979, 1998, 1996, 5773, 3700, 1010, 2021, 1996, 18813, 5233, 2217, 6494, 18141, 1996, 5465, 1999, 2885, 1012, 2116, 1997, 1996, 19264, 1999, 2023, 2338, 2991, 2247, 1996, 3971, 5178, 1999, 2137, 2381, 1010, 2021, 21713, 6238, 3957, 4923, 2000, 2035, 2122, 2273, 1998, 2393, 1996, 2381, 23176, 2156, 2008, 1048, 1004, 1039, 2020, 2025, 1996, 2069, 5590, 11131, 4895, 7507, 19418, 2098, 5380, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6LWSQnh-UGQn"
      },
      "outputs": [],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for s in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        s,                      # Sentence to encode.\n",
        "                        truncation=True,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens=False,\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94sqHr36CdtB",
        "outputId": "c8ccf24a-e4c8-4abd-ca75-6158a4cfdb00"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  1045,  2031,  2467,  2042,  1037,  5470,  1997,  1996,  4572,\n",
              "         1998,  5215,  1006,  1048,  1004,  1039,  1007,  5590,  1998,  2031,\n",
              "         3191,  3365,  2808,  2006,  2008,  3690,  1012,  1045,  2130,  2346,\n",
              "        21129,  2247,  1996,  5284,  2314,  2000,  1996,  2314,  1005,  1055,\n",
              "         3120,  1999,  8124,  1006, 11826,  2075,  2167,  7734,  1998,  2789,\n",
              "         8124,  2349,  2000,  5567, 22668,  2008,  2621,  1007,  1010,  7458,\n",
              "         2247,  2035,  1996,  3439,  5751,  1012,  1045,  1005,  1049,  1037,\n",
              "         5470,  2138,  1045,  3305,  1996,  8424,  2009,  2165,  2000,  8849,\n",
              "         4242,  4915,  2007,  4022,  6355,  4864,  1010,  2021,  1045,  2036,\n",
              "         3305,  1996,  7784,  1997,  2137,  4935,  2000,  1996,  3534,  3081,\n",
              "         1996,  4514,  6019,  1012,  3098,  2039,  2122,  4915,  2003,  2028,\n",
              "         1997,  7625,  1005,  1055,  5221,  4190, 20499,  2004,  2343,  1012,\n",
              "         2054,  7628, 21713,  6238,  2515,  2182,  2003,  2025,  2074,  7680,\n",
              "         7849,  4697,  1996,  1048,  1004,  1039,  5590,  1010,  2295,  1012,\n",
              "         2016,  5577,  1996,  2402,  2637,  2012,  1996,  2735,  1997,  1996,\n",
              "         3708,  2301,  1012, 13200,  2020,  3048, 15165,  1010,  2021,  3577,\n",
              "         4758,  1996,  2530,  4915,  1012,  2016,  3957,  2460, 22056,  1997,\n",
              "         1996,  2867,  1010,  1996, 11141,  1010,  5465,  1998, 19264,  1997,\n",
              "         1996,  3690,  1012,  2009,  2001,  1037,  2051,  1997,  2307, 17601,\n",
              "         1012, 21713,  6238, 17509,  7625,  2004,  1037,  2158,  3554,  2125,\n",
              "         1996,  2198,  5922,  6793,  1025,  2035,  2001,  2025,  2183,  2061,\n",
              "         2092,  2005,  7625,  2043,  2002,  2034,  2150,  2343,  1012,  2054,\n",
              "         8141,  2131,  2041,  1997,  2023,  2200,  3191,  3085,  4070,  2003,\n",
              "         2008,  1996,  1048,  1004,  1039,  5590,  2001,  2025,  1996,  2069,\n",
              "         5590,  2183,  2006,  2012,  1996,  2051,  1012,  2009,  1005,  1055,\n",
              "         5875,  2000,  3602,  2008,  2045,  2020,  2060, 26103, 19264,  5627,\n",
              "         2000,  3189,  2067,  2000,  7625,  2054,  1996,  3009,  1011,  2218,\n",
              "         4915,  2020,  2066,  1010,  1998, 21713,  6238,  5577,  2122,  1999,\n",
              "         7189,  2000,  1996,  1048,  1004,  1039,  5590,  1996,  4477,  1004,\n",
              "        23034,  5590,  2001,  2004,  7070,  2000,  7625,  2004,  1996,  1048,\n",
              "         1004,  1039,  2028,  2001,  1010,  2030,  1996,  1997,  2102,  1011,\n",
              "        17808,  5590,  1997, 27838,  8569,  7811, 12694,  1010,  2030,  1996,\n",
              "         8424,  1997,  2726, 11462,  2030,  2848, 12731, 29472,  1012,  2035,\n",
              "         2122,  2273, 10107,  2037,  5417,  2781,  1997,  4476,  1010,  1998,\n",
              "        21713,  6238, 18058,  1037,  3435,  1011, 13823,  7984,  2000,  2425,\n",
              "         1996,  2062,  3143,  2466,  1997,  1037,  2402,  2637, 15035,  2000,\n",
              "         8849,  1998, 16083,  2049,  2530,  7372,  1012,  2065,  2009,  2910,\n",
              "         1005,  1056,  2042,  2005,  1996, 10961,  1997,  1996, 18813,  5233,\n",
              "         1999,  2530,  2885,  1010,  2605,  1998,  3577,  2089,  2031,  2018,\n",
              "         2367, 12018,  1997,  2037,  3260,  1999,  1996,  2047,  2088,  1012,\n",
              "         2005,  2216,  2040,  2024,  2092,  1011,  7893,  2094,  1999,  1996,\n",
              "         1048,  1004,  1039,  5590,  1010,  2009,  1005,  1055,  2092,  1011,\n",
              "         2124,  2426,  2216,  5784,  2008,  4572,  1998,  5215,  2020,  2025,\n",
              "         1996,  2034,  2317,  2273,  2000, 20811,  1996,  5284,  2314,  1012,\n",
              "         2045,  2020,  2116,  2413,  8132,  7347,  1998,  1037,  2261, 10459,\n",
              "        20999,  2040,  2018,  2081,  3967,  2007,  1996,  3128,  6946,  1010,\n",
              "         1998,  2040,  4895,  2243, 19779, 15787,  3659,  4012, 23041,  5555,\n",
              "         3468,  7870,  2000,  2122,  8211,  2111,  1998, 11703, 20592,  2972,\n",
              "         4731,  1012, 21713,  6238,  5363,  2000,  3288,  2023,  2046,  7339,\n",
              "         2182,  1010,  2004,  1048,  1004,  1039,  2106,  2025,  3113,  2151,\n",
              "        10420, 12493,  2127,  2027,  2234,  2426,  1996,  2158,  7847,  1012,\n",
              "         2972,   102])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlyteN-zJGuU",
        "outputId": "d5e2ac54-44cc-463e-a60d-91c770d62291"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "vPrzId6-VHRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff16ba8-47cd-4df3-c08c-7d484df4ea70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44,970 training samples\n",
            "4,997 validation samples\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(44)\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size, # Trains with this batch size.\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size, # Evaluate with this batch size.\n",
        "            num_workers=2\n",
        "        )"
      ],
      "metadata": {
        "id": "S28rl4_sW-Tg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForSequenceClassification,BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n",
        "\n",
        "\"\"\"\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 100, # The number of output labels--2 for binary classification.\n",
        "             # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\"\"\"\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f3bb64753ed340eeb9051eaa8c190614",
            "7f45af872b89469a9d8ed0cfc9ba5e1b",
            "d9512363335f4e43b4a371e5c92c479f",
            "0ebe5d4cbadc4d0d9c6ba4a7554fcbf5",
            "593f9269a1e048729a08c4baf1bb3492",
            "ffaf2783803748d9886917a04e43a727",
            "0b2aa46f5f7142298bfbff0551665e68",
            "e87f901b914b4e0aae5a57d978f406ec",
            "a8e86845f37f45adb4fbe0492741de01",
            "37117ff5e359480e98ce51a9887464ec",
            "6d8cb6c3ce0d4634a9aab87289ccd0af"
          ]
        },
        "id": "FFC8OPPtXj-o",
        "outputId": "5b97bf42-6d21-4535-dd09-c7759ae78696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3bb64753ed340eeb9051eaa8c190614"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.15, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.15, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=101, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyfOCEN1Xryv",
        "outputId": "f74df032-0ed3-4224-9d0f-d3b1ba8774fd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "#total_steps = len(train_dataloader) * epochs\n",
        "gradient_accumulation_steps=1\n",
        "n_gpu=1\n",
        "#total_steps= ((len(train_dataloader) // (batch_size * max(1, n_gpu)))// gradient_accumulation_steps* float(epochs))\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "0w5GFlvKYPSt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "Kw9o2H90ZOV6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "ETl2dVFAZRQ9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3VSWJY-BIEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66SqB6uMBIHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zrxmddWgA4cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1)"
      ],
      "metadata": {
        "id": "5H4s_OnkA4e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNBdfXbKBFq4",
        "outputId": "f8cd87ad-25d0-4a33-c0bf-52b260905023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7019])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r =nn.ReLU()"
      ],
      "metadata": {
        "id": "gCQMjgO9bSt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNl5tVWibUK5",
        "outputId": "cc256ce7-9deb-473f-a7dc-f8c53479a953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat((x, x, x), 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7OfPiRtA4hE",
        "outputId": "b1400300-c125-4970-e1e6-2bf5ea2f9f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.9391,  1.4540,  0.6497],\n",
              "        [ 1.2617, -1.2708, -0.6085],\n",
              "        [-1.9391,  1.4540,  0.6497],\n",
              "        [ 1.2617, -1.2708, -0.6085],\n",
              "        [-1.9391,  1.4540,  0.6497],\n",
              "        [ 1.2617, -1.2708, -0.6085]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " eps = 1e-07\n",
        " print(eps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RLH0u9jaqMm",
        "outputId": "32f2a605-dc50-4b04-b63e-f77dd05891ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZXgwP-TPaqRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBTEnFlRaqTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLkwap5waqXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z5rW50TJBHaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "kGPX_c8JBHdy"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "seed_val = 44\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "RLrdCbDju7W_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 44\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "      #  print(b_input_ids)\n",
        "      #  print(b_input_mask)\n",
        "      #  print(b_labels)\n",
        "        arr_ind=[i for i in range(len(b_labels))]\n",
        "      #  print(arr_ind)\n",
        "        counter = 0\n",
        "        ########\n",
        "        b_lables_pair_l2 = []\n",
        "        while(1):\n",
        "          ind1=np.random.choice(arr_ind)\n",
        "          ind2=np.random.choice(arr_ind)\n",
        "          counter =counter + 1\n",
        "          if(b_labels[ind1].item()!=b_labels[ind2].item()):\n",
        "         #    print(ind1,ind2)\n",
        "             #print(b_labels[ind1].item(),b_labels[ind2].item())\n",
        "             arr_ind.remove(ind1)\n",
        "             arr_ind.remove(ind2)\n",
        "             b_lables_pair_l2.append([ind1,ind2])\n",
        "          if(counter>50 or len(arr_ind)<=8):\n",
        "         #   print(arr_ind)\n",
        "            break\n",
        "\n",
        "        b_input_ids_l1 = torch.cat(tuple([batch[0][ind:ind+1] for ind in arr_ind])).to(device)\n",
        "        b_input_mask_l1 = torch.cat(tuple([batch[1][ind:ind+1] for ind in arr_ind])).to(device)\n",
        "        b_labels_l1 = torch.cat(tuple([batch[2][ind:ind+1] for ind in arr_ind])).to(device)\n",
        "        # print(b_input_ids)\n",
        "        # print(b_input_ids_l1)\n",
        "\n",
        "        # print(\"******\")\n",
        "        # print(batch[0][0:1])\n",
        "        # print(batch[0][1:2])\n",
        "        # sum_pair = np.ceil((batch[0][0:1]+batch[0][1:2])/2)\n",
        "        # avg_pair=sum_pair.type(torch.int64)\n",
        "        # print(avg_pair)\n",
        "        b_input_ids_l2=[]\n",
        "        b_input_mask_l2=[]\n",
        "        b_labels_l2=[]\n",
        "\n",
        "        for ind_pair in b_lables_pair_l2:\n",
        "          i=ind_pair[0]\n",
        "          j=ind_pair[1]\n",
        "\n",
        "          sum_pair=np.ceil((batch[0][i:i+1]+batch[0][j:j+1])/2)\n",
        "          avg_pair=sum_pair.type(torch.int64)\n",
        "          b_input_ids_l2.append(avg_pair)\n",
        "\n",
        "\n",
        "\n",
        "          sum_pair_mask=np.ceil((batch[1][i:i+1]+batch[1][j:j+1])/2)\n",
        "          avg_pair_mask=sum_pair_mask.type(torch.int64)\n",
        "\n",
        "          b_input_mask_l2.append(avg_pair_mask)\n",
        "\n",
        "          b_labels_l2.append(torch.tensor([100]))\n",
        "\n",
        "        b_labels_l2 = torch.cat(tuple(b_labels_l2)).to(device)\n",
        "        b_input_mask_l2 = torch.cat(tuple(b_input_mask_l2)).to(device)\n",
        "        b_input_ids_l2 = torch.cat(tuple(b_input_ids_l2)).to(device)\n",
        "        \n",
        "\n",
        "       \n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result1 = model(b_input_ids_l1, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask_l1, \n",
        "                       labels=b_labels_l1,\n",
        "                       return_dict=True)\n",
        "        \n",
        "        result2 = model(b_input_ids_l2, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask_l2, \n",
        "                       labels=b_labels_l2,\n",
        "                       return_dict=True)\n",
        "        \n",
        " \n",
        "\n",
        " \n",
        "        loss1 = result1.loss\n",
        "        loss2 = result2.loss\n",
        "        \n",
        "\n",
        "        logits1 = result1.logits\n",
        "        logits2 = result2.logits\n",
        "\n",
        "        eps = 1e-7\n",
        "        # t = F.relu()\n",
        "        # t = torch.log(t +eps)\n",
        "\n",
        "        kthlogits1 = logits1[: , len(logits1[0])-1:len(logits1[0])].clone()\n",
        "        kthlogits2 = logits2[: , len(logits2[0])-1:len(logits2[0])].clone()\n",
        "      #  print(\"kthlogits before Relu   \",kthlogits1)\n",
        "        ReLU = nn.ReLU()\n",
        "        kthlogits1 = ReLU(kthlogits1)\n",
        "      #  print(\"kthlogits after Relu   \",kthlogits1)\n",
        "        kthloss1 = -1 * torch.log(kthlogits1 + eps)\n",
        "       # print(\"kthloss  \",kthloss1)\n",
        "        kthloss1 = torch.sum(kthloss1)\n",
        "        kthloss1 = torch.sum(kthloss1)/len(b_labels_l1)\n",
        "       # print(\"kthloss  \",kthloss1)\n",
        "        #print(\"logits : \",logits)\n",
        "        #print(len(logits))\n",
        "        kthlogits2 = ReLU(kthlogits2)\n",
        "        kthloss2 = -1 * torch.log(kthlogits2 + eps)\n",
        "        kthloss2 = torch.sum(kthloss2)/len(b_labels_l2)\n",
        "        loss = loss1 + (0.4 * kthloss1) + (0.999 * kthloss2)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "        \n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "       # print(logits)\n",
        "        \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "      #  print(label_ids) \n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX-FmXpBZfoX",
        "outputId": "7194d747-f6b6-48a1-a29c-ba3ef423ceb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  2,811.    Elapsed: 0:00:42.\n",
            "  Batch    80  of  2,811.    Elapsed: 0:01:26.\n",
            "  Batch   120  of  2,811.    Elapsed: 0:02:10.\n",
            "  Batch   160  of  2,811.    Elapsed: 0:02:55.\n",
            "  Batch   200  of  2,811.    Elapsed: 0:03:40.\n",
            "  Batch   240  of  2,811.    Elapsed: 0:04:26.\n",
            "  Batch   280  of  2,811.    Elapsed: 0:05:12.\n",
            "  Batch   320  of  2,811.    Elapsed: 0:05:57.\n",
            "  Batch   360  of  2,811.    Elapsed: 0:06:43.\n",
            "  Batch   400  of  2,811.    Elapsed: 0:07:28.\n",
            "  Batch   440  of  2,811.    Elapsed: 0:08:14.\n",
            "  Batch   480  of  2,811.    Elapsed: 0:08:59.\n",
            "  Batch   520  of  2,811.    Elapsed: 0:09:45.\n",
            "  Batch   560  of  2,811.    Elapsed: 0:10:31.\n",
            "  Batch   600  of  2,811.    Elapsed: 0:11:16.\n",
            "  Batch   640  of  2,811.    Elapsed: 0:12:02.\n",
            "  Batch   680  of  2,811.    Elapsed: 0:12:48.\n",
            "  Batch   720  of  2,811.    Elapsed: 0:13:33.\n",
            "  Batch   760  of  2,811.    Elapsed: 0:14:19.\n",
            "  Batch   800  of  2,811.    Elapsed: 0:15:05.\n",
            "  Batch   840  of  2,811.    Elapsed: 0:15:51.\n",
            "  Batch   880  of  2,811.    Elapsed: 0:16:37.\n",
            "  Batch   920  of  2,811.    Elapsed: 0:17:22.\n",
            "  Batch   960  of  2,811.    Elapsed: 0:18:08.\n",
            "  Batch 1,000  of  2,811.    Elapsed: 0:18:54.\n",
            "  Batch 1,040  of  2,811.    Elapsed: 0:19:40.\n",
            "  Batch 1,080  of  2,811.    Elapsed: 0:20:26.\n",
            "  Batch 1,120  of  2,811.    Elapsed: 0:21:11.\n",
            "  Batch 1,160  of  2,811.    Elapsed: 0:21:57.\n",
            "  Batch 1,200  of  2,811.    Elapsed: 0:22:43.\n",
            "  Batch 1,240  of  2,811.    Elapsed: 0:23:28.\n",
            "  Batch 1,280  of  2,811.    Elapsed: 0:24:14.\n",
            "  Batch 1,320  of  2,811.    Elapsed: 0:25:00.\n",
            "  Batch 1,360  of  2,811.    Elapsed: 0:25:45.\n",
            "  Batch 1,400  of  2,811.    Elapsed: 0:26:31.\n",
            "  Batch 1,440  of  2,811.    Elapsed: 0:27:17.\n",
            "  Batch 1,480  of  2,811.    Elapsed: 0:28:02.\n",
            "  Batch 1,520  of  2,811.    Elapsed: 0:28:48.\n",
            "  Batch 1,560  of  2,811.    Elapsed: 0:29:34.\n",
            "  Batch 1,600  of  2,811.    Elapsed: 0:30:19.\n",
            "  Batch 1,640  of  2,811.    Elapsed: 0:31:05.\n",
            "  Batch 1,680  of  2,811.    Elapsed: 0:31:50.\n",
            "  Batch 1,720  of  2,811.    Elapsed: 0:32:36.\n",
            "  Batch 1,760  of  2,811.    Elapsed: 0:33:22.\n",
            "  Batch 1,800  of  2,811.    Elapsed: 0:34:07.\n",
            "  Batch 1,840  of  2,811.    Elapsed: 0:34:53.\n",
            "  Batch 1,880  of  2,811.    Elapsed: 0:35:38.\n",
            "  Batch 1,920  of  2,811.    Elapsed: 0:36:24.\n",
            "  Batch 1,960  of  2,811.    Elapsed: 0:37:10.\n",
            "  Batch 2,000  of  2,811.    Elapsed: 0:37:56.\n",
            "  Batch 2,040  of  2,811.    Elapsed: 0:38:41.\n",
            "  Batch 2,080  of  2,811.    Elapsed: 0:39:27.\n",
            "  Batch 2,120  of  2,811.    Elapsed: 0:40:13.\n",
            "  Batch 2,160  of  2,811.    Elapsed: 0:40:58.\n",
            "  Batch 2,200  of  2,811.    Elapsed: 0:41:44.\n",
            "  Batch 2,240  of  2,811.    Elapsed: 0:42:30.\n",
            "  Batch 2,280  of  2,811.    Elapsed: 0:43:15.\n",
            "  Batch 2,320  of  2,811.    Elapsed: 0:44:01.\n",
            "  Batch 2,360  of  2,811.    Elapsed: 0:44:47.\n",
            "  Batch 2,400  of  2,811.    Elapsed: 0:45:33.\n",
            "  Batch 2,440  of  2,811.    Elapsed: 0:46:18.\n",
            "  Batch 2,480  of  2,811.    Elapsed: 0:47:04.\n",
            "  Batch 2,520  of  2,811.    Elapsed: 0:47:50.\n",
            "  Batch 2,560  of  2,811.    Elapsed: 0:48:35.\n",
            "  Batch 2,600  of  2,811.    Elapsed: 0:49:21.\n",
            "  Batch 2,640  of  2,811.    Elapsed: 0:50:07.\n",
            "  Batch 2,680  of  2,811.    Elapsed: 0:50:52.\n",
            "  Batch 2,720  of  2,811.    Elapsed: 0:51:38.\n",
            "  Batch 2,760  of  2,811.    Elapsed: 0:52:24.\n",
            "  Batch 2,800  of  2,811.    Elapsed: 0:53:09.\n",
            "\n",
            "  Average training loss: -4.99\n",
            "  Training epcoh took: 0:53:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:02:49\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of  2,811.    Elapsed: 0:00:46.\n",
            "  Batch    80  of  2,811.    Elapsed: 0:01:32.\n",
            "  Batch   120  of  2,811.    Elapsed: 0:02:17.\n",
            "  Batch   160  of  2,811.    Elapsed: 0:03:03.\n",
            "  Batch   200  of  2,811.    Elapsed: 0:03:48.\n",
            "  Batch   240  of  2,811.    Elapsed: 0:04:34.\n",
            "  Batch   280  of  2,811.    Elapsed: 0:05:20.\n",
            "  Batch   320  of  2,811.    Elapsed: 0:06:05.\n",
            "  Batch   360  of  2,811.    Elapsed: 0:06:51.\n",
            "  Batch   400  of  2,811.    Elapsed: 0:07:37.\n",
            "  Batch   440  of  2,811.    Elapsed: 0:08:22.\n",
            "  Batch   480  of  2,811.    Elapsed: 0:09:08.\n",
            "  Batch   520  of  2,811.    Elapsed: 0:09:54.\n",
            "  Batch   560  of  2,811.    Elapsed: 0:10:40.\n",
            "  Batch   600  of  2,811.    Elapsed: 0:11:25.\n",
            "  Batch   640  of  2,811.    Elapsed: 0:12:11.\n",
            "  Batch   680  of  2,811.    Elapsed: 0:12:56.\n",
            "  Batch   720  of  2,811.    Elapsed: 0:13:42.\n",
            "  Batch   760  of  2,811.    Elapsed: 0:14:28.\n",
            "  Batch   800  of  2,811.    Elapsed: 0:15:13.\n",
            "  Batch   840  of  2,811.    Elapsed: 0:15:59.\n",
            "  Batch   880  of  2,811.    Elapsed: 0:16:45.\n",
            "  Batch   920  of  2,811.    Elapsed: 0:17:31.\n",
            "  Batch   960  of  2,811.    Elapsed: 0:18:16.\n",
            "  Batch 1,000  of  2,811.    Elapsed: 0:19:02.\n",
            "  Batch 1,040  of  2,811.    Elapsed: 0:19:48.\n",
            "  Batch 1,080  of  2,811.    Elapsed: 0:20:34.\n",
            "  Batch 1,120  of  2,811.    Elapsed: 0:21:19.\n",
            "  Batch 1,160  of  2,811.    Elapsed: 0:22:05.\n",
            "  Batch 1,200  of  2,811.    Elapsed: 0:22:51.\n",
            "  Batch 1,240  of  2,811.    Elapsed: 0:23:37.\n",
            "  Batch 1,280  of  2,811.    Elapsed: 0:24:22.\n",
            "  Batch 1,320  of  2,811.    Elapsed: 0:25:08.\n",
            "  Batch 1,360  of  2,811.    Elapsed: 0:25:53.\n",
            "  Batch 1,400  of  2,811.    Elapsed: 0:26:39.\n",
            "  Batch 1,440  of  2,811.    Elapsed: 0:27:24.\n",
            "  Batch 1,480  of  2,811.    Elapsed: 0:28:10.\n",
            "  Batch 1,520  of  2,811.    Elapsed: 0:28:55.\n",
            "  Batch 1,560  of  2,811.    Elapsed: 0:29:41.\n",
            "  Batch 1,600  of  2,811.    Elapsed: 0:30:27.\n",
            "  Batch 1,640  of  2,811.    Elapsed: 0:31:12.\n",
            "  Batch 1,680  of  2,811.    Elapsed: 0:31:58.\n",
            "  Batch 1,720  of  2,811.    Elapsed: 0:32:43.\n",
            "  Batch 1,760  of  2,811.    Elapsed: 0:33:29.\n",
            "  Batch 1,800  of  2,811.    Elapsed: 0:34:15.\n",
            "  Batch 1,840  of  2,811.    Elapsed: 0:35:00.\n",
            "  Batch 1,880  of  2,811.    Elapsed: 0:35:46.\n",
            "  Batch 1,920  of  2,811.    Elapsed: 0:36:31.\n",
            "  Batch 1,960  of  2,811.    Elapsed: 0:37:17.\n",
            "  Batch 2,000  of  2,811.    Elapsed: 0:38:02.\n",
            "  Batch 2,040  of  2,811.    Elapsed: 0:38:48.\n",
            "  Batch 2,080  of  2,811.    Elapsed: 0:39:34.\n",
            "  Batch 2,120  of  2,811.    Elapsed: 0:40:19.\n",
            "  Batch 2,160  of  2,811.    Elapsed: 0:41:05.\n",
            "  Batch 2,200  of  2,811.    Elapsed: 0:41:50.\n",
            "  Batch 2,240  of  2,811.    Elapsed: 0:42:36.\n",
            "  Batch 2,280  of  2,811.    Elapsed: 0:43:22.\n",
            "  Batch 2,320  of  2,811.    Elapsed: 0:44:07.\n",
            "  Batch 2,360  of  2,811.    Elapsed: 0:44:53.\n",
            "  Batch 2,400  of  2,811.    Elapsed: 0:45:38.\n",
            "  Batch 2,440  of  2,811.    Elapsed: 0:46:24.\n",
            "  Batch 2,480  of  2,811.    Elapsed: 0:47:10.\n",
            "  Batch 2,520  of  2,811.    Elapsed: 0:47:55.\n",
            "  Batch 2,560  of  2,811.    Elapsed: 0:48:41.\n",
            "  Batch 2,600  of  2,811.    Elapsed: 0:49:26.\n",
            "  Batch 2,640  of  2,811.    Elapsed: 0:50:12.\n",
            "  Batch 2,680  of  2,811.    Elapsed: 0:50:58.\n",
            "  Batch 2,720  of  2,811.    Elapsed: 0:51:43.\n",
            "  Batch 2,760  of  2,811.    Elapsed: 0:52:29.\n",
            "  Batch 2,800  of  2,811.    Elapsed: 0:53:14.\n",
            "\n",
            "  Average training loss: -4.99\n",
            "  Training epcoh took: 0:53:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:02:49\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:52:26 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2RIsX_1VuuO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-aozXuiuuSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "count = 1\n",
        "# Evaluate data for one epoch\n",
        "for batch in validation_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        result = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels,\n",
        "                        return_dict=True)\n",
        "\n",
        "    # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "    # output values prior to applying an activation function like the \n",
        "    # softmax.\n",
        "    loss = result.loss\n",
        "    logits = result.logits\n",
        "    # print(logits)\n",
        "    \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    logits[:,100] = logits[:,100] + 2.5\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    pred_labels = np.argmax(logits, axis=1)\n",
        "  #  print(label_ids) \n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "      # Store predictions and true labels\n",
        "    predictions.extend(pred_labels.tolist())\n",
        "    true_labels.extend(label_ids.tolist())\n",
        "    # if(count == 1):\n",
        "    #   break\n",
        "    count = count +1\n",
        "\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Validation took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ5XI85DuuVJ",
        "outputId": "87661ee7-3567-4229-afce-30ad2f560fa2"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:02:38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bias ........................                      percentage\n",
        "\n",
        "   4   .........................                    .58\n",
        "\n",
        "   3 ............................                    .24\n",
        "\n",
        "   2 .............................               .17    "
      ],
      "metadata": {
        "id": "jUxaOGAP_yu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "result_report= classification_report(true_labels, predictions, digits=3, output_dict=False)\n",
        "print(result_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlDwxTqb9I_I",
        "outputId": "a90d463f-68d0-49a4-cacc-38faad098a6e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.875     0.792     0.832        53\n",
            "           1      0.976     0.872     0.921        47\n",
            "           2      0.907     0.830     0.867        47\n",
            "           3      1.000     0.907     0.951        54\n",
            "           4      0.852     0.377     0.523        61\n",
            "           5      1.000     0.358     0.528        53\n",
            "           6      0.947     0.818     0.878        44\n",
            "           7      0.951     0.812     0.876        48\n",
            "           8      0.974     0.792     0.874        48\n",
            "           9      0.885     0.451     0.597        51\n",
            "          10      0.977     0.956     0.966        45\n",
            "          11      0.808     0.553     0.656        38\n",
            "          12      1.000     0.929     0.963        56\n",
            "          13      1.000     0.804     0.892        46\n",
            "          14      0.889     0.542     0.674        59\n",
            "          15      1.000     0.945     0.972        55\n",
            "          16      0.976     0.788     0.872        52\n",
            "          17      0.900     0.783     0.837        46\n",
            "          18      0.886     0.775     0.827        40\n",
            "          19      0.971     0.647     0.776        51\n",
            "          20      1.000     0.935     0.966        46\n",
            "          21      0.970     0.627     0.762        51\n",
            "          22      0.964     0.443     0.607        61\n",
            "          23      0.829     0.630     0.716        46\n",
            "          24      0.950     0.851     0.898        67\n",
            "          25      0.957     0.746     0.838        59\n",
            "          26      0.957     0.918     0.938        49\n",
            "          27      0.955     0.857     0.903        49\n",
            "          28      0.895     0.756     0.819        45\n",
            "          29      0.889     0.744     0.810        43\n",
            "          30      0.867     0.812     0.839        48\n",
            "          31      0.980     0.862     0.917        58\n",
            "          32      0.845     0.942     0.891        52\n",
            "          33      0.860     0.638     0.733        58\n",
            "          34      0.828     0.343     0.485        70\n",
            "          35      1.000     0.776     0.874        49\n",
            "          36      0.919     0.850     0.883        40\n",
            "          37      1.000     0.860     0.925        50\n",
            "          38      1.000     0.762     0.865        42\n",
            "          39      0.881     0.755     0.813        49\n",
            "          40      0.841     0.627     0.718        59\n",
            "          41      0.891     0.980     0.933        50\n",
            "          42      0.975     0.886     0.929        44\n",
            "          43      1.000     0.855     0.922        55\n",
            "          44      0.944     0.773     0.850        44\n",
            "          45      1.000     0.750     0.857        48\n",
            "          46      0.979     0.939     0.958        49\n",
            "          47      0.974     0.902     0.937        41\n",
            "          48      0.981     0.930     0.955        57\n",
            "          49      1.000     0.845     0.916        58\n",
            "          50      1.000     0.732     0.845        41\n",
            "          51      1.000     0.848     0.918        46\n",
            "          52      0.964     0.711     0.818        38\n",
            "          53      0.684     0.591     0.634        44\n",
            "          54      1.000     0.477     0.646        44\n",
            "          55      0.907     0.765     0.830        51\n",
            "          56      1.000     0.938     0.968        48\n",
            "          57      1.000     0.744     0.853        43\n",
            "          58      0.956     0.843     0.896        51\n",
            "          59      0.974     0.902     0.937        41\n",
            "          60      0.852     0.511     0.639        45\n",
            "          61      0.978     0.846     0.907        52\n",
            "          62      0.960     0.906     0.932        53\n",
            "          63      1.000     0.786     0.880        56\n",
            "          64      1.000     0.811     0.896        53\n",
            "          65      1.000     0.942     0.970        52\n",
            "          66      0.978     0.882     0.928        51\n",
            "          67      0.980     0.907     0.942        54\n",
            "          68      0.963     0.542     0.693        48\n",
            "          69      0.881     0.725     0.796        51\n",
            "          70      0.857     0.625     0.723        48\n",
            "          71      1.000     0.932     0.965        44\n",
            "          72      0.977     0.896     0.935        48\n",
            "          73      1.000     0.569     0.725        51\n",
            "          74      1.000     0.984     0.992        62\n",
            "          75      1.000     0.630     0.773        46\n",
            "          76      1.000     0.875     0.933        40\n",
            "          77      0.933     0.933     0.933        45\n",
            "          78      0.971     0.733     0.835        45\n",
            "          79      1.000     0.957     0.978        47\n",
            "          80      1.000     0.957     0.978        46\n",
            "          81      0.891     0.803     0.845        61\n",
            "          82      0.930     0.914     0.922        58\n",
            "          83      0.976     0.953     0.965        43\n",
            "          84      1.000     0.804     0.891        51\n",
            "          85      0.959     0.887     0.922        53\n",
            "          86      0.953     0.854     0.901        48\n",
            "          87      1.000     0.588     0.741        51\n",
            "          88      0.976     0.800     0.879        50\n",
            "          89      0.951     0.696     0.804        56\n",
            "          90      0.884     0.760     0.817        50\n",
            "          91      0.946     0.700     0.805        50\n",
            "          92      1.000     0.925     0.961        53\n",
            "          93      1.000     0.978     0.989        45\n",
            "          94      0.981     0.839     0.904        62\n",
            "          95      1.000     0.882     0.938        51\n",
            "          96      0.825     0.971     0.892        34\n",
            "          97      1.000     0.698     0.822        63\n",
            "          98      1.000     0.898     0.946        49\n",
            "          99      1.000     0.889     0.941        54\n",
            "         100      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.783      4997\n",
            "   macro avg      0.941     0.779     0.845      4997\n",
            "weighted avg      0.950     0.783     0.851      4997\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OppISe6t9UGj",
        "outputId": "5c7f208a-0dc6-4d44-b35a-fc639f3d29ac"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4997"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.count(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3daDRx3u_ijx",
        "outputId": "d937ed7d-6fcb-4f7d-f8e9-697cb133c0be"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "883"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.count(100)/len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcADTQZC_mBt",
        "outputId": "05c00f63-71a6-484c-a08f-c6df19b9b3c3"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1767060236141685"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(true_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cLiXR-d8dGm",
        "outputId": "16a4a450-397a-449c-b408-2ac21b401b0d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "a5gkpsd7wsTx"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T20tqWtKwsdm",
        "outputId": "6946cb8f-4845-469d-e4be-d558bec0a5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([43, 20, 59, 34,  7, 63, 43,  7, 35,  5, 76, 91,  5, 89, 84,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.argmax(logits, axis=1).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W3X60iSwsmF",
        "outputId": "f83b6936-d8a8-4a40-84a6-7578efcc314c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 43,  20,  59,  34,   7,  63,  59,   7,  35, 100,  76,  91,  89,\n",
              "        89,  84,   0])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.max(logits, axis=1).flatten()"
      ],
      "metadata": {
        "id": "YFoZh2hUyOjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_Tbcqae4INZ",
        "outputId": "f6ba42ee-12bf-4b72-f126-527a08ea9cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16.159687, 16.142715, 16.420454, 12.797331, 15.578764, 14.300396,\n",
              "       16.22332 , 13.515502, 16.915512,  9.753988, 17.33382 , 14.549238,\n",
              "       11.515009, 15.093859, 16.382534, 11.79152 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKLjJg0t9uFm",
        "outputId": "2f26e106-efb1-4f8f-91cb-d316a83cab57"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.0996609e+00, -1.6790918e+00, -2.8319037e+00,  4.8462071e+00,\n",
              "       -1.2346944e+00,  1.2848768e-01, -7.3115964e+00,  1.2761467e+00,\n",
              "        8.7527359e-01,  1.3938758e+00,  5.0330334e+00,  1.6960272e+00,\n",
              "        6.1136885e+00,  3.0458198e+00, -2.4202554e+00,  7.4863701e+00,\n",
              "        3.5305688e+00, -3.6537640e+00,  6.9197905e-01, -4.0501647e+00,\n",
              "       -2.1340194e+00, -3.2536345e+00,  1.0249410e+00, -3.8096561e+00,\n",
              "        1.1830561e+00,  9.3371964e-01, -1.1311479e+00, -2.2338388e+00,\n",
              "       -7.5191736e-01, -1.2780213e+00, -4.3915421e-01, -3.3016515e+00,\n",
              "       -6.1894357e-01,  3.8974103e-01,  1.7989233e+00,  1.2102002e+00,\n",
              "       -7.3611873e-01,  4.5160756e+00,  1.6900563e+00,  3.7431271e+00,\n",
              "       -1.9941065e+00, -2.3456495e+00, -1.0667553e+00,  1.6159681e+01,\n",
              "       -2.4779987e+00,  7.3027892e+00,  3.9735091e+00,  2.6683168e+00,\n",
              "        1.4056995e+00,  1.2774503e+00,  4.3289142e+00,  2.5949926e+00,\n",
              "        3.4666615e+00, -2.9608481e+00, -3.9181409e+00, -4.6378851e-01,\n",
              "        1.2821400e+00,  6.3494515e-01, -1.7643874e+00,  4.8106074e+00,\n",
              "       -2.8821847e+00, -5.1097174e+00,  8.8775426e-02, -1.3933393e+00,\n",
              "       -4.0252476e+00, -1.5280004e+00, -8.8146490e-01, -3.6417024e+00,\n",
              "        6.8715721e-01, -5.5551201e-01, -1.4843566e+00, -2.2415216e+00,\n",
              "        3.2298620e+00,  2.3921216e+00, -2.7623457e-01,  2.7122283e+00,\n",
              "        2.9585545e+00,  4.3676031e-01, -1.3524405e+00,  1.0106429e+00,\n",
              "        2.7771709e+00,  7.1136680e+00, -2.9760287e+00,  3.4307318e+00,\n",
              "        1.3302125e+00, -3.7126739e+00, -2.9561855e-02, -4.4102345e+00,\n",
              "       -1.8152529e+00, -1.5742894e-02,  1.8054245e-01,  3.2185533e+00,\n",
              "        8.9865762e-01,  6.7859759e+00, -7.2359905e-02,  4.8702002e+00,\n",
              "       -1.3385351e+00, -3.5612178e-01,  3.5672119e+00, -1.0588086e+00,\n",
              "        1.1689118e+01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[:,100].flatten()"
      ],
      "metadata": {
        "id": "fKoIwTyR5rQa",
        "outputId": "9d9ff0d6-ee24-444b-8067-4819ee05c912",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11.689118, 12.660099, 12.072441, 10.014484, 10.427648, 10.893843,\n",
              "       11.349183,  8.377089, 12.765142,  9.753993, 13.452802,  9.308194,\n",
              "        9.111309, 11.043558, 12.507127,  8.944355], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[:,100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4c_nsyj-DWl",
        "outputId": "14a5a8c2-9c3e-4a72-9fcc-7f1a9320f0c0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11.689118, 12.660099, 12.072441, 10.014484, 10.427648, 10.893843,\n",
              "       11.349183,  8.377089, 12.765142,  9.753993, 13.452802,  9.308194,\n",
              "        9.111309, 11.043558, 12.507127,  8.944355], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[:,100] = logits[:,100] +10"
      ],
      "metadata": {
        "id": "_8GrOzoD9yCH"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwtiSFBG95Ds",
        "outputId": "b5392129-6fd3-457a-90c7-1bdae2c2a9bf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.0996609e+00, -1.6790918e+00, -2.8319037e+00,  4.8462071e+00,\n",
              "       -1.2346944e+00,  1.2848768e-01, -7.3115964e+00,  1.2761467e+00,\n",
              "        8.7527359e-01,  1.3938758e+00,  5.0330334e+00,  1.6960272e+00,\n",
              "        6.1136885e+00,  3.0458198e+00, -2.4202554e+00,  7.4863701e+00,\n",
              "        3.5305688e+00, -3.6537640e+00,  6.9197905e-01, -4.0501647e+00,\n",
              "       -2.1340194e+00, -3.2536345e+00,  1.0249410e+00, -3.8096561e+00,\n",
              "        1.1830561e+00,  9.3371964e-01, -1.1311479e+00, -2.2338388e+00,\n",
              "       -7.5191736e-01, -1.2780213e+00, -4.3915421e-01, -3.3016515e+00,\n",
              "       -6.1894357e-01,  3.8974103e-01,  1.7989233e+00,  1.2102002e+00,\n",
              "       -7.3611873e-01,  4.5160756e+00,  1.6900563e+00,  3.7431271e+00,\n",
              "       -1.9941065e+00, -2.3456495e+00, -1.0667553e+00,  1.6159681e+01,\n",
              "       -2.4779987e+00,  7.3027892e+00,  3.9735091e+00,  2.6683168e+00,\n",
              "        1.4056995e+00,  1.2774503e+00,  4.3289142e+00,  2.5949926e+00,\n",
              "        3.4666615e+00, -2.9608481e+00, -3.9181409e+00, -4.6378851e-01,\n",
              "        1.2821400e+00,  6.3494515e-01, -1.7643874e+00,  4.8106074e+00,\n",
              "       -2.8821847e+00, -5.1097174e+00,  8.8775426e-02, -1.3933393e+00,\n",
              "       -4.0252476e+00, -1.5280004e+00, -8.8146490e-01, -3.6417024e+00,\n",
              "        6.8715721e-01, -5.5551201e-01, -1.4843566e+00, -2.2415216e+00,\n",
              "        3.2298620e+00,  2.3921216e+00, -2.7623457e-01,  2.7122283e+00,\n",
              "        2.9585545e+00,  4.3676031e-01, -1.3524405e+00,  1.0106429e+00,\n",
              "        2.7771709e+00,  7.1136680e+00, -2.9760287e+00,  3.4307318e+00,\n",
              "        1.3302125e+00, -3.7126739e+00, -2.9561855e-02, -4.4102345e+00,\n",
              "       -1.8152529e+00, -1.5742894e-02,  1.8054245e-01,  3.2185533e+00,\n",
              "        8.9865762e-01,  6.7859759e+00, -7.2359905e-02,  4.8702002e+00,\n",
              "       -1.3385351e+00, -3.5612178e-01,  3.5672119e+00, -1.0588086e+00,\n",
              "        2.1689117e+01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B = logits[:,100].flatten()+5"
      ],
      "metadata": {
        "id": "pgBa2Rgg2xHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1SF2OxN4JUd",
        "outputId": "f86fe0aa-5cec-41ca-b530-c07ab856a3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16.689117, 17.660099, 17.072441, 15.014484, 15.42765 , 15.893845,\n",
              "       16.349188, 13.37709 , 17.765142, 14.753988, 18.4528  , 14.308195,\n",
              "       14.111306, 16.043554, 17.507126, 13.944355], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B - A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qeu_pCuL3RLE",
        "outputId": "e614fbe4-1105-4860-8cfb-c3a56cf14f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.5294304 ,  1.5173836 ,  0.6519871 ,  2.2171535 , -0.15111351,\n",
              "        1.5934486 ,  0.12586784, -0.13841152,  0.84963036,  5.        ,\n",
              "        1.1189804 , -0.24104309,  2.5962973 ,  0.9496956 ,  1.1245918 ,\n",
              "        2.152835  ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQY7kD5NzUQn",
        "outputId": "3a314f19-ddae-498b-e356-9e87e4fadaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.0996609e+00, -1.6790900e+00, -2.8319027e+00,  4.8462095e+00,\n",
              "       -1.2346971e+00,  1.2848650e-01, -7.3115978e+00,  1.2761461e+00,\n",
              "        8.7527359e-01,  1.3938751e+00,  5.0330329e+00,  1.6960280e+00,\n",
              "        6.1136885e+00,  3.0458202e+00, -2.4202557e+00,  7.4863701e+00,\n",
              "        3.5305686e+00, -3.6537657e+00,  6.9197953e-01, -4.0501666e+00,\n",
              "       -2.1340208e+00, -3.2536354e+00,  1.0249424e+00, -3.8096557e+00,\n",
              "        1.1830566e+00,  9.3372047e-01, -1.1311474e+00, -2.2338395e+00,\n",
              "       -7.5191766e-01, -1.2780216e+00, -4.3915480e-01, -3.3016520e+00,\n",
              "       -6.1894429e-01,  3.8974038e-01,  1.7989233e+00,  1.2102022e+00,\n",
              "       -7.3611897e-01,  4.5160770e+00,  1.6900564e+00,  3.7431254e+00,\n",
              "       -1.9941070e+00, -2.3456492e+00, -1.0667535e+00,  1.6159687e+01,\n",
              "       -2.4779971e+00,  7.3027887e+00,  3.9735079e+00,  2.6683164e+00,\n",
              "        1.4056995e+00,  1.2774494e+00,  4.3289151e+00,  2.5949929e+00,\n",
              "        3.4666610e+00, -2.9608474e+00, -3.9181399e+00, -4.6378908e-01,\n",
              "        1.2821393e+00,  6.3494408e-01, -1.7643869e+00,  4.8106093e+00,\n",
              "       -2.8821840e+00, -5.1097212e+00,  8.8775873e-02, -1.3933393e+00,\n",
              "       -4.0252471e+00, -1.5280032e+00, -8.8146418e-01, -3.6417046e+00,\n",
              "        6.8715900e-01, -5.5551451e-01, -1.4843564e+00, -2.2415223e+00,\n",
              "        3.2298627e+00,  2.3921208e+00, -2.7623457e-01,  2.7122293e+00,\n",
              "        2.9585564e+00,  4.3676332e-01, -1.3524407e+00,  1.0106418e+00,\n",
              "        2.7771697e+00,  7.1136665e+00, -2.9760303e+00,  3.4307315e+00,\n",
              "        1.3302134e+00, -3.7126729e+00, -2.9563338e-02, -4.4102325e+00,\n",
              "       -1.8152528e+00, -1.5743375e-02,  1.8054119e-01,  3.2185545e+00,\n",
              "        8.9865690e-01,  6.7859769e+00, -7.2359204e-02,  4.8702021e+00,\n",
              "       -1.3385346e+00, -3.5612461e-01,  3.5672123e+00, -1.0588081e+00,\n",
              "        1.1689117e+01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[:,100].flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhx-17rfuvMJ",
        "outputId": "346eaac5-b7d3-49ca-9090-bc979d762873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11.689117, 12.660098, 12.072441, 10.014484, 10.42765 , 10.893845,\n",
              "       11.349188,  8.37709 , 12.765142,  9.753988, 13.4528  ,  9.308195,\n",
              "        9.111306, 11.043554, 12.507126,  8.944355], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(logits)\n",
        "for i in logits:\n",
        "  print(i[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkrxioAluvPg",
        "outputId": "3e417b12-9784-4132-b4b5-d1877eb8486d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.689117\n",
            "12.660098\n",
            "12.072441\n",
            "10.014484\n",
            "10.42765\n",
            "10.893845\n",
            "11.349188\n",
            "8.37709\n",
            "12.765142\n",
            "9.753988\n",
            "13.4528\n",
            "9.308195\n",
            "9.111306\n",
            "11.043554\n",
            "12.507126\n",
            "8.944355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/ASU/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "if not os.path.exists(output_dir+'tokenizer/'):\n",
        "    os.makedirs(output_dir+'tokenizer/')\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir+'tokenizer/')\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "metadata": {
        "id": "xFET0qIiPdk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f8df59-8609-4900-8257-f7d123d727bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/ASU/model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ASU/model_save/tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/tokenizer/vocab.txt',\n",
              " '/content/drive/MyDrive/ASU/model_save/tokenizer/added_tokens.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "Tv4UlVXfHU5h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "87e38bce-fb4e-4de7-9b98-7dfa21a42684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1              -4.99         0.63           0.87       0:53:21         0:02:49\n",
              "2              -4.99         0.63           0.87       0:53:27         0:02:49"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbd1269d-0e15-4f0e-9141-9b8f6e71ebf9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-4.99</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:53:21</td>\n",
              "      <td>0:02:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-4.99</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:53:27</td>\n",
              "      <td>0:02:49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbd1269d-0e15-4f0e-9141-9b8f6e71ebf9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbd1269d-0e15-4f0e-9141-9b8f6e71ebf9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbd1269d-0e15-4f0e-9141-9b8f6e71ebf9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iweBagNKHVLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "8a2b6a44-4aef-4dfd-c349-3f253a1d7ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import regex as re\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ASU/ood_test_data_small.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nUAlH28vHYuN"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['flag']=df.loc[:,['real_label','review']].apply(lambda x: re.match(\"UPDATE*\",x['review']),axis=1 )\n",
        "#removing updated records\n",
        "\n",
        "df=df.loc[:,['real_label','review','flag']].loc[df['flag'].isin([None])]\n",
        "df.drop('flag',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "rAII-BpSKeSC"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "JjfsmaGSL38f",
        "outputId": "a6c4d4df-cc95-4628-cbba-7575d265443c"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   real_label                                             review\n",
              "0          44  I bought this battery charger a year ago, when...\n",
              "1          44  I bought this because with four geriatric vehi...\n",
              "2          44  I was a tad skeptical of the outcome after see...\n",
              "3          44  I insist on every one of my vehicles to have a...\n",
              "4          44  This is a very well-made top grain cow leather...\n",
              "5          44  At first I was pleased to get this roller shad...\n",
              "6          44  This strap appears well-made, with inch-thick ...\n",
              "7          44  For a quick, overall shine on chrome and plast...\n",
              "8          44  This balaclava comes in a small, bubble-wrap p...\n",
              "9          44  This is an impressive car jump battery pack wi..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7702af78-bc78-4302-b140-154d36145690\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real_label</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44</td>\n",
              "      <td>I bought this battery charger a year ago, when...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>I bought this because with four geriatric vehi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44</td>\n",
              "      <td>I was a tad skeptical of the outcome after see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>I insist on every one of my vehicles to have a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44</td>\n",
              "      <td>This is a very well-made top grain cow leather...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>44</td>\n",
              "      <td>At first I was pleased to get this roller shad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>44</td>\n",
              "      <td>This strap appears well-made, with inch-thick ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>44</td>\n",
              "      <td>For a quick, overall shine on chrome and plast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>44</td>\n",
              "      <td>This balaclava comes in a small, bubble-wrap p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>44</td>\n",
              "      <td>This is an impressive car jump battery pack wi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7702af78-bc78-4302-b140-154d36145690')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7702af78-bc78-4302-b140-154d36145690 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7702af78-bc78-4302-b140-154d36145690');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_real_labels = [i for i in range(100,10000)]"
      ],
      "metadata": {
        "id": "ZIBmhuYisehN"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_real_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkEsbxpisl0i",
        "outputId": "7ab19b25-63d5-4162-e811-78b030b4baba"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 406,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 420,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 431,\n",
              " 432,\n",
              " 433,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 439,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 458,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 464,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 472,\n",
              " 473,\n",
              " 474,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 479,\n",
              " 480,\n",
              " 481,\n",
              " 482,\n",
              " 483,\n",
              " 484,\n",
              " 485,\n",
              " 486,\n",
              " 487,\n",
              " 488,\n",
              " 489,\n",
              " 490,\n",
              " 491,\n",
              " 492,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 498,\n",
              " 499,\n",
              " 500,\n",
              " 501,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 505,\n",
              " 506,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 521,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 531,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 536,\n",
              " 537,\n",
              " 538,\n",
              " 539,\n",
              " 540,\n",
              " 541,\n",
              " 542,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 549,\n",
              " 550,\n",
              " 551,\n",
              " 552,\n",
              " 553,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 561,\n",
              " 562,\n",
              " 563,\n",
              " 564,\n",
              " 565,\n",
              " 566,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 576,\n",
              " 577,\n",
              " 578,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 582,\n",
              " 583,\n",
              " 584,\n",
              " 585,\n",
              " 586,\n",
              " 587,\n",
              " 588,\n",
              " 589,\n",
              " 590,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 600,\n",
              " 601,\n",
              " 602,\n",
              " 603,\n",
              " 604,\n",
              " 605,\n",
              " 606,\n",
              " 607,\n",
              " 608,\n",
              " 609,\n",
              " 610,\n",
              " 611,\n",
              " 612,\n",
              " 613,\n",
              " 614,\n",
              " 615,\n",
              " 616,\n",
              " 617,\n",
              " 618,\n",
              " 619,\n",
              " 620,\n",
              " 621,\n",
              " 622,\n",
              " 623,\n",
              " 624,\n",
              " 625,\n",
              " 626,\n",
              " 627,\n",
              " 628,\n",
              " 629,\n",
              " 630,\n",
              " 631,\n",
              " 632,\n",
              " 633,\n",
              " 634,\n",
              " 635,\n",
              " 636,\n",
              " 637,\n",
              " 638,\n",
              " 639,\n",
              " 640,\n",
              " 641,\n",
              " 642,\n",
              " 643,\n",
              " 644,\n",
              " 645,\n",
              " 646,\n",
              " 647,\n",
              " 648,\n",
              " 649,\n",
              " 650,\n",
              " 651,\n",
              " 652,\n",
              " 653,\n",
              " 654,\n",
              " 655,\n",
              " 656,\n",
              " 657,\n",
              " 658,\n",
              " 659,\n",
              " 660,\n",
              " 661,\n",
              " 662,\n",
              " 663,\n",
              " 664,\n",
              " 665,\n",
              " 666,\n",
              " 667,\n",
              " 668,\n",
              " 669,\n",
              " 670,\n",
              " 671,\n",
              " 672,\n",
              " 673,\n",
              " 674,\n",
              " 675,\n",
              " 676,\n",
              " 677,\n",
              " 678,\n",
              " 679,\n",
              " 680,\n",
              " 681,\n",
              " 682,\n",
              " 683,\n",
              " 684,\n",
              " 685,\n",
              " 686,\n",
              " 687,\n",
              " 688,\n",
              " 689,\n",
              " 690,\n",
              " 691,\n",
              " 692,\n",
              " 693,\n",
              " 694,\n",
              " 695,\n",
              " 696,\n",
              " 697,\n",
              " 698,\n",
              " 699,\n",
              " 700,\n",
              " 701,\n",
              " 702,\n",
              " 703,\n",
              " 704,\n",
              " 705,\n",
              " 706,\n",
              " 707,\n",
              " 708,\n",
              " 709,\n",
              " 710,\n",
              " 711,\n",
              " 712,\n",
              " 713,\n",
              " 714,\n",
              " 715,\n",
              " 716,\n",
              " 717,\n",
              " 718,\n",
              " 719,\n",
              " 720,\n",
              " 721,\n",
              " 722,\n",
              " 723,\n",
              " 724,\n",
              " 725,\n",
              " 726,\n",
              " 727,\n",
              " 728,\n",
              " 729,\n",
              " 730,\n",
              " 731,\n",
              " 732,\n",
              " 733,\n",
              " 734,\n",
              " 735,\n",
              " 736,\n",
              " 737,\n",
              " 738,\n",
              " 739,\n",
              " 740,\n",
              " 741,\n",
              " 742,\n",
              " 743,\n",
              " 744,\n",
              " 745,\n",
              " 746,\n",
              " 747,\n",
              " 748,\n",
              " 749,\n",
              " 750,\n",
              " 751,\n",
              " 752,\n",
              " 753,\n",
              " 754,\n",
              " 755,\n",
              " 756,\n",
              " 757,\n",
              " 758,\n",
              " 759,\n",
              " 760,\n",
              " 761,\n",
              " 762,\n",
              " 763,\n",
              " 764,\n",
              " 765,\n",
              " 766,\n",
              " 767,\n",
              " 768,\n",
              " 769,\n",
              " 770,\n",
              " 771,\n",
              " 772,\n",
              " 773,\n",
              " 774,\n",
              " 775,\n",
              " 776,\n",
              " 777,\n",
              " 778,\n",
              " 779,\n",
              " 780,\n",
              " 781,\n",
              " 782,\n",
              " 783,\n",
              " 784,\n",
              " 785,\n",
              " 786,\n",
              " 787,\n",
              " 788,\n",
              " 789,\n",
              " 790,\n",
              " 791,\n",
              " 792,\n",
              " 793,\n",
              " 794,\n",
              " 795,\n",
              " 796,\n",
              " 797,\n",
              " 798,\n",
              " 799,\n",
              " 800,\n",
              " 801,\n",
              " 802,\n",
              " 803,\n",
              " 804,\n",
              " 805,\n",
              " 806,\n",
              " 807,\n",
              " 808,\n",
              " 809,\n",
              " 810,\n",
              " 811,\n",
              " 812,\n",
              " 813,\n",
              " 814,\n",
              " 815,\n",
              " 816,\n",
              " 817,\n",
              " 818,\n",
              " 819,\n",
              " 820,\n",
              " 821,\n",
              " 822,\n",
              " 823,\n",
              " 824,\n",
              " 825,\n",
              " 826,\n",
              " 827,\n",
              " 828,\n",
              " 829,\n",
              " 830,\n",
              " 831,\n",
              " 832,\n",
              " 833,\n",
              " 834,\n",
              " 835,\n",
              " 836,\n",
              " 837,\n",
              " 838,\n",
              " 839,\n",
              " 840,\n",
              " 841,\n",
              " 842,\n",
              " 843,\n",
              " 844,\n",
              " 845,\n",
              " 846,\n",
              " 847,\n",
              " 848,\n",
              " 849,\n",
              " 850,\n",
              " 851,\n",
              " 852,\n",
              " 853,\n",
              " 854,\n",
              " 855,\n",
              " 856,\n",
              " 857,\n",
              " 858,\n",
              " 859,\n",
              " 860,\n",
              " 861,\n",
              " 862,\n",
              " 863,\n",
              " 864,\n",
              " 865,\n",
              " 866,\n",
              " 867,\n",
              " 868,\n",
              " 869,\n",
              " 870,\n",
              " 871,\n",
              " 872,\n",
              " 873,\n",
              " 874,\n",
              " 875,\n",
              " 876,\n",
              " 877,\n",
              " 878,\n",
              " 879,\n",
              " 880,\n",
              " 881,\n",
              " 882,\n",
              " 883,\n",
              " 884,\n",
              " 885,\n",
              " 886,\n",
              " 887,\n",
              " 888,\n",
              " 889,\n",
              " 890,\n",
              " 891,\n",
              " 892,\n",
              " 893,\n",
              " 894,\n",
              " 895,\n",
              " 896,\n",
              " 897,\n",
              " 898,\n",
              " 899,\n",
              " 900,\n",
              " 901,\n",
              " 902,\n",
              " 903,\n",
              " 904,\n",
              " 905,\n",
              " 906,\n",
              " 907,\n",
              " 908,\n",
              " 909,\n",
              " 910,\n",
              " 911,\n",
              " 912,\n",
              " 913,\n",
              " 914,\n",
              " 915,\n",
              " 916,\n",
              " 917,\n",
              " 918,\n",
              " 919,\n",
              " 920,\n",
              " 921,\n",
              " 922,\n",
              " 923,\n",
              " 924,\n",
              " 925,\n",
              " 926,\n",
              " 927,\n",
              " 928,\n",
              " 929,\n",
              " 930,\n",
              " 931,\n",
              " 932,\n",
              " 933,\n",
              " 934,\n",
              " 935,\n",
              " 936,\n",
              " 937,\n",
              " 938,\n",
              " 939,\n",
              " 940,\n",
              " 941,\n",
              " 942,\n",
              " 943,\n",
              " 944,\n",
              " 945,\n",
              " 946,\n",
              " 947,\n",
              " 948,\n",
              " 949,\n",
              " 950,\n",
              " 951,\n",
              " 952,\n",
              " 953,\n",
              " 954,\n",
              " 955,\n",
              " 956,\n",
              " 957,\n",
              " 958,\n",
              " 959,\n",
              " 960,\n",
              " 961,\n",
              " 962,\n",
              " 963,\n",
              " 964,\n",
              " 965,\n",
              " 966,\n",
              " 967,\n",
              " 968,\n",
              " 969,\n",
              " 970,\n",
              " 971,\n",
              " 972,\n",
              " 973,\n",
              " 974,\n",
              " 975,\n",
              " 976,\n",
              " 977,\n",
              " 978,\n",
              " 979,\n",
              " 980,\n",
              " 981,\n",
              " 982,\n",
              " 983,\n",
              " 984,\n",
              " 985,\n",
              " 986,\n",
              " 987,\n",
              " 988,\n",
              " 989,\n",
              " 990,\n",
              " 991,\n",
              " 992,\n",
              " 993,\n",
              " 994,\n",
              " 995,\n",
              " 996,\n",
              " 997,\n",
              " 998,\n",
              " 999,\n",
              " 1000,\n",
              " 1001,\n",
              " 1002,\n",
              " 1003,\n",
              " 1004,\n",
              " 1005,\n",
              " 1006,\n",
              " 1007,\n",
              " 1008,\n",
              " 1009,\n",
              " 1010,\n",
              " 1011,\n",
              " 1012,\n",
              " 1013,\n",
              " 1014,\n",
              " 1015,\n",
              " 1016,\n",
              " 1017,\n",
              " 1018,\n",
              " 1019,\n",
              " 1020,\n",
              " 1021,\n",
              " 1022,\n",
              " 1023,\n",
              " 1024,\n",
              " 1025,\n",
              " 1026,\n",
              " 1027,\n",
              " 1028,\n",
              " 1029,\n",
              " 1030,\n",
              " 1031,\n",
              " 1032,\n",
              " 1033,\n",
              " 1034,\n",
              " 1035,\n",
              " 1036,\n",
              " 1037,\n",
              " 1038,\n",
              " 1039,\n",
              " 1040,\n",
              " 1041,\n",
              " 1042,\n",
              " 1043,\n",
              " 1044,\n",
              " 1045,\n",
              " 1046,\n",
              " 1047,\n",
              " 1048,\n",
              " 1049,\n",
              " 1050,\n",
              " 1051,\n",
              " 1052,\n",
              " 1053,\n",
              " 1054,\n",
              " 1055,\n",
              " 1056,\n",
              " 1057,\n",
              " 1058,\n",
              " 1059,\n",
              " 1060,\n",
              " 1061,\n",
              " 1062,\n",
              " 1063,\n",
              " 1064,\n",
              " 1065,\n",
              " 1066,\n",
              " 1067,\n",
              " 1068,\n",
              " 1069,\n",
              " 1070,\n",
              " 1071,\n",
              " 1072,\n",
              " 1073,\n",
              " 1074,\n",
              " 1075,\n",
              " 1076,\n",
              " 1077,\n",
              " 1078,\n",
              " 1079,\n",
              " 1080,\n",
              " 1081,\n",
              " 1082,\n",
              " 1083,\n",
              " 1084,\n",
              " 1085,\n",
              " 1086,\n",
              " 1087,\n",
              " 1088,\n",
              " 1089,\n",
              " 1090,\n",
              " 1091,\n",
              " 1092,\n",
              " 1093,\n",
              " 1094,\n",
              " 1095,\n",
              " 1096,\n",
              " 1097,\n",
              " 1098,\n",
              " 1099,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['real_label'] = df['real_label'].replace(arr_real_labels,100)"
      ],
      "metadata": {
        "id": "KNe-aZ9SsZ-4"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.loc[df.real_label.values<100]"
      ],
      "metadata": {
        "id": "mApZpnbpMN10"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(by='real_label').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "XikERaqQLOiG",
        "outputId": "8cd174af-f3cd-4d03-f6ac-8a5fab9a9ca5"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            review\n",
              "real_label        \n",
              "0               99\n",
              "1              100\n",
              "2              100\n",
              "3              100\n",
              "4              100\n",
              "...            ...\n",
              "95             100\n",
              "96             100\n",
              "97             100\n",
              "98             100\n",
              "99             100\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5881bf5b-8e2d-446a-a88a-f34f2e85c834\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>real_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5881bf5b-8e2d-446a-a88a-f34f2e85c834')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5881bf5b-8e2d-446a-a88a-f34f2e85c834 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5881bf5b-8e2d-446a-a88a-f34f2e85c834');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create sentence and label lists\n",
        "#\n",
        "labels = df.real_label.values\n",
        "sentence1 = df.review.values\n",
        "#sentence1=sentences\n",
        "#labels = dataset_filtered.real_label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent1 in zip(sentence1):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    #print(sent1)\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent1[0],# Sentence to encode.\n",
        "                        truncation=True,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        return_overflowing_tokens=False,\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "r9dPsWLsKHFH"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  logits[:,100] = logits[:,100] + 2.5\n",
        "  pred_labels = np.argmax(logits, axis=1)\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(pred_labels.tolist())\n",
        "  true_labels.extend(label_ids.tolist())\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJTEXHAzM3pK",
        "outputId": "33e7e5c5-8a89-4126-9179-e983429ecb6e"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 9,987 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(predictions)"
      ],
      "metadata": {
        "id": "6Uo5Q2CMsC2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2329b50f-84b6-4d36-95ca-18786c4eaba6"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(true_labels)"
      ],
      "metadata": {
        "id": "04Gb-rS0sFPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e581b68-b704-45ed-be45-bcff1be858b4"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "id": "ISe3fy7CAden",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720eef7b-7560-455d-a10e-12d887e85486"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19987"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.count(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kubLwA5dDipj",
        "outputId": "12dd1a6c-8d18-4669-82ad-f8c607c6bc59"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9135"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.count(100)/len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjJqO75QDkd1",
        "outputId": "5bccbfb5-1ad7-4d7a-e384-e7ddcb06662e"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4570470806023916"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#all classes\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "result_report= classification_report(true_labels, predictions, digits=3, output_dict=False)\n",
        "print(result_report)"
      ],
      "metadata": {
        "id": "FCeZuz9vAdhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e6607c-0e2b-4150-a5be-141202131917"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.482     0.677     0.563        99\n",
            "           1      0.741     0.800     0.769       100\n",
            "           2      0.681     0.810     0.740       100\n",
            "           3      0.941     0.950     0.945       100\n",
            "           4      0.214     0.240     0.226       100\n",
            "           5      0.639     0.394     0.487        99\n",
            "           6      0.482     0.410     0.443       100\n",
            "           7      0.828     0.960     0.889       100\n",
            "           8      0.664     0.890     0.761       100\n",
            "           9      0.602     0.650     0.625       100\n",
            "          10      0.930     0.930     0.930       100\n",
            "          11      0.571     0.720     0.637       100\n",
            "          12      0.659     0.890     0.757       100\n",
            "          13      0.843     0.750     0.794       100\n",
            "          14      0.637     0.510     0.567       100\n",
            "          15      0.854     0.880     0.867       100\n",
            "          16      0.900     0.810     0.853       100\n",
            "          17      0.794     0.850     0.821       100\n",
            "          18      0.669     0.790     0.725       100\n",
            "          19      0.607     0.680     0.642       100\n",
            "          20      0.944     0.840     0.889       100\n",
            "          21      0.614     0.700     0.654       100\n",
            "          22      0.576     0.340     0.428       100\n",
            "          23      0.407     0.570     0.475       100\n",
            "          24      0.456     0.620     0.525       100\n",
            "          25      0.699     0.798     0.745        99\n",
            "          26      0.780     0.960     0.861       100\n",
            "          27      0.386     0.540     0.450       100\n",
            "          28      0.475     0.660     0.552       100\n",
            "          29      0.889     0.816     0.851        98\n",
            "          30      0.784     0.690     0.734       100\n",
            "          31      0.670     0.750     0.708       100\n",
            "          32      0.333     0.810     0.472       100\n",
            "          33      0.321     0.340     0.330       100\n",
            "          34      0.690     0.490     0.573       100\n",
            "          35      0.844     0.270     0.409       100\n",
            "          36      0.629     0.610     0.619       100\n",
            "          37      0.794     0.850     0.821       100\n",
            "          38      0.900     0.636     0.746        99\n",
            "          39      0.497     0.760     0.601       100\n",
            "          40      0.451     0.460     0.455       100\n",
            "          41      0.552     0.950     0.699       100\n",
            "          42      0.770     0.670     0.717       100\n",
            "          43      0.579     0.550     0.564       100\n",
            "          44      0.551     0.510     0.530        96\n",
            "          45      0.935     0.580     0.716       100\n",
            "          46      0.891     0.980     0.933       100\n",
            "          47      0.688     0.860     0.764       100\n",
            "          48      0.828     0.770     0.798       100\n",
            "          49      0.918     0.900     0.909       100\n",
            "          50      0.284     0.540     0.372       100\n",
            "          51      0.853     0.580     0.690       100\n",
            "          52      0.538     0.640     0.584       100\n",
            "          53      0.456     0.680     0.546       100\n",
            "          54      0.864     0.570     0.687       100\n",
            "          55      0.467     0.780     0.584       100\n",
            "          56      0.904     0.940     0.922       100\n",
            "          57      0.831     0.690     0.754       100\n",
            "          58      0.747     0.650     0.695       100\n",
            "          59      0.693     0.880     0.775       100\n",
            "          60      0.667     0.700     0.683       100\n",
            "          61      0.570     0.570     0.570       100\n",
            "          62      0.595     0.780     0.675       100\n",
            "          63      0.893     0.670     0.766       100\n",
            "          64      0.894     0.840     0.866       100\n",
            "          65      0.762     0.770     0.766       100\n",
            "          66      0.897     0.780     0.834       100\n",
            "          67      0.705     0.740     0.722       100\n",
            "          68      0.571     0.360     0.442       100\n",
            "          69      0.574     0.673     0.620        98\n",
            "          70      0.575     0.610     0.592       100\n",
            "          71      0.457     0.580     0.511       100\n",
            "          72      0.943     1.000     0.971       100\n",
            "          73      0.433     0.450     0.441       100\n",
            "          74      0.776     0.900     0.833       100\n",
            "          75      0.935     0.430     0.589       100\n",
            "          76      0.959     0.940     0.949       100\n",
            "          77      0.561     0.780     0.653       100\n",
            "          78      0.535     0.540     0.537       100\n",
            "          79      1.000     0.970     0.985       100\n",
            "          80      0.847     1.000     0.917       100\n",
            "          81      0.570     0.850     0.683       100\n",
            "          82      0.537     0.650     0.588       100\n",
            "          83      0.810     0.940     0.870       100\n",
            "          84      0.865     0.450     0.592       100\n",
            "          85      0.483     0.830     0.610       100\n",
            "          86      0.487     0.910     0.634       100\n",
            "          87      0.363     0.450     0.402       100\n",
            "          88      0.507     0.740     0.602       100\n",
            "          89      0.620     0.620     0.620       100\n",
            "          90      0.517     0.606     0.558        99\n",
            "          91      0.817     0.490     0.613       100\n",
            "          92      0.681     0.960     0.797       100\n",
            "          93      0.975     0.770     0.860       100\n",
            "          94      0.598     0.640     0.618       100\n",
            "          95      0.952     0.590     0.728       100\n",
            "          96      0.537     0.950     0.686       100\n",
            "          97      0.552     0.320     0.405       100\n",
            "          98      0.779     0.600     0.678       100\n",
            "          99      0.707     0.820     0.759       100\n",
            "         100      0.742     0.678     0.709     10000\n",
            "\n",
            "    accuracy                          0.690     19987\n",
            "   macro avg      0.678     0.701     0.674     19987\n",
            "weighted avg      0.710     0.690     0.692     19987\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIWN9I0xEqa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2RVrY9bEqiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BW69RUlREqlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2fBN-gGAEqns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKDOI2t9EqrL",
        "outputId": "2142f1ef-255e-42af-a8b2-97b03beb175e"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(true_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egodBhBSEtpc",
        "outputId": "dd18dbb2-f94f-49a8-9112-fb250103c488"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HKrQAksEwKW",
        "outputId": "23ed9b6a-9601-4175-9963-b7e17e54f7f9"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9987"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.count(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBbavERSEyLz",
        "outputId": "7e1f85f8-8986-49e1-9846-6cc7794ccd96"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2353"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.count(100)/len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRtw9ANqE0Wf",
        "outputId": "5eaea80b-48c7-4a24-dc68-dc1f44a1dd62"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.235606288174627"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#known classes\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "result_report= classification_report(true_labels, predictions, digits=3, output_dict=False)\n",
        "print(result_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlC333pBAdmX",
        "outputId": "ea5436cd-d7af-4940-c59e-d2a002388adf"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.604     0.677     0.638        99\n",
            "           1      0.976     0.800     0.879       100\n",
            "           2      0.953     0.810     0.876       100\n",
            "           3      0.960     0.950     0.955       100\n",
            "           4      0.750     0.240     0.364       100\n",
            "           5      0.929     0.394     0.553        99\n",
            "           6      0.932     0.410     0.569       100\n",
            "           7      0.941     0.960     0.950       100\n",
            "           8      0.908     0.890     0.899       100\n",
            "           9      0.714     0.650     0.681       100\n",
            "          10      0.979     0.930     0.954       100\n",
            "          11      0.791     0.720     0.754       100\n",
            "          12      0.989     0.890     0.937       100\n",
            "          13      0.987     0.750     0.852       100\n",
            "          14      0.761     0.510     0.611       100\n",
            "          15      0.946     0.880     0.912       100\n",
            "          16      0.988     0.810     0.890       100\n",
            "          17      0.895     0.850     0.872       100\n",
            "          18      0.832     0.790     0.810       100\n",
            "          19      0.850     0.680     0.756       100\n",
            "          20      1.000     0.840     0.913       100\n",
            "          21      0.886     0.700     0.782       100\n",
            "          22      0.872     0.340     0.489       100\n",
            "          23      0.613     0.570     0.591       100\n",
            "          24      0.838     0.620     0.713       100\n",
            "          25      1.000     0.798     0.888        99\n",
            "          26      0.923     0.960     0.941       100\n",
            "          27      0.964     0.540     0.692       100\n",
            "          28      0.805     0.660     0.725       100\n",
            "          29      0.930     0.816     0.870        98\n",
            "          30      0.873     0.690     0.771       100\n",
            "          31      0.974     0.750     0.847       100\n",
            "          32      0.835     0.810     0.822       100\n",
            "          33      0.773     0.340     0.472       100\n",
            "          34      0.875     0.490     0.628       100\n",
            "          35      0.931     0.270     0.419       100\n",
            "          36      0.968     0.610     0.748       100\n",
            "          37      0.966     0.850     0.904       100\n",
            "          38      0.940     0.636     0.759        99\n",
            "          39      0.835     0.760     0.796       100\n",
            "          40      0.648     0.460     0.538       100\n",
            "          41      0.896     0.950     0.922       100\n",
            "          42      0.944     0.670     0.784       100\n",
            "          43      1.000     0.550     0.710       100\n",
            "          44      0.817     0.510     0.628        96\n",
            "          45      1.000     0.580     0.734       100\n",
            "          46      0.980     0.980     0.980       100\n",
            "          47      1.000     0.860     0.925       100\n",
            "          48      1.000     0.770     0.870       100\n",
            "          49      0.978     0.900     0.938       100\n",
            "          50      1.000     0.540     0.701       100\n",
            "          51      1.000     0.580     0.734       100\n",
            "          52      0.901     0.640     0.749       100\n",
            "          53      0.654     0.680     0.667       100\n",
            "          54      0.966     0.570     0.717       100\n",
            "          55      0.821     0.780     0.800       100\n",
            "          56      1.000     0.940     0.969       100\n",
            "          57      0.908     0.690     0.784       100\n",
            "          58      0.970     0.650     0.778       100\n",
            "          59      1.000     0.880     0.936       100\n",
            "          60      0.854     0.700     0.769       100\n",
            "          61      0.905     0.570     0.699       100\n",
            "          62      0.940     0.780     0.852       100\n",
            "          63      0.957     0.670     0.788       100\n",
            "          64      0.944     0.840     0.889       100\n",
            "          65      1.000     0.770     0.870       100\n",
            "          66      0.987     0.780     0.872       100\n",
            "          67      0.961     0.740     0.836       100\n",
            "          68      0.947     0.360     0.522       100\n",
            "          69      0.917     0.673     0.776        98\n",
            "          70      0.847     0.610     0.709       100\n",
            "          71      0.983     0.580     0.730       100\n",
            "          72      1.000     1.000     1.000       100\n",
            "          73      1.000     0.450     0.621       100\n",
            "          74      1.000     0.900     0.947       100\n",
            "          75      0.977     0.430     0.597       100\n",
            "          76      1.000     0.940     0.969       100\n",
            "          77      0.918     0.780     0.843       100\n",
            "          78      0.964     0.540     0.692       100\n",
            "          79      1.000     0.970     0.985       100\n",
            "          80      1.000     1.000     1.000       100\n",
            "          81      0.955     0.850     0.899       100\n",
            "          82      0.929     0.650     0.765       100\n",
            "          83      1.000     0.940     0.969       100\n",
            "          84      1.000     0.450     0.621       100\n",
            "          85      0.976     0.830     0.897       100\n",
            "          86      0.883     0.910     0.897       100\n",
            "          87      0.938     0.450     0.608       100\n",
            "          88      0.937     0.740     0.827       100\n",
            "          89      0.873     0.620     0.725       100\n",
            "          90      0.779     0.606     0.682        99\n",
            "          91      1.000     0.490     0.658       100\n",
            "          92      1.000     0.960     0.980       100\n",
            "          93      1.000     0.770     0.870       100\n",
            "          94      0.985     0.640     0.776       100\n",
            "          95      0.983     0.590     0.737       100\n",
            "          96      0.864     0.950     0.905       100\n",
            "          97      0.889     0.320     0.471       100\n",
            "          98      1.000     0.600     0.750       100\n",
            "          99      0.921     0.820     0.868       100\n",
            "         100      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.701      9987\n",
            "   macro avg      0.911     0.694     0.774      9987\n",
            "weighted avg      0.920     0.701     0.782      9987\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unknown classes\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "result_report= classification_report(true_labels, predictions, digits=3, output_dict=False)\n",
        "print(result_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFZ2ppkjaNI",
        "outputId": "964f2c1e-7b25-4307-d3ea-aec23f54c13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000         0\n",
            "           1      0.000     0.000     0.000         0\n",
            "           2      0.000     0.000     0.000         0\n",
            "           3      0.000     0.000     0.000         0\n",
            "           4      0.000     0.000     0.000         0\n",
            "           5      0.000     0.000     0.000         0\n",
            "           6      0.000     0.000     0.000         0\n",
            "           7      0.000     0.000     0.000         0\n",
            "           8      0.000     0.000     0.000         0\n",
            "           9      0.000     0.000     0.000         0\n",
            "          10      0.000     0.000     0.000         0\n",
            "          11      0.000     0.000     0.000         0\n",
            "          12      0.000     0.000     0.000         0\n",
            "          13      0.000     0.000     0.000         0\n",
            "          14      0.000     0.000     0.000         0\n",
            "          15      0.000     0.000     0.000         0\n",
            "          16      0.000     0.000     0.000         0\n",
            "          17      0.000     0.000     0.000         0\n",
            "          18      0.000     0.000     0.000         0\n",
            "          19      0.000     0.000     0.000         0\n",
            "          20      0.000     0.000     0.000         0\n",
            "          21      0.000     0.000     0.000         0\n",
            "          22      0.000     0.000     0.000         0\n",
            "          23      0.000     0.000     0.000         0\n",
            "          24      0.000     0.000     0.000         0\n",
            "          25      0.000     0.000     0.000         0\n",
            "          26      0.000     0.000     0.000         0\n",
            "          27      0.000     0.000     0.000         0\n",
            "          28      0.000     0.000     0.000         0\n",
            "          29      0.000     0.000     0.000         0\n",
            "          30      0.000     0.000     0.000         0\n",
            "          31      0.000     0.000     0.000         0\n",
            "          32      0.000     0.000     0.000         0\n",
            "          33      0.000     0.000     0.000         0\n",
            "          34      0.000     0.000     0.000         0\n",
            "          35      0.000     0.000     0.000         0\n",
            "          36      0.000     0.000     0.000         0\n",
            "          37      0.000     0.000     0.000         0\n",
            "          38      0.000     0.000     0.000         0\n",
            "          39      0.000     0.000     0.000         0\n",
            "          40      0.000     0.000     0.000         0\n",
            "          41      0.000     0.000     0.000         0\n",
            "          42      0.000     0.000     0.000         0\n",
            "          43      0.000     0.000     0.000         0\n",
            "          44      0.000     0.000     0.000         0\n",
            "          45      0.000     0.000     0.000         0\n",
            "          46      0.000     0.000     0.000         0\n",
            "          47      0.000     0.000     0.000         0\n",
            "          48      0.000     0.000     0.000         0\n",
            "          49      0.000     0.000     0.000         0\n",
            "          50      0.000     0.000     0.000         0\n",
            "          51      0.000     0.000     0.000         0\n",
            "          52      0.000     0.000     0.000         0\n",
            "          53      0.000     0.000     0.000         0\n",
            "          54      0.000     0.000     0.000         0\n",
            "          55      0.000     0.000     0.000         0\n",
            "          56      0.000     0.000     0.000         0\n",
            "          57      0.000     0.000     0.000         0\n",
            "          58      0.000     0.000     0.000         0\n",
            "          59      0.000     0.000     0.000         0\n",
            "          60      0.000     0.000     0.000         0\n",
            "          61      0.000     0.000     0.000         0\n",
            "          62      0.000     0.000     0.000         0\n",
            "          63      0.000     0.000     0.000         0\n",
            "          64      0.000     0.000     0.000         0\n",
            "          65      0.000     0.000     0.000         0\n",
            "          66      0.000     0.000     0.000         0\n",
            "          67      0.000     0.000     0.000         0\n",
            "          68      0.000     0.000     0.000         0\n",
            "          69      0.000     0.000     0.000         0\n",
            "          70      0.000     0.000     0.000         0\n",
            "          71      0.000     0.000     0.000         0\n",
            "          72      0.000     0.000     0.000         0\n",
            "          73      0.000     0.000     0.000         0\n",
            "          74      0.000     0.000     0.000         0\n",
            "          75      0.000     0.000     0.000         0\n",
            "          76      0.000     0.000     0.000         0\n",
            "          77      0.000     0.000     0.000         0\n",
            "          78      0.000     0.000     0.000         0\n",
            "          79      0.000     0.000     0.000         0\n",
            "          80      0.000     0.000     0.000         0\n",
            "          81      0.000     0.000     0.000         0\n",
            "          82      0.000     0.000     0.000         0\n",
            "          83      0.000     0.000     0.000         0\n",
            "          84      0.000     0.000     0.000         0\n",
            "          85      0.000     0.000     0.000         0\n",
            "          86      0.000     0.000     0.000         0\n",
            "          87      0.000     0.000     0.000         0\n",
            "          88      0.000     0.000     0.000         0\n",
            "          89      0.000     0.000     0.000         0\n",
            "          90      0.000     0.000     0.000         0\n",
            "          91      0.000     0.000     0.000         0\n",
            "          92      0.000     0.000     0.000         0\n",
            "          93      0.000     0.000     0.000         0\n",
            "          94      0.000     0.000     0.000         0\n",
            "          95      0.000     0.000     0.000         0\n",
            "          96      0.000     0.000     0.000         0\n",
            "          97      0.000     0.000     0.000         0\n",
            "          98      0.000     0.000     0.000         0\n",
            "          99      0.000     0.000     0.000         0\n",
            "         100      1.000     0.210     0.347     10000\n",
            "\n",
            "    accuracy                          0.210     10000\n",
            "   macro avg      0.010     0.002     0.003     10000\n",
            "weighted avg      1.000     0.210     0.347     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "caVFv6ShYsbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIxAXegHYzBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vW7Ch9PyYzEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "893z078eYzG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQSlpEx2YzKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "your_json_string = result_report\n",
        "json_object = json.dumps(your_json_string, indent=4, ensure_ascii=False)\n",
        "\n",
        "with open(\"results_1222715130.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)"
      ],
      "metadata": {
        "id": "yCI-Fs67AdpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CMuNjK5gAdre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions_ , true_labels_ = [], []\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  print(logits[1])\n",
        "  pred_labels = np.argmax(logits, axis=1)\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions_.extend(pred_labels.tolist())\n",
        "  true_labels_.extend(label_ids.tolist())\n",
        "  print(predictions_)\n",
        "  print(true_labels_)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUrkK-CzAdt8",
        "outputId": "d1e76df7-1ba3-4d9f-f317-a2f6d5a07135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.521321    0.07314553 -2.325873   -1.5545316   3.5426848   2.4031134\n",
            "  0.3055778  -1.4581652  -0.19385695  8.478442    0.21955353  0.63490045\n",
            " -2.7836509  -1.6843215   4.866111   -1.0288891   0.92718965 -0.8014004\n",
            "  0.12310801  0.22154124 -4.883802    2.364166    1.926676    3.5969424\n",
            "  1.0419817   1.2625259   0.87761426 -2.7740285   1.2729399   0.3212202\n",
            "  2.9376636  -1.2947284   3.371887    3.9017026   2.7942882   1.2241025\n",
            " -1.4135665   2.4409661  -2.0375347  -0.48364833 -1.0659833  -1.0770173\n",
            " -2.9016585  -0.36810777 10.153384   -2.2908528  -1.2075008  -2.461818\n",
            " -2.2707443   0.6778618  -1.393576    3.0939329   3.0984018   1.4783939\n",
            " -1.0920581  -0.29470092  1.6331164   3.3886757  -0.5064911  -3.1865935\n",
            "  1.6472883  -1.5547365  -0.6167881  -0.57130235 -1.6344649  -3.994726\n",
            " -3.449339   -1.2787609  -2.2344222   1.8775072  -0.42447975 -2.5376377\n",
            " -2.5433025  -3.2450795   1.3288859  -0.15739805  0.579081   -0.39993834\n",
            " -0.6305399  -0.12616795 -0.48814857 -1.8701324  -2.608364    0.87378126\n",
            "  1.487576   -1.5454506   1.8477441   3.0162365  -5.165508    3.3387237\n",
            "  3.798234    0.5680129  -4.784421   -1.9845235  -1.9633942   2.2415373\n",
            "  1.0882373  -1.8882289  -0.5277344   0.29993626  6.968705  ]\n",
            "[53, 44, 44, 44, 44, 90, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n",
            "[44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yD3m4p8WAdwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DvjCbMVDAdzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HToeHyo5_0J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "result_report= classification_report(true_labels, predictions, digits=3)\n",
        "print(result_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYNPK2cnM9FX",
        "outputId": "4906c040-80c7-4234-bd71-aa4b009f082a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.200     0.131     0.159        99\n",
            "           1      0.627     0.370     0.465       100\n",
            "           2      0.475     0.290     0.360       100\n",
            "           3      0.369     0.940     0.530       100\n",
            "           4      0.000     0.000     0.000       100\n",
            "           5      0.200     0.010     0.019        99\n",
            "           6      0.000     0.000     0.000       100\n",
            "           7      0.434     0.850     0.574       100\n",
            "           8      0.342     0.820     0.482       100\n",
            "           9      0.240     0.520     0.328       100\n",
            "          10      0.742     0.950     0.833       100\n",
            "          11      0.278     0.400     0.328       100\n",
            "          12      0.857     0.660     0.746       100\n",
            "          13      0.697     0.760     0.727       100\n",
            "          14      0.275     0.140     0.185       100\n",
            "          15      0.500     0.490     0.495       100\n",
            "          16      0.771     0.740     0.755       100\n",
            "          17      0.198     0.740     0.313       100\n",
            "          18      0.348     0.860     0.496       100\n",
            "          19      0.416     0.420     0.418       100\n",
            "          20      1.000     0.590     0.742       100\n",
            "          21      0.266     0.490     0.345       100\n",
            "          22      0.091     0.010     0.018       100\n",
            "          23      0.190     0.040     0.066       100\n",
            "          24      0.415     0.170     0.241       100\n",
            "          25      0.656     0.808     0.724        99\n",
            "          26      0.220     0.980     0.360       100\n",
            "          27      0.328     0.210     0.256       100\n",
            "          28      0.349     0.590     0.439       100\n",
            "          29      0.275     0.796     0.408        98\n",
            "          30      0.266     0.620     0.372       100\n",
            "          31      0.537     0.660     0.592       100\n",
            "          32      0.250     0.150     0.187       100\n",
            "          33      0.333     0.170     0.225       100\n",
            "          34      0.122     0.480     0.195       100\n",
            "          35      0.432     0.160     0.234       100\n",
            "          36      0.484     0.310     0.378       100\n",
            "          37      0.865     0.640     0.736       100\n",
            "          38      0.489     0.687     0.571        99\n",
            "          39      0.792     0.380     0.514       100\n",
            "          40      0.082     0.130     0.101       100\n",
            "          41      0.468     0.520     0.493       100\n",
            "          42      0.950     0.380     0.543       100\n",
            "          43      0.933     0.420     0.579       100\n",
            "          44      0.750     0.031     0.060        96\n",
            "          45      0.935     0.580     0.716       100\n",
            "          46      0.885     1.000     0.939       100\n",
            "          47      0.888     0.870     0.879       100\n",
            "          48      0.659     0.850     0.742       100\n",
            "          49      0.900     0.810     0.853       100\n",
            "          50      0.677     0.650     0.663       100\n",
            "          51      0.506     0.400     0.447       100\n",
            "          52      0.000     0.000     0.000       100\n",
            "          53      0.156     0.530     0.241       100\n",
            "          54      0.250     0.380     0.302       100\n",
            "          55      0.800     0.040     0.076       100\n",
            "          56      0.588     0.900     0.711       100\n",
            "          57      0.222     0.410     0.288       100\n",
            "          58      0.818     0.090     0.162       100\n",
            "          59      0.866     0.840     0.853       100\n",
            "          60      0.417     0.050     0.089       100\n",
            "          61      0.358     0.240     0.287       100\n",
            "          62      0.758     0.720     0.738       100\n",
            "          63      0.435     0.300     0.355       100\n",
            "          64      0.299     0.750     0.427       100\n",
            "          65      0.543     0.250     0.342       100\n",
            "          66      0.893     0.500     0.641       100\n",
            "          67      0.706     0.240     0.358       100\n",
            "          68      0.000     0.000     0.000       100\n",
            "          69      0.667     0.245     0.358        98\n",
            "          70      0.073     0.030     0.043       100\n",
            "          71      0.328     0.420     0.368       100\n",
            "          72      0.990     1.000     0.995       100\n",
            "          73      0.889     0.080     0.147       100\n",
            "          74      0.778     0.910     0.839       100\n",
            "          75      0.000     0.000     0.000       100\n",
            "          76      0.886     0.930     0.907       100\n",
            "          77      0.385     0.620     0.475       100\n",
            "          78      0.452     0.380     0.413       100\n",
            "          79      0.960     0.970     0.965       100\n",
            "          80      0.943     1.000     0.971       100\n",
            "          81      0.842     0.800     0.821       100\n",
            "          82      0.382     0.260     0.310       100\n",
            "          83      0.968     0.910     0.938       100\n",
            "          84      0.967     0.580     0.725       100\n",
            "          85      0.563     0.400     0.468       100\n",
            "          86      0.559     0.330     0.415       100\n",
            "          87      0.000     0.000     0.000       100\n",
            "          88      0.197     0.150     0.170       100\n",
            "          89      0.259     0.210     0.232       100\n",
            "          90      0.545     0.182     0.273        99\n",
            "          91      0.643     0.090     0.158       100\n",
            "          92      0.970     0.960     0.965       100\n",
            "          93      0.891     0.820     0.854       100\n",
            "          94      0.898     0.440     0.591       100\n",
            "          95      0.909     0.600     0.723       100\n",
            "          96      0.612     0.930     0.738       100\n",
            "          97      0.417     0.150     0.221       100\n",
            "          98      0.969     0.310     0.470       100\n",
            "          99      0.716     0.530     0.609       100\n",
            "\n",
            "    accuracy                          0.472      9987\n",
            "   macro avg      0.527     0.472     0.449      9987\n",
            "weighted avg      0.527     0.472     0.449      9987\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/ASU/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "metadata": {
        "id": "55TGwUWdM92G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce898a7-005b-4447-9fc3-a0379d90911e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/ASU/model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ASU/model_save/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/vocab.txt',\n",
              " '/content/drive/MyDrive/ASU/model_save/added_tokens.json',\n",
              " '/content/drive/MyDrive/ASU/model_save/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=K /content/drive/MyDrive/ASU/model_save/"
      ],
      "metadata": {
        "id": "Wup4eBSGNAnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104ad359-b384-4b32-9248-9d92adc71879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 428970K\n",
            "-rw------- 1 root root      5K Oct 28 19:32 config.json\n",
            "-rw------- 1 root root 428038K Oct 28 19:32 pytorch_model.bin\n",
            "-rw------- 1 root root      1K Oct 28 19:32 special_tokens_map.json\n",
            "drwx------ 2 root root      4K Oct 28 19:06 tokenizer\n",
            "-rw------- 1 root root      1K Oct 28 19:32 tokenizer_config.json\n",
            "-rw------- 1 root root    695K Oct 28 19:32 tokenizer.json\n",
            "-rw------- 1 root root    227K Oct 28 19:32 vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l --block-size=M /content/drive/MyDrive/ASU/model_save/pytorch_model.bin"
      ],
      "metadata": {
        "id": "AwSPmLacNFlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e86b086-9cd9-40ce-8bfc-cce240f20def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 419M Oct 28 19:32 /content/drive/MyDrive/ASU/model_save/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "mCrOKj_3eFJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76e9385-9bc4-4897-83b5-620c64aec8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 28.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 77.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "XJLCdjSR6O5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "#model = RobertaForSequenceClassification.from_pretrained(output_dir)\n",
        "#tokenizer = RobertaForSequenceClassification.from_pretrained(output_dir)\n",
        "\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/ASU/model_save/'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir+'tokenizer/')\n",
        "model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
        "\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "nvMN56oGNtjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e41148-0994-4bd2-d4e4-87afdc499601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.15, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.15, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.15, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.15, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA8r4uk9PPkj",
        "outputId": "428dbb8c-2e92-4680-8710-f49c17a8a60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Trz1nxZCPQjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8fbab10f1994b229063ab13728a4eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c913df38dfa349788aef3210a050e76f",
              "IPY_MODEL_1a637a97a2ef433f90c61569666f974d",
              "IPY_MODEL_bf9ed46215d64729ae3e1e4c89936018"
            ],
            "layout": "IPY_MODEL_3c94452b1e9f49e2a6ef8e2204e75f17"
          }
        },
        "c913df38dfa349788aef3210a050e76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6477d9145ec4642a15306c42fb0e5b8",
            "placeholder": "​",
            "style": "IPY_MODEL_12298742368944748ec6235c30aa6de9",
            "value": "Downloading: 100%"
          }
        },
        "1a637a97a2ef433f90c61569666f974d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff12dd166db44dd9b3e1fc0e69d2caca",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc90d23c6cfb459d9052bcca9c6181cb",
            "value": 28
          }
        },
        "bf9ed46215d64729ae3e1e4c89936018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6adc7d4defd84636bcbcee7e18f26e6d",
            "placeholder": "​",
            "style": "IPY_MODEL_cb59bddd00e8413d9b1895c691e11a10",
            "value": " 28.0/28.0 [00:00&lt;00:00, 173B/s]"
          }
        },
        "3c94452b1e9f49e2a6ef8e2204e75f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6477d9145ec4642a15306c42fb0e5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12298742368944748ec6235c30aa6de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff12dd166db44dd9b3e1fc0e69d2caca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc90d23c6cfb459d9052bcca9c6181cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6adc7d4defd84636bcbcee7e18f26e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb59bddd00e8413d9b1895c691e11a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61703f7d98514dd4a98bbcf20a6b1490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c5b0405910242ea9e2702988ed24610",
              "IPY_MODEL_16a77a29059d4b3aafaef293fac589c4",
              "IPY_MODEL_b35e1f19aa6946ab84f5a8beba21701f"
            ],
            "layout": "IPY_MODEL_6148c5c2aa134daebccf557542087c7e"
          }
        },
        "0c5b0405910242ea9e2702988ed24610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57ba7b537afb4b0da88186e83d48537d",
            "placeholder": "​",
            "style": "IPY_MODEL_061add92a441496486919713329df6bb",
            "value": "Downloading: 100%"
          }
        },
        "16a77a29059d4b3aafaef293fac589c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca41315e98974e09b87f37a2178d078e",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3ba42d3e272456fa076eda69178d850",
            "value": 570
          }
        },
        "b35e1f19aa6946ab84f5a8beba21701f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a616558029b34f9dabf2d4cdfa112304",
            "placeholder": "​",
            "style": "IPY_MODEL_c17b1349d1ce46f0955877d601ba29f2",
            "value": " 570/570 [00:00&lt;00:00, 3.67kB/s]"
          }
        },
        "6148c5c2aa134daebccf557542087c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ba7b537afb4b0da88186e83d48537d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "061add92a441496486919713329df6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca41315e98974e09b87f37a2178d078e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ba42d3e272456fa076eda69178d850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a616558029b34f9dabf2d4cdfa112304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c17b1349d1ce46f0955877d601ba29f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c10843fd97e946049c331463734769a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22fc2296b6a445cab503133e93f39937",
              "IPY_MODEL_f4df45341a9d49498ed222a60c530f5a",
              "IPY_MODEL_3502771957a947a9b9c1e1d574133b88"
            ],
            "layout": "IPY_MODEL_3efc247cea7341d09ef54d284bd6f7a4"
          }
        },
        "22fc2296b6a445cab503133e93f39937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae6806c486344f49b970fea14d38b9f0",
            "placeholder": "​",
            "style": "IPY_MODEL_2f7daa84a85e48cea2d4f01f12cc1c5b",
            "value": "Downloading: 100%"
          }
        },
        "f4df45341a9d49498ed222a60c530f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a187bad5424481685e850cde19b256e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_299c2db1a7af431fa4f964af5c0a28ac",
            "value": 231508
          }
        },
        "3502771957a947a9b9c1e1d574133b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f20c4aeef26f43b7bd00467225031cc7",
            "placeholder": "​",
            "style": "IPY_MODEL_b06d2f8668964ab6b88fc7bb2f72d8d5",
            "value": " 232k/232k [00:00&lt;00:00, 7.93kB/s]"
          }
        },
        "3efc247cea7341d09ef54d284bd6f7a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6806c486344f49b970fea14d38b9f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f7daa84a85e48cea2d4f01f12cc1c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a187bad5424481685e850cde19b256e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "299c2db1a7af431fa4f964af5c0a28ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f20c4aeef26f43b7bd00467225031cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b06d2f8668964ab6b88fc7bb2f72d8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94f5ad04cdaa47e49dcda39850daf905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae42439fdd244ce4b55442874171930b",
              "IPY_MODEL_24f1eaab6af64b33bd7b849ed24a7920",
              "IPY_MODEL_74711b55307b4a3c91d45ec876999c93"
            ],
            "layout": "IPY_MODEL_97223a35fd7241caab91a16046f146bb"
          }
        },
        "ae42439fdd244ce4b55442874171930b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffb82895ce3495cbc087c446ee12ce3",
            "placeholder": "​",
            "style": "IPY_MODEL_e6edb509beda4729bafdcc0b4c4ace7b",
            "value": "Downloading: 100%"
          }
        },
        "24f1eaab6af64b33bd7b849ed24a7920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58b94c1de4ee4e758675e80c4406a7bc",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2a54883c72a4d75bf52dd252c59180d",
            "value": 466062
          }
        },
        "74711b55307b4a3c91d45ec876999c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d04877f1877246ffabc5754bb3934928",
            "placeholder": "​",
            "style": "IPY_MODEL_e76e1ad512764a1292a07a70e58e95cf",
            "value": " 466k/466k [00:00&lt;00:00, 1.34MB/s]"
          }
        },
        "97223a35fd7241caab91a16046f146bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ffb82895ce3495cbc087c446ee12ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6edb509beda4729bafdcc0b4c4ace7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58b94c1de4ee4e758675e80c4406a7bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a54883c72a4d75bf52dd252c59180d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d04877f1877246ffabc5754bb3934928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e76e1ad512764a1292a07a70e58e95cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3bb64753ed340eeb9051eaa8c190614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f45af872b89469a9d8ed0cfc9ba5e1b",
              "IPY_MODEL_d9512363335f4e43b4a371e5c92c479f",
              "IPY_MODEL_0ebe5d4cbadc4d0d9c6ba4a7554fcbf5"
            ],
            "layout": "IPY_MODEL_593f9269a1e048729a08c4baf1bb3492"
          }
        },
        "7f45af872b89469a9d8ed0cfc9ba5e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffaf2783803748d9886917a04e43a727",
            "placeholder": "​",
            "style": "IPY_MODEL_0b2aa46f5f7142298bfbff0551665e68",
            "value": "Downloading: 100%"
          }
        },
        "d9512363335f4e43b4a371e5c92c479f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e87f901b914b4e0aae5a57d978f406ec",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8e86845f37f45adb4fbe0492741de01",
            "value": 440473133
          }
        },
        "0ebe5d4cbadc4d0d9c6ba4a7554fcbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37117ff5e359480e98ce51a9887464ec",
            "placeholder": "​",
            "style": "IPY_MODEL_6d8cb6c3ce0d4634a9aab87289ccd0af",
            "value": " 440M/440M [00:08&lt;00:00, 55.6MB/s]"
          }
        },
        "593f9269a1e048729a08c4baf1bb3492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffaf2783803748d9886917a04e43a727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2aa46f5f7142298bfbff0551665e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e87f901b914b4e0aae5a57d978f406ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e86845f37f45adb4fbe0492741de01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37117ff5e359480e98ce51a9887464ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8cb6c3ce0d4634a9aab87289ccd0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}